

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="pc-xie">
  <meta name="keywords" content="">
  
    <meta name="description" content="项目问题1. FullGc消除, young gc 从2秒到10ms 怎么做到的背景: 每次演练后, 通过CAT 的老年代明显的上涨, 再过1-2周, 会导致应用发生OOM1.1 FullGC 怎么消除1.1.1 增加jvm 的OOM 文件dump, -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;${DUMP_LOG_DIR}1.1.2">
<meta property="og:type" content="article">
<meta property="og:title" content="面经">
<meta property="og:url" content="http://localhost:4000/2024/08/17/interview/%E9%9D%A2%E7%BB%8F/index.html">
<meta property="og:site_name" content="pc-xie">
<meta property="og:description" content="项目问题1. FullGc消除, young gc 从2秒到10ms 怎么做到的背景: 每次演练后, 通过CAT 的老年代明显的上涨, 再过1-2周, 会导致应用发生OOM1.1 FullGC 怎么消除1.1.1 增加jvm 的OOM 文件dump, -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;${DUMP_LOG_DIR}1.1.2">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://localhost:4000/img/tcp/tcp_start_connection.png">
<meta property="og:image" content="http://localhost:4000/img/tcp/tcp_finish_connection.png">
<meta property="article:published_time" content="2024-08-17T05:20:30.839Z">
<meta property="article:modified_time" content="2024-09-05T08:50:37.462Z">
<meta property="article:author" content="pc-xie">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/img/tcp/tcp_start_connection.png">
  
  
  
  <title>面经 - pc-xie</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"localhost","root":"/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="面经"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-08-17 13:20" pubdate>
          2024年8月17日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          50k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          420 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">面经</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="项目问题"><a href="#项目问题" class="headerlink" title="项目问题"></a>项目问题</h1><h2 id="1-FullGc消除-young-gc-从2秒到10ms-怎么做到的"><a href="#1-FullGc消除-young-gc-从2秒到10ms-怎么做到的" class="headerlink" title="1. FullGc消除, young gc 从2秒到10ms 怎么做到的"></a>1. FullGc消除, young gc 从2秒到10ms 怎么做到的</h2><p>背景: 每次演练后, 通过CAT 的老年代明显的上涨, 再过1-2周, 会导致应用发生OOM<br>1.1 FullGC 怎么消除<br>1.1.1 增加jvm 的OOM 文件dump, -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;${DUMP_LOG_DIR}<br>1.1.2 主动去dump 文件 jmap -dump:live,format&#x3D;b,file&#x3D;test.hprof pid<br>1.1.3 将dump 下来的文件导入到MAT上<br>1.1.4 查看堆上的内存占用<br>1.1.5 发现有个对象占用特别高, 但是该对象也是需要常驻内存的, 该内存具体使用的是哪些客户端正在监听该配置文件, 每次配置推送的时候需要通过该对内存找到有哪些客户端正在使用该配置文件,从而将最新的版本好内容推送给客户端。<br>具体流程如下:</p>
<ol>
<li>根据变更配置文件去找到对应的监听机器, 其中数据结构如下</li>
<li>行是ip, 列是ConfigMeta, value 是Cache&lt;Listener, Listener&gt;&gt;,<br>3.1 出发点是有哪些IP 用了这个配置文件, 因此key 是IP, value 是configMeta, 然后每个缓存用的是Listener<br>3.2 从机器出发, 机器的Ip 是固定,  当机器重启后, IP 出现了漂移, ip1在应用A 读取的配置是a,b,c 经过漂移后, ip1在应用B 下面读取的配置是e，f,g. 其中a,b,c 的数据不会被删除掉, 从而导致内存越用越多<br>3.3 更改数据结构, 将监听列表从table 换成了一个map, 换成从配置文件的角度出发, k 是configMeta, value 是cache<Listener>。 每个配置文件有哪些客户端正在使用,</li>
</ol>
<h2 id="2-如果解决yong-gc-比较耗时比较高的问题"><a href="#2-如果解决yong-gc-比较耗时比较高的问题" class="headerlink" title="2. 如果解决yong gc 比较耗时比较高的问题"></a>2. 如果解决yong gc 比较耗时比较高的问题</h2><p>2.1 其中yong 区的比例是5<br>2.1.1  设置 MaxGCPauseMillis 到100ms<br>2.1.2 jdk1.8 默认的是新生代比列是5%, 调整G1NewSizePercent 的比列到30,<br>2.1.3 结果: 对上面设置了以后yong gc 时间还是在1秒左右<br>yong gc 的频率从原来的7几次降低到了3次, 然后此时yong gc 的频率下来了, 但是每次的时间从原来的 300 ms 变成了450ms左右<br>3. 其中总的耗时仍然为1分钟1.5 秒左右<br>4. 最后将g1 替换成了zgc<br>根据g1 的算法<br>G1 里面的yong gc采用标记-复制的算法<br>复制的时候用户线程和GC线程无法并行处理</p>
<ol>
<li><p>并发标记:在用户线程运行的同时, GC 线程 从root 对象出发, 标记会并发的标记存活对象, 这个过程是和用户同时进行的</p>
</li>
<li><p>初始标记:<br>2.1 初始标记: 从root 对象出发, 标记所有root 对象(需要STW), 时间比较短, 由于root 对象比较少<br>2.2 并发标记: 再从root 对象到可直接到达的对象 有哪些对象可达, 其中应用线程和GC线程可以同时去处理<br>2.3 再标记: 在并发2.2 中过程中发生变化的对象, 需要STW</p>
</li>
<li><p>确定回收集<br>进行最后的一次标记, 标记哪些对象需要回收, 需要STW</p>
</li>
<li><p>删选回收<br>采用复制算法, 会进行存活对象的移动<br>在次过程是需要STW的, 这个过程中为什么耗时比较高?????? 复制过程的耗时与对象的存活数量以及对象的复杂度成正比, 并且是没办法和用户线程去并行处理的，这个过程如果进行和用户线程进行并行处理, 会导致指针无法确认对象的问题<br>1.1 并发标记在初始标记之前的目的: 并发标记是用户线程和GC线程可以同时进行的, 但是在并发标记的时候可能会有新的对象被分配和标记, 因此在并发标记完成后, 再进行准确的初始标记, 用来获得准确的对象, 目的是可以准确的利用并发标记的优势, 将第GC 对程序的影响, 提高回收的准确率<br>G1 是将整个堆的空间分成多个大小的内存区域, 每个内存区域即可以是yong 区的一部分, 也有可能是old 区的一部分,其中我们指定的是4M<br>2.5 最终考虑升级到 zgc<br> zgc 相比较于g1 的gc 方式, 有了完全的提升<br>2.6 带来影响CPU 负载会有上升<br>GC 算法</p>
</li>
<li><p>不过 G1 为了解决 CMS 并发清理导致内存碎片化的问题，使用了复制算法转移对象，这样如果在转移过程中 GC 线程和用户线程并行，会导致指针无法准确定位对象的问题</p>
</li>
<li><p>zgc: 采用内存分区，使用染色指针和读屏障解决了复制算法并发转移对象导致的指针无法准确定位对象的问题<br>染色指针: 每个对象的指针在存储时都包含了附加的信息，用于表示对象的状态，比如是否是可达对象、是否需要被回收等<br>读屏障: 在 ZGC 中，读屏障用于捕获并记录正在被并发标记的对象引用，以便在后续的并发标记阶段中正确地标记这些对象。读屏障能够保证并发标记的准确性，防止对象在标记过程中被移动或修改引用关系导致的错误标记。</p>
</li>
</ol>
<p>原来是把GC 的标记放在了对象头上去, zgc 是将GC 的标记放在了指针中<br>M0,M1, Remapped<br>mmap 地址映射<br>读屏障<br>对象引用指针<br>  : 之前: GC 的标记信息放在对象头上去<br>  : 之后: GC 的标记信息直接放在引用指针上去<br>ZGC 过程:<br>  标记 -&gt; 转移<br>  完全做到了和用户进程的并发去处理<br>    并发标记: 使用读屏障的并发标记, 访问对象时插入特殊的屏障来跟踪对象的引用关系<br>    并发整理:<br>    并发引用重定位: 使用并发引用重定位去更新引用对象, 对象移动的时候, 可以正确更新对象的引用</p>
<p>  具体实现: 通过着色指针和读屏障技术<br>    读屏障技术: 解决对象发生转移, 对象地址未及时更新的情况, 读屏障在对象发生转移后, 会将读出来的指针更新到对象地址上去<br>      怎么判断是否发生移动, 通过着色指针<br>    空间换时间<br>      M0 , M1, Remapped</p>
<ol start="3">
<li>升级了zgc, 大概每次过1 个月左右, 应用发生了OOM, 在内部的监控上面发现应用机器的RSS内存从12G 慢慢上涨到15G, 导致应用被操作系统kill了, 这个是在使用g1 的时候没有发生过的<br>3.1 如何解决zgc 导致应用发生了OOM<br>通过pmap 去查看堆外内存的占用</li>
</ol>
<h1 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h1><h2 id="TCP-三次握手、四次挥手"><a href="#TCP-三次握手、四次挥手" class="headerlink" title="TCP 三次握手、四次挥手"></a>TCP 三次握手、四次挥手</h2><pre><code class="hljs">TCP 粘包
    TCP 面向连接的流式传输, 他将应用层的数据看成是一个连续的数据流, 不关心数据的边界, 因此在发送数据的时候, 可能将多个小的数据块合并成一个大的数据块, 从而导致发生了粘包
</code></pre>
<h2 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h2><p>三次握手（Three-way Handshake）其实就是指建立一个TCP连接时，需要客户端和服务器总共发送3个包。进行三次握手的主要作用就是为了确认双方的接收能力和发送能力是否正常、指定自己的初始化序列号为后面的可靠性传送做准备。实质上其实就是连接服务器指定端口，建立TCP连接，并同步连接双方的序列号和确认号，交换TCP窗口大小信息。<br>刚开始客户端处于 Closed 的状态，服务端处于 Listen 状态。<br>进行三次握手：<br>第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN(c)。此时客户端处于 SYN_SEND 状态。<br>其中SYN&#x3D;1，初始序号seq&#x3D;x，SYN&#x3D;1的报文段不能携带数据，但要消耗掉一个序号。<br>第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)。同时会把客户端的 ISN + 1 作为ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_RCVD 的状态。<br>在确认报文段中SYN&#x3D;1，ACK&#x3D;1，确认号ack&#x3D;x+1，初始序号seq&#x3D;y。<br>第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 ESTABLISHED 状态。服务器收到 ACK 报文之后，也处于 ESTABLISHED 状态，此时，双方已建立起了连接。<br>确认报文段ACK&#x3D;1，确认号ack&#x3D;y+1，序号seq&#x3D;x+1（初始为seq&#x3D;x，第二个报文段所以要+1），ACK报文段可以携带数据，不携带数据则不消耗序号。<br>发送第一个SYN的一端将执行主动打开（active open），接收这个SYN并发回下一个SYN的另一端执行被动打开（passive open）。<br>在socket编程中，客户端执行connect()时，将触发三次握手。<br><img src="/../img/tcp/tcp_start_connection.png" srcset="/img/loading.gif" lazyload alt="三次握手"></p>
<h3 id="为什么需要三次握手"><a href="#为什么需要三次握手" class="headerlink" title="为什么需要三次握手:"></a>为什么需要三次握手:</h3><p>  假设只有两次握手, 第一个发过去的包, 由于网络等原因, 滞后了,然后又重新发送了一个数据包给服务端,此时服务端收到了第二次发过来的数据包, 并进行了建立链接,进行了响应, 后面发送过去的第一个数据包也到了服务端,服务端进行了建立链接, 等到客户端数据传输,此时客户端由于没有数据需要传输会忽略这个请求, 而服务端一直等着数据的传输,造成资源的浪费。</p>
<h3 id="三次握手中传输数据可以不"><a href="#三次握手中传输数据可以不" class="headerlink" title="三次握手中传输数据可以不:"></a>三次握手中传输数据可以不:</h3><p>  在第三位次握手的时候可以进行发送数据, 在第一次握手的时候是不行的, 防止被恶意攻击,如果第一次就可以进行数据传输的话, 攻击者可以发送大量的SYN 包, 其中携带了大量的数据,由于服务端收到数据后要对数据进行解析处理, 造成服务端资源的浪费</p>
<h3 id="三次握手的目的"><a href="#三次握手的目的" class="headerlink" title="三次握手的目的:"></a>三次握手的目的:</h3><p>  交换初始化序列号和确认号, 为后面的可靠性传输做保证</p>
<h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><p>建立一个连接需要三次握手，而终止一个连接要经过四次挥手（也有将四次挥手叫做四次握手的）。这由TCP的半关闭（half-close）造成的。所谓的半关闭，其实就是TCP提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力。<br>TCP 的连接的拆除需要发送四个包，因此称为四次挥手(Four-way handshake)，客户端或服务器均可主动发起挥手动作。<br>刚开始双方都处于 ESTABLISHED 状态，假如是客户端先发起关闭请求。四次挥手的过程如下：</p>
<p>第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于 FIN_WAIT1 状态。<br>即发出连接释放报文段（FIN&#x3D;1，序号seq&#x3D;u），并停止再发送数据，主动关闭TCP连接，进入FIN_WAIT1（终止等待1）状态，等待服务端的确认。<br>第二次挥手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 +1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT 状态。<br>即服务端收到连接释放报文段后即发出确认报文段（ACK&#x3D;1，确认号ack&#x3D;u+1，序号seq&#x3D;v），服务端进入CLOSE_WAIT（关闭等待）状态，此时的TCP处于半关闭状态，客户端到服务端的连接释放。客户端收到服务端的确认后，进入FIN_WAIT2（终止等待2）状态，等待服务端发出的连接释放报文段。<br>第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。<br>即服务端没有要向客户端发出的数据，服务端发出连接释放报文段（FIN&#x3D;1，ACK&#x3D;1，序号seq&#x3D;w，确认号ack&#x3D;u+1），服务端进入LAST_ACK（最后确认）状态，等待客户端的确认。<br>第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 +1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过2MSL(2个报文最大生存周期)以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态，服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。其中MSL 的默认值60 秒<br>即客户端收到服务端的连接释放报文段后，对此发出确认报文段（ACK&#x3D;1，seq&#x3D;u+1，ack&#x3D;w+1），客户端进入TIME_WAIT（时间等待）状态。此时TCP未释放掉，需要经过时间等待计时器设置的时间2MSL后，客户端才进入CLOSED状态。<br>其中重传的超时事件和MSL 没关联<br>重传超时时间为1s + 2s + 4s + 8s 在120以内即可</p>
<p>收到一个FIN只意味着在这一方向上没有数据流动。客户端执行主动关闭并进入TIME_WAIT是正常的，服务端通常执行被动关闭，不会进入TIME_WAIT状态。<br><img src="/../img/tcp/tcp_finish_connection.png" srcset="/img/loading.gif" lazyload alt="四次挥手"></p>
<h3 id="为什么是四次挥手-三次可以不"><a href="#为什么是四次挥手-三次可以不" class="headerlink" title="为什么是四次挥手, 三次可以不"></a>为什么是四次挥手, 三次可以不</h3><p>  四次挥手是由于TCP 链接中, 发送方在结束他的发送后, 还能继续接受另外一端的数据, 在关闭连接的时候, 服务端收到了客户端发过来的FIN报文, 此时数据传输不一定完成了, 因此不可以直接对客户端响应一个ACK+FIN, 先对客户端进行响应一个ACK, 等需要发送的数据全都发完后, 再去发送一个FIN报文给发送方</p>
<h3 id="2MSL-作用是什么"><a href="#2MSL-作用是什么" class="headerlink" title="2MSL 作用是什么"></a>2MSL 作用是什么</h3><ol>
<li>保证客户端发送的最后一个ACK报文段能够到达服务端。<br>假设客户端发送完ACK后不去等待直接进行关闭,如果客户端在发送完ACK后不等待直接进行关闭，那么在网络原因等情况下，最后一个ACK报文段可能会丢失，导致服务器无法收到客户端发送的FIN-ACK的确认报文，从而无法正常进入关闭连接状态。此时，服务器会超时重传FIN-ACK报文，而客户端却已经关闭了连接。此时，服务器会收到客户端发送的RST报文，导致连接异常关闭。另外，如果客户端在2MSL时间内重新发送了一个新的连接请求，而这个连接请求的端口与之前的连接相同，服务器可能会收到之前连接的滞留报文，从而导致混淆。因此，2MSL的等待时间可以避免这种混淆的发生，保证连接的正常关闭。</li>
<li>防止“已失效的连接请求报文段”出现在本连接中。<br>客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段。</li>
</ol>
<h3 id="四次挥手的目的"><a href="#四次挥手的目的" class="headerlink" title="四次挥手的目的:"></a>四次挥手的目的:</h3><p>  通信双方可以正确的关闭并释放连接资源</p>
<h1 id="Mysql"><a href="#Mysql" class="headerlink" title="Mysql"></a>Mysql</h1><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="索引分类"><a href="#索引分类" class="headerlink" title="索引分类"></a>索引分类</h3><ol>
<li>逻辑功能分类:<br>1.1 普通索引:没有任何约束条件, 用户提高查询的效率<br>1.2 唯一索引: 在普通索引的基础上增加了唯一性约束的条件, 一张表里面可以有多个唯一索引<br>1.3 主键索引: 在唯一索引的基础上增加了不为空的约束条件, 一张表里面最多有一个主键索引</li>
<li>物理实现分类<br>2.1 聚集索引: 基于表的主键列的索引, 索引的叶子节点存储了实际的数据行, 一张表只能有一个聚集索引, 通常为主键索引<br>2.2 非聚集索引: 叶子节点存储了索引的值和一个指向数据实际存储位置的指针, 一个表可以有多个非聚集索引</li>
<li>字段个数<br>3.1 单一索引: 索引列为一个的索引<br>3.2 联合索引: 多个列组合在一起的索引</li>
</ol>
<h3 id="什么时候需要创建索引"><a href="#什么时候需要创建索引" class="headerlink" title="什么时候需要创建索引:"></a>什么时候需要创建索引:</h3><ol>
<li>字段的数值有唯一性的限制，比如用户名</li>
<li>频繁作为 WHERE 查询条件的字段</li>
<li>需要经常 GROUP BY 和 ORDER BY 的列</li>
<li>UPDATE、DELETE 的 WHERE 条件列</li>
</ol>
<h3 id="无需创建索引"><a href="#无需创建索引" class="headerlink" title="无需创建索引:"></a>无需创建索引:</h3><ol>
<li>如果表记录太少</li>
<li>where 条件中用不到的列</li>
<li>字段中如果有大量重复数据，也不用创建索引，比如性别字段</li>
</ol>
<h3 id="索引失效"><a href="#索引失效" class="headerlink" title="索引失效"></a>索引失效</h3><ol>
<li>如果索引进行了表达式计算、使用函数</li>
<li>在 WHERE 子句中，如果在 OR 前的条件列进行了索引，而在 OR 后的条件列没有进行索引</li>
<li>当我们使用 LIKE 进行模糊查询的时候，前面不能是 %</li>
<li>我们在使用联合索引的时候要注意最左原则</li>
</ol>
<h3 id="最左前缀匹配"><a href="#最左前缀匹配" class="headerlink" title="最左前缀匹配"></a>最左前缀匹配</h3><p>索引的最左前缀原则，可以是联合索引的最左N个字段。比如你建立一个组合索引（a,b,c），其实可以相当于建了（a），（a,b）,(a,b,c)三个索引，大大提高了索引复用能力。</p>
<h2 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h2><p>传统查询过程: MySQL 服务器先从存储引擎层获取满足条件的所有数据, 然后再根据条件在MySQL服务层去进行过滤, 这可能导致存储引擎层返回大量的不必要的数据到MySQL 的服务层, 增加了网络传输和数据的处理<br>索引下推通过将查询条件推送至存储引擎层进行过滤，可以在存储引擎层尽可能地提前过滤掉不符合条件的数据，从而减少从存储引擎返回到MySQL服务器层的数据量</p>
<h3 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h3><p>适用于某些查询条件在索引上进行处理的情况</p>
<h2 id="索引数据结构"><a href="#索引数据结构" class="headerlink" title="索引数据结构"></a>索引数据结构</h2><h3 id="hash表"><a href="#hash表" class="headerlink" title="hash表"></a>hash表</h3><p>不支持范围查询</p>
<h3 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h3><p>当数据量增多的情况下, 索引层数也会变高</p>
<h3 id="树"><a href="#树" class="headerlink" title="树"></a>树</h3><h4 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h4><p>在极端情况下，如果每次插入的数据都是最小或者都是最大的元素，那么树结构会退化成一条链表。查询数据是的时间复杂度就会是O(n)</p>
<h4 id="平衡二叉查找树（AVL树"><a href="#平衡二叉查找树（AVL树" class="headerlink" title="平衡二叉查找树（AVL树"></a>平衡二叉查找树（AVL树</h4><p>让每个节点的左右子树高度差不能超过 1。： 随着数据量的变多, 导致树的高度变高, 意味着磁盘的IO变化, 影响整体的查询销量</p>
<h4 id="B树"><a href="#B树" class="headerlink" title="B树"></a>B树</h4><p>叶子节点没有形成链表, 范围查询的时候需要多次随机IO, 性能较低</p>
<h4 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h4><p>B+树中的非叶子节点都不存储数据，而是只作为索引。由叶子节点存放整棵树的所有数据。而叶子节点之间构成一个从小到大有序的链表互相指向相邻的叶子节点，也就是叶子节点之间形成了有序的双向链表</p>
<h4 id="B树和-B-树对比"><a href="#B树和-B-树对比" class="headerlink" title="B树和 B+树对比"></a>B树和 B+树对比</h4><ol>
<li>更好的磁盘IO性能：B+树相较于B树，更适合在磁盘上进行存储和访问。B+树的内部节点（非叶子节点）只包含索引键值，而不存储实际数据，使得每个节点可以容纳更多的索引项。这意味着在同样的索引大小下，B+树的高度更低，减少了磁盘IO的次数，提高了数据访问的效率。</li>
<li>有序性和范围查询：B+树的叶子节点使用链表连接，使得B+树的叶子节点在磁盘上是有序的。这使得B+树在范围查询时更加高效，因为可以利用顺序访问特性，避免随机磁盘IO。而B树的叶子节点并没有进行链表连接，导致范围查询需要进行多次随机IO，性能较低。</li>
<li>更适合顺序访问：由于B+树的叶子节点形成了一个有序链表，对于顺序访问（如范围扫描、顺序遍历）的查询操作更加高效。相比之下，B树需要在内部节点和叶子节点之间进行来回跳跃，不利于顺序访问。</li>
<li>更适合大规模数据存储：B+树适用于大规模数据存储，因为它具有更高的数据密度和更好的IO性能。B+树的内部节点只存储索引键值，相较于B树，可以容纳更多的索引项，减少了树的高度，降低了存储开销。</li>
</ol>
<h3 id="使用B-树的原因"><a href="#使用B-树的原因" class="headerlink" title="使用B+树的原因"></a>使用B+树的原因</h3><ol>
<li>高效的查找性能：B+树是一种高效的平衡树结构，具有非常高效的查找性能。它的平均查找时间复杂度为O(logN)，能够快速地定位到目标数据的位置</li>
<li>高效的范围查询：B+树是一种有序树结构，能够非常高效地支持范围查询操作。它可以快速地找到满足条件的起始位置和结束位置，从而快速地定位到需要查询的数据。</li>
<li>内存友好：B+树的内部节点只存储索引信息，而不存储具体的数据，因此它的内存占用比较小。此外，B+树的叶子节点是顺序存储的，能够利用操作系统的预读特性，从而更加高效地利用内存。</li>
<li>支持高效的插入和删除：B+树的平衡特性使得它支持高效的插入和删除操作。对于插入操作，B+树只需要在叶子节点上插入新的数据即可。对于删除操作，B+树只需要删除叶子节点上的数据即可。</li>
</ol>
<h2 id="数据库回表"><a href="#数据库回表" class="headerlink" title="数据库回表"></a>数据库回表</h2><h3 id="回表定义-如果返回的列不在索引列中-就需要到主键索引或者数据页当中读取对应的数据行"><a href="#回表定义-如果返回的列不在索引列中-就需要到主键索引或者数据页当中读取对应的数据行" class="headerlink" title="回表定义: 如果返回的列不在索引列中,就需要到主键索引或者数据页当中读取对应的数据行"></a>回表定义: 如果返回的列不在索引列中,就需要到主键索引或者数据页当中读取对应的数据行</h3><p>回表会增加I&#x2F;O 开销和数据库的负载, 对数据库性能有负面影响</p>
<h3 id="如何降低回表"><a href="#如何降低回表" class="headerlink" title="如何降低回表"></a>如何降低回表</h3><ol>
<li>使用覆盖索引: 指的是索引查询返回了所有的列, 不需要回表既可以返回查询结果, 从而避免回表操作, 提高性能</li>
<li>合理设计索引: 查询所需的列尽可能包含在索引中, 从而减少回表的次数; 但是索引本身也是需要消耗存储空间和进行维护</li>
<li>使用查询缓存: 查询缓存指的是查询结果被写入磁盘前, 将查询结果缓存到内存当中, 下一次查询直接从内存当中去进行获取,避免回表的操作</li>
<li>优化查询语句: 尽可能将查询条件放在索引列上, 从而减少回表的次数</li>
</ol>
<h3 id="Mysql索引底层数据结构-为什么用B-树"><a href="#Mysql索引底层数据结构-为什么用B-树" class="headerlink" title="Mysql索引底层数据结构, 为什么用B+树"></a>Mysql索引底层数据结构, 为什么用B+树</h3><pre><code class="hljs">    B+树
    支持高效的搜索、稳定的搜索效率,支持范围查找、内存占用比较低
            ## 索引各个场景
            有5个字段 a,b,c,d,e,f,g,h 
            (a,b,c) 是一个联合索引, (d,e)是一个联合索引
            1. 创建联合索引(a,b,c)
            符合最左匹配原则 走索引
            explain select * from not_dice.testPerson where a = &quot;1&quot;;                               
            索引

            explain select * from not_dice.testPerson where b = &quot;1&quot;;
            全表
            explain select * from not_dice.testPerson where c = &quot;1&quot;;
            全表

            explain select * from not_dice.testPerson where a = &quot;1&quot; and b = &quot;1&quot;;
            索引
            explain select * from not_dice.testPerson where b = &quot;1&quot; and a = &quot;1&quot;;
            索引

            explain select * from not_dice.testPerson where a = &quot;1&quot; and c = &quot;1&quot;;
            索引下推
            explain select * from not_dice.testPerson where c = &quot;1&quot; and a = &quot;1&quot;;
            索引

            explain SELECT * FROM not_dice.testPerson where  c  = &quot;1&quot; and b = &quot;1&quot;;
            进行全表扫描了
            explain select * from not_dice.testPerson where a = &quot;1&quot; and b = &quot;1&quot; and c = &quot;1&quot;;
            索引
            explain select * from not_dice.testPerson where b = &quot;1&quot; and a = &quot;1&quot; and c = &quot;1&quot;;
            索引
            explain select * from not_dice.testPerson where c = &quot;1&quot; and b = &quot;1&quot; and a = &quot;1&quot;;
            索引
            explain select * from not_dice.testPerson where a = &quot;1&quot; and c = &quot;1&quot; and b = &quot;1&quot;;
            索引

            explain select * from not_dice.testPerson where a = &quot;1&quot; and c = &quot;1&quot; and b = &quot;1&quot; and d = &quot;1&quot;;
            索引

            explain select * from not_dice.testPerson where c = &quot;1&quot; and b = &quot;1&quot; and d = &quot;1&quot;;
            走d_f的索引
            explain select * from not_dice.testPerson where c = &quot;1&quot; and b = &quot;1&quot; and f = &quot;1&quot;;
            全表
</code></pre>
<h3 id="explain-中各个参数的作用"><a href="#explain-中各个参数的作用" class="headerlink" title="explain 中各个参数的作用"></a>explain 中各个参数的作用</h3><pre><code class="hljs">type: 连接类型从高效到低效依次为 system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL
key: 查询使用到的索引, 如果为null 则说明没有用到索引
rows: 扫描需要的行数, 越大 说明执行时间越长
filtered: where 条件过滤的百分比, 百分比越小 性能越高
Extra: 查询的额外信息
</code></pre>
<h3 id="慢sql"><a href="#慢sql" class="headerlink" title="慢sql"></a>慢sql</h3><pre><code class="hljs">慢sql 怎么定位  怎么优化sql 
    查看数据库的慢sql日志
    explain 去进行查询
优化sql:
    1. 优化数据库
        如果单表数据量超过了千万, 考虑将大表拆分成小表
        引入redis 等缓存
    2. 查询优化, 每次查询的时候只需要返回需要的列, 或者是进行分页优化
    3. 使用 explain 查看执行计划
    4. 使用索引
    5. select 的时候只选择需要的列
    6. 优化where 条件, 如避免使用子函数
    7. 优化join、group by 和 order by
        join 的时候确保on 条件上有索引, 减少表的连接
        order by 和 group by 上有索引
        order by 和 group by 先用where 条件对数据去进行过滤, 减少数据集的大小
</code></pre>
<h2 id="事物"><a href="#事物" class="headerlink" title="事物"></a>事物</h2><h3 id="事物的四大特性"><a href="#事物的四大特性" class="headerlink" title="事物的四大特性"></a>事物的四大特性</h3><pre><code class="hljs">    A 原子性: 事物时最小的执行单位, 不允许分割, 事物的原子性动作要么都执行成功, 要么都执行失败
        通过undo log 来保证 回滚日志   
    C 一致性: 事物之行前后, 数据保持一致
        持久性+原子性+隔离性
    I 隔离性: 并发访问数据库, 一个事物的执行不被其他事物所干扰
        通过 MVCC（多版本并发控制） 或锁机制
    D 持久性: 一个事物提交以后, 他对数据库中的数据改变是持久的
        redo log （重做日志）可以实现事物的持久性
</code></pre>
<h4 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h4><pre><code class="hljs">redo log: 事物的持久性
undo log: 实现了事物的原子性, 用于事物的回滚
bin log: server 生成的日志, 用于数据备份和主从复制
relay log 用于主从的数据同步

undolog 记录旧版本数据, redolog 记录新数据, 事物提交时, redo log会先标记事物为prepare状态, 再写入binlog, 最后将事物标记为commit 再进行提交
</code></pre>
<h4 id="一条事物update-的时候各个日志在什么时候会用到"><a href="#一条事物update-的时候各个日志在什么时候会用到" class="headerlink" title="一条事物update 的时候各个日志在什么时候会用到"></a>一条事物update 的时候各个日志在什么时候会用到</h4><pre><code class="hljs"> 3. 开启事物, 先将记录记录到undo log 中, 将更新的旧数据记录到undo log中
 4. innodb 开始更新记录, 先更新内存, 同时标记为脏页, 将记录写入redolog 中, 为了减少磁盘的IO, 由后台线程将脏页数据写入到磁盘中
 5. 更新完成后, 记录该语句对应的binlog, 此时binlog 会保存到binlog cache 中, 在事物提交的时候统一将所有binlog刷新的磁盘上
 6. 事物提交
        prepare 阶段 redolog 设置事物状态为prepare, 将redolog 刷盘
        commit 阶段 binlog刷盘, 将redolog设置为commit
</code></pre>
<h4 id="为什么需要两阶段提交"><a href="#为什么需要两阶段提交" class="headerlink" title="为什么需要两阶段提交"></a>为什么需要两阶段提交</h4><pre><code class="hljs">binlog 的两阶段提交
    目的: 
        防止数据丢失和保证数据的一致性
        保持binlog 和 redo log 的一致性: 确保数据库崩溃后, 保证事物提交的原子性和一致性
        防止数据丢失: 如果事物已经提交到了redo log，但是没有写入到binlog 中, 在系统奔溃后恢复, 由于binlog 没有该事物的记录, 从而影响主从复制
        防止数据不一致: 如果事物已经写入到binlog 但是没有写入到redolog， 奔溃后恢复的时候会导致binlog 中有记录, 但是实际数据库没有应用, 导致数据不一致
    过程
        1. prepare 阶段
            事物执行, innondb 会将事物的更改记录写入到redo log 中, 并将这些日志标记为 prepare 状态, 这意味着这些事物已经在操作了, 但是还未提交, 数据的修改刷新了内存中, 但是还没有刷新到磁盘
        2. commit 阶段
            写入binlog， 在事物提交之前, 将事物的更改写入到binlog 中, 此时binlog 记录的是最终持久化的数据, 此时redolog 中数据还是处于prepare 状态
            提交事物, 将redolog 中的事物标记为commit 状态, 一旦事物标记为commit, 数据页的修改会被刷新到磁盘上
    关键:
        顺序性和原子性:
            先记录redolog 的prepare 状态, 再写入binlog, 最后提交redo log， 防止奔溃恢复时出现数据的不一致
        奔溃恢复
            如果在写入binlog 后, 但是在提交redolog 之前的 发生了奔溃, mysql 在恢复时根据redolog 的prepare状态 和binlog 的记录继续完成提交, 确保事物的一致性
</code></pre>
<h3 id="事物隔离级别-什么是脏读、幻读"><a href="#事物隔离级别-什么是脏读、幻读" class="headerlink" title="事物隔离级别, 什么是脏读、幻读"></a>事物隔离级别, 什么是脏读、幻读</h3><pre><code class="hljs">    读未提交 允许读取到未提交的事物, 可能导致脏读、不可重复读、幻读
    读已提交 允许读取到事物已经提交的数据, 可以防止脏读, 可能导致不可重复读、幻读
    可重复读 对于多次读取的数据是一致的, 可以防止脏读、不可以重复读, 可能导致幻读
    串行化   事物的最高级别, 所有事物都是要串行的去执行, 可以防止脏读、幻读、不可重复读

    脏读: 读区到其他未提交事物的数据											
    不可重复读:  对于同一条数据, 在同一个事物中前后读区结果不一致						
    幻读: 在同一个事物中, 对于一个范围内的数据进行多次多去, 发现返回的数据结果行数不一致					
</code></pre>
<h3 id="可重复读为什么不能解决幻读"><a href="#可重复读为什么不能解决幻读" class="headerlink" title="可重复读为什么不能解决幻读"></a>可重复读为什么不能解决幻读</h3><pre><code class="hljs">    读已提交: 事物中只能读取到其他已提交的数据
        通过在语句语句执行之前生成一个read view, 因此可以保证每次读取的时候可以读取到其他事物提交后的数据
    可重复读 是通过在启动事物时生成一个read view, 整个事物期间都在用这个read view, 因此没办法防止幻读, 因为整个事物期间基于的视图时一样的
</code></pre>
<h1 id="java-基础"><a href="#java-基础" class="headerlink" title="java 基础"></a>java 基础</h1><h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><h3 id="java-创建线程的方式"><a href="#java-创建线程的方式" class="headerlink" title="java 创建线程的方式"></a>java 创建线程的方式</h3><pre><code class="hljs">    Thread
        继承 Thread 实现run方法, 并且通过 start() 来开始执行
    Runnable
        实现runnable 接口, 
    Callable 和 Future
    使用 Executor 线程池来管理线程
</code></pre>
<h3 id="为什么要用线程池"><a href="#为什么要用线程池" class="headerlink" title="为什么要用线程池"></a>为什么要用线程池</h3><pre><code class="hljs">    有大量异步任务的时候提升性能
    通过一系列参数对线程资源进行管理
线程正在做一个耗时高的任务, 做到一半怎么进行停止 ===========

常用线程池
</code></pre>
<h3 id="线程池核心参数介绍-有哪些"><a href="#线程池核心参数介绍-有哪些" class="headerlink" title="线程池核心参数介绍 有哪些"></a>线程池核心参数介绍 有哪些</h3><pre><code class="hljs">核心线程数、最大线程数、超时时间、空闲线程存活的时间单位、用于保存等待执行任务的队列、用于创建线程的工厂、当任务队列满了以后, 用于何种策略去
</code></pre>
<h3 id="线程池为啥先放阻塞队列-再创建非核心线程"><a href="#线程池为啥先放阻塞队列-再创建非核心线程" class="headerlink" title="线程池为啥先放阻塞队列, 再创建非核心线程"></a>线程池为啥先放阻塞队列, 再创建非核心线程</h3><pre><code class="hljs">1. 提高线程利用率
    核心线程数较少的情况下可以处理所有任务, 而无需频繁的创建和销毁线程, 当只有核心线程数都在忙碌, 并且队列中的任务到达一定的数量的时候, 才会去创建非核心线程数, 可以减少频繁的创建和销毁, 提升线程的利用率
2. 减少系统资源开销
    在高并发的场景下线程的创建和销毁会带来较大的开销, 因此优先使用核心线程数, 再将任务加入到阻塞队列中, 尽可能少的创建非核心线程数, 从而减少系统的资源开销
3. 防止过度创建线程
    如果在任务到达的时候, 直接创建线程, 可能导致线程快速增长, 最终耗尽资源, 通过将任务加入到阻塞队列中, 可以平衡任务的负载, 只有当队列满了, 并且核心线程数无法处理所有的任务的时候, 才创建额外的非核心线程, 防止系统过载
4. 保证任务的有序
    可以确保任务按照一定的顺序执行, 在任务过多时才启用, 确保线程池在高负载的时候可以处理任务
</code></pre>
<h3 id="线程池执行异常了-该线程会怎能样-怎么在主线程中捕获该异常"><a href="#线程池执行异常了-该线程会怎能样-怎么在主线程中捕获该异常" class="headerlink" title="线程池执行异常了, 该线程会怎能样, 怎么在主线程中捕获该异常"></a>线程池执行异常了, 该线程会怎能样, 怎么在主线程中捕获该异常</h3><pre><code class="hljs">    execute()
        如果执行线程没有进行catch 捕获, 会导致worker 线程被终止, 同时默认情况下没有配置afterExecute 方法的, 如果当前worker 小于核心线程数, 则会创建一个新的 worker 线程去进行替换, 新创建的worker 是非核心的
    submit()
        异常会被封装在返回的future 中, 当对象调用future.get 的时候获取到对应的异常
</code></pre>
<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><h3 id="乐观锁、悲观锁"><a href="#乐观锁、悲观锁" class="headerlink" title="乐观锁、悲观锁"></a>乐观锁、悲观锁</h3><ol>
<li>悲观锁: 假设并发访问冲突会导致数据不一致, 在使用悲观锁的情况下, 线程访问共享资源会事先获得锁, 确保可以独占的进行, 而其他线程则会被阻塞, 悲观锁适用于数据修改比较频繁, 并发冲突比较高的场景下</li>
<li>乐观锁: 假设并发冲突较少发生, 多个线程可以同时进行读写操作而不去加锁, 乐观锁的实现是通过版本号或者时间戳来判断数据是否被进行了修改, 如果一个线程要更新数据, 会先获取当前版本号, 如果当前版本号发生了变化, 则说明其他线程进行了修改, 如果当前版本号没有发生变化, 说明可以进行修改</li>
</ol>
<h2 id="6-ReentrantReadWriteLock-使用场景"><a href="#6-ReentrantReadWriteLock-使用场景" class="headerlink" title="6 ReentrantReadWriteLock 使用场景"></a>6 ReentrantReadWriteLock 使用场景</h2><p>读多, 写少的情况下<br>读操作的并发性:<br>    只有没有写操作, 多个线程同时进行读取数据, 在读多写少的场景下面可以显著提高读取的性能<br>写操作的独占性:<br>    写操作是独占的, 当一个线程在运行的时候, 其他所有的读取和写都会被阻塞, 直到写操作完成。这样可以保证数据的一致性, 防止读线程读取到错误不完整的数据。<br>使用场景:<br>    读多写少的场景, 例如: 缓存, 配置读取<br>读锁为共享锁，写锁为排他锁<br>如何保证安全性:<br>    读锁: 在进行更新数据的时候, 只有所有读锁都释放了以后, 写锁才可以被获取到<br>    写锁: 写锁获取时, 会检查是否有读锁的存在, 如果有读锁的存在, 写锁会被阻塞, 直到所有的读锁都被释放, 一旦有线程拿到写锁, 会阻止任何新的读锁和其他写锁的获取</p>
<p>锁的使用场景:<br>    读写锁:<br>        读多写少的, 高并发的情况下可以提高读取的效率<br>    客观锁:<br>        通过版本号机制, 适用于冲突较少, 并发较低的情况下<br>    synchronized:<br>        简单的并发控制, 例如在方法上或者对象上控制并发<br>    ReentrantLock:<br>        可以手动的管理锁的粒度, 可中断锁, 可对锁进行超时处理</p>
<h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><h5 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h5><p>适用于读操作比较多, 并发冲突比较少的场景</p>
<h5 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h5><p>适用于写操作操作比较多, 并发冲突比较多的场景</p>
<h3 id="synchronized、Lock"><a href="#synchronized、Lock" class="headerlink" title="synchronized、Lock"></a>synchronized、Lock</h3><h4 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h4><h4 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h4><h4 id="ReadLock、writeLock"><a href="#ReadLock、writeLock" class="headerlink" title="ReadLock、writeLock"></a>ReadLock、writeLock</h4><h5 id="使用场景-1"><a href="#使用场景-1" class="headerlink" title="使用场景"></a>使用场景</h5><h6 id="ReadLock"><a href="#ReadLock" class="headerlink" title="ReadLock:"></a>ReadLock:</h6><ol>
<li>并发读取, 当多个线程需要读取共享资源的时候, 多个线程可以同时获取锁资源</li>
<li>读多写少, 当共享资源的读取次数远远超过写操作的时候, 允许多个读可以提高并发性能</li>
</ol>
<h6 id="WriteLock"><a href="#WriteLock" class="headerlink" title="WriteLock:"></a>WriteLock:</h6><ol>
<li>数据修改, 当一个线程要对共享资源去进行修改的时候, 需要获取WriteLock, 写锁会阻塞其他的读锁和写锁, 确保只有一个线程独占获取锁资源</li>
<li>数据一致性保护, 当涉及到多个步骤的写锁时, 可以通过WriteLock来保证多个步骤的原子性</li>
</ol>
<h3 id="乐观锁-悲观锁"><a href="#乐观锁-悲观锁" class="headerlink" title="乐观锁 悲观锁"></a>乐观锁 悲观锁</h3><pre><code class="hljs">    并发冲突低的情况下 使用乐观锁
        并发冲突高的时候使用乐观锁, 会导致重试的频率增加, 增加系统的响应时间和资源消耗, 给数据库增加压力, 导致系统的复杂性变高
    并发冲突高的情况下是用悲观锁,
        并发冲突低的时候使用悲观锁导致资源的浪费.
</code></pre>
<h3 id="synchronized-cas-lock"><a href="#synchronized-cas-lock" class="headerlink" title="synchronized cas lock"></a>synchronized cas lock</h3><pre><code class="hljs">    jdk1.6之前的, 将锁信息放在对象头的Monitor 中, 通过操作系统的Mutex Lock 来实现, 1.7 1.8 以后通过锁升级、锁优化来解决这个问题, 锁升级有无锁, 偏向锁, 轻量级锁, 重量级锁
    lock 是基于aqs 来进行实现的
</code></pre>
<h3 id="synchronized-和-reentrantLocak-区别"><a href="#synchronized-和-reentrantLocak-区别" class="headerlink" title="synchronized 和 reentrantLocak 区别"></a>synchronized 和 reentrantLocak 区别</h3><pre><code class="hljs">    相同点:
        可重入锁, 都是悲观锁
        性能差不多
    不同点:
        synchronized 是java 中的关键字, 是语言级别的 reentrantLocak 依赖于AQS 实现,是java 中的一个类
        reentrantLocak 可实现等待中断
        reentrantLocak 可实现公平和非公平锁
    公平锁和非公平锁场景
        默认是非公平锁, 非公平锁降低了线程的上下文切换, 具有更高的吞吐量, 降低了锁竞争导致的延迟, 适用于短暂的任务,并发高的情况下
        公平锁场景: 对资源的执行顺序具有严格要求的, 业务逻辑处理要求具有公平性的
</code></pre>
<h3 id="死锁判定"><a href="#死锁判定" class="headerlink" title="死锁判定"></a>死锁判定</h3><pre><code class="hljs">1. 互斥条件: 资源在某个时刻只能由一个线程占用, 如果一个线程占用了一个资源, 其他线程不能访问该资源
2. 持有并等待: 线程已经持有了一个资源, 但又请求新的资源, 并且由于新资源被其他线程占用而陷入等待, 同时不会释放自己所占用的资源
3. 不剥夺条件: 资源不能强制从持有他的线程中剥夺, 只有持有该资源的线程在完成任务后主动释放
4. 循环等待条件: 存在一个线程, 链中的每个线程都在等待下一个线程持有的资源, 从而形成一个循环等待的局面
</code></pre>
<h3 id="oom-怎么排查"><a href="#oom-怎么排查" class="headerlink" title="oom 怎么排查"></a>oom 怎么排查</h3><pre><code class="hljs">1. 使用jmap 去对内存进行dump
2. 启动的时候增加gc 日志查看
    2.1 如果是full GC 很频繁, 说明老年代空间不足, 或者是老年代内存被填满了
    2.2 如果是full GC 很长, 说明GC 无法及时的释放内存
    2.3 查看每次GC 后堆内的使用情况, 判断是否有内存持续增长无法回收, 
3. 查看dump 下来的内存文件
    3.1 通过MAT 查看 大对象、对象的引用链路、
4. 如果是堆内存不足
    4.1 尝试增加堆内存
    4.2 针对频繁的full gc, 或者是yong gc 对内存占用分析, 调整比例
    4.3 对频繁创建和销毁的对象可以通过polling, 减少不必要的重复创建
    4.2 更换GC 算法
</code></pre>
<h2 id="ThreadLocal-原理"><a href="#ThreadLocal-原理" class="headerlink" title="ThreadLocal 原理"></a>ThreadLocal 原理</h2><pre><code class="hljs">    每个线程维护一个叫threadLocals 的 ThreadLocalMap,每个线程维护自己的ThreadLocalMap, threadLocalMap 中其中key 是ThreadLocal 对象, value 
    是要保存的值, 多个threadLocal 通过ThreadLocal 对象的hash值 来定位到table 中的位置,
    ThreadLocal 实例被创建的对象持有, ThreadLocal 值也是被线程实例持有, 都是位于堆上的

    由于ThreadLocal 保存的时候把自己当作key 防盗了ThreadLocalMap 中, 同时是弱引用的, 由于发生了GC的时候, 会被回收, 但是由于线程一直运行, value 
    是无法得到回收的,  在线程池中, 容易造成内存泄漏, 容易导致ThreadLocalMap 中的key 变为了null, 但是由于threadLocal线程还是一直在运行的, 
    这个value 一直得不到回收, 导致内存泄漏, 需要在最后使用的地方加上remove, 

    如果Entry 中的key 是强引用的, 容易导致key 也内存泄漏
    如果k v 都是弱引用的话, 会导致获取值的不确定性

    fastThreadLocal 通过InternaleThreadLocal 来避免了内存泄漏, 通过数组的索引可以直接访问数据, 线程退出的时候, 会自动进行清理与该线程相关的FastThreadLocal 信息
</code></pre>
<h2 id="AQS-原理-线程入队列-出队列-唤醒机制-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D"><a href="#AQS-原理-线程入队列-出队列-唤醒机制-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D" class="headerlink" title="AQS 原理, 线程入队列 出队列 唤醒机制			&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;"></a>AQS 原理, 线程入队列 出队列 唤醒机制			&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</h2><pre><code class="hljs">    查看 int 的 volatile state 属性
    入队列
        CAS 尝试获取锁, 获取锁成功则将当前线程为占用了锁资源
        获取锁资源
        2.1 尝试获取锁资源
        2.1.1 查看当前锁是否被占据
        2.1.2 如果没有的话则通过CAS 尝试获取锁, CAS 成功则将当前线程占用了锁资源
        2.1.3 如果本来就是当前线程拿到了锁的资源, 则进行可重入计数+1, 更新当前锁的重入个数
        2.2 获取当前锁资源失败, 则进行入队列等待
        2.2.1 创建一个等待的 Node 节点, 通过CAS 的方式加入到队尾节点
        2.2.1.1 如果上一步CAS 入队尾失败了, 则进行自旋的方式加入到队尾
        2.3 尝试入队列
        2.3.1 如果前驱节点为头节点, 则尝试获取锁
        2.3.2 获取锁成功则将当前节点设置为头节点
        2.3.3 如果当前节点不是头节点，或者是获取锁失败
        2.3.4 获取前驱节点的状态, 如果状态为SIGINAL(-1) 则挂起
        2.3.5 当前前驱节点状态大于0, 说明前驱节点取消了排队, 从后向前去找一个新的前驱节点
        2.3.6 当前前驱节点状态为0, 通过 CAS 将当前状态设置为-1
    出队列
        完全释放了锁, 对后续节点进行唤醒
            2.1 如果头节点不为空，或者是头节点的状态不是初始状态, 则解除线程挂起
            2.1.1 头节点为空, 说明是第一个节点入队列,
            2.2 对线程解除挂起
            2.2.1 获取头节点的状态值
            2.2.2 如果当前头节点状态值小于0, 则将状态值CAS设置为0
            2.2.3 获取头节点的下一个节点, 如果下一个节点为空, 或者下个节点状态是被cancel 的, 选择从后向前找到第一个waitStatus&lt; 0的
            2.2.3.1 选择从后向前找, 而不是从前向后找, 是因为可能有节点是无效的或者是cancelled的状态
            2.2.4 找到节点后, 进行唤醒
</code></pre>
<h3 id="volatile-关键字原理"><a href="#volatile-关键字原理" class="headerlink" title="volatile 关键字原理"></a>volatile 关键字原理</h3><pre><code class="hljs">    保证可见性
    防止重排序
    happens before 规则
        对于一个volatile 变量写的操作happens-before 任意线程对该变量的读操作, 确保了volatile的可见性
</code></pre>
<h2 id="hashMap"><a href="#hashMap" class="headerlink" title="hashMap"></a>hashMap</h2><h3 id="hashMap-默认是0-75"><a href="#hashMap-默认是0-75" class="headerlink" title="hashMap 默认是0.75"></a>hashMap 默认是0.75</h3><pre><code class="hljs">    扩容因子: 
        更小的话 是更容易创建数组, 占用更大的空间, 会频繁的发生扩缩容
        更大的话降低了内存的浪费, 增加查找的插入、删除的复杂度
    0.75 是一个平衡的结果
</code></pre>
<h3 id="hashMap-中扩容因子是2倍"><a href="#hashMap-中扩容因子是2倍" class="headerlink" title="hashMap 中扩容因子是2倍"></a>hashMap 中扩容因子是2倍</h3><pre><code class="hljs">扩大两倍是为了保证hash 函数的分布均匀, 扩大的三倍后, 可能会导致很多hash 值在同一个buckt 中, 从而降低了查询的效率, 扩大两倍是为了保证hash 分布均匀, 从而提高查询效率
扩容到3倍不行 会导致hash 冲突增加, 查询效率变低,
</code></pre>
<h3 id="list-为1-5倍-hashMap-扩容为2倍的原因"><a href="#list-为1-5倍-hashMap-扩容为2倍的原因" class="headerlink" title="list 为1.5倍, hashMap 扩容为2倍的原因"></a>list 为1.5倍, hashMap 扩容为2倍的原因</h3><pre><code class="hljs">1. arrayList 是基于动态数组的 扩容是为了平衡内存利用率和性能, 扩小了可能导致频繁的扩容, 扩大的可能导致内存空间的浪费
2. hashMap是基于散列表, 扩容需要确保hash 散列的均衡性, 在计算hash 的时候只需要取模操作就可以了, 扩容为2倍可以减少冲突, 重新计算的时候可以直接利用位运算进行分布
</code></pre>
<h3 id="hashMap-中链表插入数据的过程"><a href="#hashMap-中链表插入数据的过程" class="headerlink" title="hashMap 中链表插入数据的过程"></a>hashMap 中链表插入数据的过程</h3><pre><code class="hljs">1. 1.8 之前头插法
2. 1.8 以后尾插法
    hashMap 采用尾插法的目的是可以减少多线程下的竞争,减少链表结果的变动
</code></pre>
<h3 id="hashMap-在1-8-后使用红黑树的的目的"><a href="#hashMap-在1-8-后使用红黑树的的目的" class="headerlink" title="hashMap 在1.8 后使用红黑树的的目的"></a>hashMap 在1.8 后使用红黑树的的目的</h3><pre><code class="hljs">1. 解决链表性能问题, 在发生严重冲突的时候, 健值会以链表的形式保存, 链表的查找删除复杂度位O(n), 当链表很长的时候, 性能会显著下降
2. 提高查找效率, 红黑树的增加、查找、删除的复杂度位O(logn)
</code></pre>
<h2 id="hashTable-和-concurrentHashMap"><a href="#hashTable-和-concurrentHashMap" class="headerlink" title="hashTable 和 concurrentHashMap"></a>hashTable 和 concurrentHashMap</h2><pre><code class="hljs"> 1. 都是并发安全的, hashTable 的所有方法都是通过synchronized 来进行实现的,concurrentHashMap 通过分段锁来实现的
 2. concurrentHashMap 读的时候 通过volatile 来保证安全性
 3. concurrentHashMap put
     3.1 通过cas 和 synchronized 来保证安全性
     3.1.1 计算hash 值
     3.1.2 如果要插入的位置是个null 节点, 则直接在该位置插入, 如果不是空节点, 则进行链表采用尾插法, 或者是红黑树插入
</code></pre>
<h2 id="动态代理的过程"><a href="#动态代理的过程" class="headerlink" title="动态代理的过程"></a>动态代理的过程</h2><pre><code class="hljs">jdk 动态代理通过Proxy 类生成一个代理对象, 这个代理对象实现了目标类的接口, 并将方法调用委托给InvocationHandler 来进行处理
1. 接口定义
    1.1 创建一个自定义的接口
2. 实现InvocationHandler 接口
    2.1 这个类的invoke 方法 会处理所有代理类上的方法调用
            proxy :动态生成的代理类
            method : 与代理类对象调用的方法相对应
            args : 当前 method 方法的参数
3. 创建代理类
    MyInterface target = new MyInterfaceImpl();
    // 创建InvocationHandler
    MyInvocationHandler handler = new MyInvocationHandler(target);
        	loader :类加载器，用于加载代理对象。
            interfaces : 被代理类实现的一些接口；
            h : 实现了 InvocationHandler 接口的对象；
    // 创建代理实例
    MyInterface proxyInstance = (MyInterface) Proxy.newProxyInstance(
        target.getClass().getClassLoader(),
        target.getClass().getInterfaces(),
        handler
    );
4. 调用代理类的方法
</code></pre>
<h3 id="操作字节码的过程"><a href="#操作字节码的过程" class="headerlink" title="操作字节码的过程"></a>操作字节码的过程</h3><pre><code class="hljs">1. asm: 允许直接生成、分析、修改java 字节码
2. cgLib: 通过生成目标类的子类并覆盖父类的方法来创建代理对象, 因此可以代理普通类, 不仅仅是接口, CGLib 使用asm 来生成字节码
spring 在目标类实现任何的实现接口的时候, 默认使用cgLib 来处理, 如果类实现了一个或者多个接口的时候, 采用JDK 动态代理
</code></pre>
<h3 id="字节码增强"><a href="#字节码增强" class="headerlink" title="字节码增强:"></a>字节码增强:</h3><pre><code class="hljs">    cglib 通过生成目标类的子类的方法来创建代理对象
            定义一个类；
            自定义 MethodInterceptor 并重写 intercept 方法，intercept 用于拦截增强被代理类的方法，和 JDK 动态代理中的 invoke 方法类似；
            通过 Enhancer 类的 create()创建代理类；
        cglib 不可以代理声明为final 类型的类和方法
    asm 是可以直接修改字节码的
其中spring 默认是使用clglib
</code></pre>
<h2 id="jvm"><a href="#jvm" class="headerlink" title="jvm"></a>jvm</h2><h3 id="new-一个对象-过程是什么样子的-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D"><a href="#new-一个对象-过程是什么样子的-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D" class="headerlink" title="new 一个对象, 过程是什么样子的					&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;"></a>new 一个对象, 过程是什么样子的					&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</h3><pre><code class="hljs">    类加载, 并检查这个符号代表的引用是否被加载解析过
        类加载机制(双亲委派)
    分配内存
        指针碰撞法 
            =》标记清除
        空闲列表
            =&gt; 标记整理
    初始化零值
    设置对象头
    执行init 方法
锁优化
    锁升级
    锁消除
        检查到共享数据不可能存在竞争的, 执行锁消除
</code></pre>
<h2 id="内存模型"><a href="#内存模型" class="headerlink" title="内存模型"></a>内存模型</h2><ol>
<li>共享的:堆、方法区(metaspace)、直接内存</li>
<li>私有的: 程序技术器, 虚拟机栈、本地方法栈</li>
</ol>
<h2 id="创建对象的过程"><a href="#创建对象的过程" class="headerlink" title="创建对象的过程"></a>创建对象的过程</h2><h3 id="类加载机制"><a href="#类加载机制" class="headerlink" title="类加载机制"></a>类加载机制</h3><p>创建对象的过程和类加载的过程是Java程序执行的两个不同阶段。</p>
<p>创建对象的过程：创建对象是指在程序中通过关键字”new”来实例化一个类，从而在内存中分配一块空间用于存储对象的实例。创建对象的过程包括以下几个步骤：<br>a. 类加载：如果该类还没有被加载，首先需要进行类加载，即将类的字节码加载到内存中。<br>b. 分配内存：在堆内存中分配一块空间，用于存储对象的实例。<br>c. 初始化：对对象的实例进行初始化，设置成员变量的默认值。<br>d. 调用构造方法：执行类的构造方法，对对象进行初始化。</p>
<p>类加载的过程：类加载是指将类的字节码文件加载到JVM中，并在内存中生成对应的Class对象，从而可以通过这个Class对象获取类的信息和创建类的实例。类加载过程包括以下几个阶段：<br>a. 加载：查找并加载类的字节码文件。<br>b. 验证：验证字节码文件的格式是否正确，是否有安全性问题。<br>c. 准备：为类的静态变量分配内存，并设置默认值。<br>d. 解析：将类的符号引用转换为直接引用。<br>e. 初始化：执行类的静态初始化代码块，对静态变量进行赋值。</p>
<h3 id="双亲委派"><a href="#双亲委派" class="headerlink" title="双亲委派"></a>双亲委派</h3><p>如，当一个类需要被加载时，首先会由最顶层的启动类加载器（Bootstrap ClassLoader）尝试加载，如果找不到则会依次由扩展类加载器（Extension ClassLoader）和应用程序类加载器（Application ClassLoader）尝试加载。只有当三者都无法加载时，才会由用户自定义的类加载器尝试加载</p>
<ol>
<li>双亲委派好处:1. 安全: 防止恶意代码去篡改核心库；2. 类的一致性: 保证层次结构, 相同的类只加载一次<br>1.1 什么情况下要打破双亲委派: 热更新<br>tomcat 要打破的原因是<br>Tomcat打破双亲委派模式是因为在Web应用中，每个Web应用都是一个独立的Java应用，拥有自己的类加载器，且需要加载各自的类和依赖库。<br>tomcat 的父类加载器是StandardClassLoader 会导致类冲突、破坏应用的隔离</li>
</ol>
<h3 id="java-内存区域有哪些"><a href="#java-内存区域有哪些" class="headerlink" title="java 内存区域有哪些"></a>java 内存区域有哪些</h3><pre><code class="hljs">    程序计数器
        线程私有的, 当前线程正在执行的行号指示器
    虚拟机栈
        线程私有的, 随着线程的创建而创建, 每个方法的调用都将对应的操作进行入栈和出栈
    本地方法栈
        线程私有的, 执行native 方法用到的
    堆
        线程共享的 
    metaspace 方法区
        线程共享的
</code></pre>
<h3 id="如果判断死亡对象-GC-Roots-有哪些，空间分配担保是什么。"><a href="#如果判断死亡对象-GC-Roots-有哪些，空间分配担保是什么。" class="headerlink" title="如果判断死亡对象, GC Roots 有哪些，空间分配担保是什么。"></a>如果判断死亡对象, GC Roots 有哪些，空间分配担保是什么。</h3><pre><code class="hljs">    虚拟机栈中引用对象
    本地方法栈中引用对象
    方法区中静态属性引用的对象
    方法区中常量引用的对象
    所有被同步持有的锁
    空间分配担保: Minor GC 之前, 老年代本身还有空间容纳新生代所有剩余对象
</code></pre>
<h3 id="为什么要用分代收集"><a href="#为什么要用分代收集" class="headerlink" title="为什么要用分代收集"></a>为什么要用分代收集</h3><pre><code class="hljs">1. 大多数对象的存活时间比较短, 少数对象存活时间比较长, 可以减少GC 扫描的范围, 提升GC 的效率
2. 不同年代的GC 算法采取不一样的, 年轻代 标记复制算法, 老年代, 标记清除 或者是标记整理
</code></pre>
<h3 id="G1-收集器的优缺点，内部实现"><a href="#G1-收集器的优缺点，内部实现" class="headerlink" title="G1 收集器的优缺点，内部实现"></a>G1 收集器的优缺点，内部实现</h3><h2 id="spring"><a href="#spring" class="headerlink" title="spring"></a>spring</h2><h3 id="spring-注解的依赖"><a href="#spring-注解的依赖" class="headerlink" title="spring 注解的依赖"></a>spring 注解的依赖</h3><pre><code class="hljs">需要实现的bean 接口如下: BeanPostProcessor, ApplicationContextAware, BeanClassLoaderAware
    BeanPostProcessor 允许实例化之后以及bean 初始化方法之前调用
    ApplicationContextAware  在初始化的时候获取到Spring 上下文的引用, 从而可以访问容器中其他的bean或者执行的相关操作,
    BeanClassLoaderAware 提供classLoader的访问能力, 使得bean 可以动态加载资源

    BeanClassLoaderAware -&gt; ApplicationContextAware -&gt; PropertyPlaceholderConfigurer -&gt; BeanPostProcessor
</code></pre>
<h3 id="bean-生命周期"><a href="#bean-生命周期" class="headerlink" title="bean 生命周期"></a>bean 生命周期</h3><pre><code class="hljs">    实例化: 根据@Configuration 或者是扫描到的@Component 等注解识别需要实例化的bean, 通过反射去调用无参构造函数去进行实例化
    依赖注入: 将属性设置到实力化对象中
    Aware 接口处理: 如果实现了beanNameAware 则调用setName 传递bean 名称, 实现BeanFactoryAware 则调用setBeanFactory, 实现ApplicationContextAware 则调用setApplicationContext 传递ApplicationContext
    BeanPostProcessor 中的 postProcessBeforeInitialization
    初始化: @PostConstruct 会调用初始化后的一些行为,  如果接口实现了 InitializingBean 的 afterPropertiesSet, 则会调用afterPropertiesSet
    BeanPostProcessor 中的 postProcessAfterInitialization
    准备就绪, 可以准备使用
</code></pre>
<h3 id="Spring-的IOC-和-AOP"><a href="#Spring-的IOC-和-AOP" class="headerlink" title="Spring 的IOC 和 AOP"></a>Spring 的IOC 和 AOP</h3><pre><code class="hljs">    IOC 指的是控制反转, 将对象的创建和管理委托给spring容器, 而不是直接有应用程序代码直接控制
    AOP 指的是允许不修改代码的情况下, 方便的添加或者修改横切关注点
        AOP 一般通过动态代理来进行实现
            jdk 自身的动态代理: 基于java 的反射来进行实现的
            cglib 
</code></pre>
<h3 id="springBoot-提供出来的扩展点有哪些"><a href="#springBoot-提供出来的扩展点有哪些" class="headerlink" title="springBoot 提供出来的扩展点有哪些"></a>springBoot 提供出来的扩展点有哪些</h3><pre><code class="hljs">1. ApplicationContextInitializer
    可以在spring 应用程序上下文刷新之前进行配置, 可以获取到Environment的信息
2. 从spring 容器中获取到bean 对象
    2.1 FactoryBean: beanFactory 是bean 工厂, factoryBean 是一种bean 的类型, 当容器注入的class 类型是FactoryBean 类型的时候, 最终生成bean 是通过FactoryBean 的getObject 获取到的
3. 实现自定义的HandlerInterceptor 拦截器
4. ApplicationContextAware 获取bean 对象
5. ApplicationListener 监听事件的
6. BeanPostProcessor bean 初始化前后做一些事情

    
</code></pre>
<h3 id="Autowired和-Resource"><a href="#Autowired和-Resource" class="headerlink" title="@Autowired和@Resource"></a>@Autowired和@Resource</h3><pre><code class="hljs">相同点: 
    都可以作为属性注入修饰, 在接口只有单一实现类的时候, 两个注解的修饰情况相同
不同点: 
    1. @Resource 是jdk 原生的, @Autowired 是spring 引入的注解
    2. @Autowired 默认按照byType 自动配置,(优先根据接口类型去匹配并注入bean)
         @Resource 是byName 进行配置的 (优先根据bean 的名字去进行匹配, 例如类名)
        当一个接口有多个类的时候, @Autowired 和 @Resource 都是需要通过名称才可以正确匹配到对应的name, @Autowired 可以通过@Qualified 来进行显示制定, @Resource 可以通过name 进行显示制定
    3. @Autowired 支持在构造函数、方法、字段、和参数上进行使用, @Resource 主要用于字段和方法上的注入, 不支持在构造函数或者是参数上进行使用
</code></pre>
<h1 id="ZK"><a href="#ZK" class="headerlink" title="ZK"></a>ZK</h1><h2 id="zk-投票过程"><a href="#zk-投票过程" class="headerlink" title="zk 投票过程"></a>zk 投票过程</h2><pre><code class="hljs">投票采用paxos 算法实现
1. epoch 候选者的zxId(事物日志的id) 越大说明数据越新, 
2. zxId 相同比较epoch, epoch 相同比较服务器id
3. 服务器选票过半的成为leader
</code></pre>
<h2 id="zk-脑裂"><a href="#zk-脑裂" class="headerlink" title="zk 脑裂"></a>zk 脑裂</h2><pre><code class="hljs">如何解决ZK 脑裂问题
    1. 确保奇数个节点
    2. 网络分区的监控和恢复
    3. 启用Observer 节点
    4. 事物的日志和快照定期备份
    5. Quorums: 当集群中存活节点少于法定人数的时候, 集群不可用
    6. 冗余通信
</code></pre>
<h1 id="netty"><a href="#netty" class="headerlink" title="netty"></a>netty</h1><h2 id="Netty-的一次网络请求过程是什么"><a href="#Netty-的一次网络请求过程是什么" class="headerlink" title="Netty 的一次网络请求过程是什么"></a>Netty 的一次网络请求过程是什么</h2><pre><code class="hljs">客户端
    初始化:
        EventLoopGroup 的创建, 用于管理和服务之间网络链接和IO 操作, Bootstrap 配置客户端的各种参数, 包括线程模型, NioSocketChannel, 远端服务器的地址, 以及客户端的handler
    建立链接
        连接服务器: 通过Bootstrap.connect() 方法启动连接过程, 链接成功后会将channel 注册到event loop 上
        等待建立连接完成:  connect() 返回一个ChannelFuture, 可以通过sync() 或者是addListener 进行完成
    发送请求
        构造数据进行请求, 连接成功后, 通过channel 向服务器发送数据, 通常是将请求封装成 ByteBuf 
        对数据进行writeAndFlush 写数据, 数据会通过ChannelPipeline 的outbounder 进行处理, 通过底层的socket 发送到服务器
    接收响应
        pipeline 处理, 当服务器响应数据到的时候, 数据会到channelHander 的inbounder,
        处理响应数据: 业务逻辑进行处理, 处理完后返回给应用层
    关闭连接
        主动关闭连接: channel.close 关闭连接, 释放资源
        监听关闭操作: close 返回的future 进行监听, 进行监听关闭是否成功。
    资源清理
        group.shutDownGracefully() 进行清理
服务端
    初始化阶段
        创建EventLoopGroup, bossGroup 和 workerGroup, bossGroup 负责接受请求, workerGroup 负责处理 BossGroup 分配过来的IO 操作
        配置 serverBootstrap : 使用 ServerBootstrap 来配置 Netty 服务, 包括 channel 的类型, 指定 EventLoopGroup, 配置 channelPipeline , 以及设置服务器的监听端口
    绑定端口
        serverBootStrap.bind() 方法绑定服务器的监听端口, 会启动一个异步操作过程, bossGroup 中的线程会监听这个连接请求
        bind() 返回一个future, 可以通过sync()  或者是addListener 来等待响应
    接受客户端请求
        bossGroup 中的线程会去监听端口的连接请求, 当有新的请求进来的时候, Netty会为这个连接创建一个channel, 并将其分配给worker 的EventLoop上,
        注册channel: 新的channel 会被注册在worker Group 中的eventLoop 上, 接下来和这个连接的相关读写操作都是在这个EventLoop 上
    处理客户端请求
        每个channel 关联的channelpipeline, 包含了一系列的handler
        当客户数据到达的时候, 数据会通过channelPipeline 中的inbounder 来进行处理, 负责数据的读取, 解码，业务逻辑处理等
    响应客户端
        当业务逻辑处理完后, 通过会通过ChannelHandlerContext.writeAndFlush() 将数据响应回给客户端
        数据会通过channelpipeline 中的outbounder，然后通过底层的socket 发送给客户端
    关闭连接
        客户端关闭连接, 或者是服务端主动关闭连接的时候, Netty 会处发ChannelInbounderHandler 的channelInactive 或者是channelUnregistered, 可以进行资源清理
        在关闭服务器的时候, 需要调用bossGroup 和worker Group 的shutdownGracefully 进行线程资源的释放
</code></pre>
<h2 id="Channel-的作用"><a href="#Channel-的作用" class="headerlink" title="Channel 的作用"></a>Channel 的作用</h2><pre><code class="hljs">负责网络IO操作相关的
    1.1 管理IO 操作
        对数据读取、发送、和连接的管理
    1.2 处理事件
        从网络传输到channelPipeline, 将channelPipeline 处理后的数据返回到网络中去
    1.3 支持异步IO
        即将数据异步写入到网络中,不会阻塞当前线程
</code></pre>
<h2 id="EventLoop-作用"><a href="#EventLoop-作用" class="headerlink" title="EventLoop 作用"></a>EventLoop 作用</h2><pre><code class="hljs">1.每一个EventLoop 维护着一个 Selector 和 线程
2.处理IO 事件和任务
    监视和处理IO事件, 基于Java NIO 的selector 事件
3. 任务的调度
    还可以管理定时任务和普通任务, 可以提交任务到eventLoop上, 按照顺序和指定周期执行
4. 线程管理
    一个eventLoop通常和一个线程绑定, 每个eventLoop 可以维护多个channel, 但一个channel 始终绑定在一个eventLoop 上, 确保了同一个channel 上的事件处理是线程安全的
5. 事件的派发与处理
    负责从IO操作中获取事件, 将这些事件派发到对应的ChannelHandler中, 每个channel 代表一个连接或者IO操作, 在其pipeline中的一系列处理
</code></pre>
<h2 id="EventLoopGroup-作用"><a href="#EventLoopGroup-作用" class="headerlink" title="EventLoopGroup 作用"></a>EventLoopGroup 作用</h2><pre><code class="hljs">用于管理所有的EventLoop, 一个 EventLoopGroup 用于管理多个线程来并发去处理执行IO 事件
</code></pre>
<p>Channel 是网络通信的管道, 负责实际数据的读写, EventLoop 是负载驱动Channel 的 执行, 通过循环监听IO 事件来处理这些事件, EventLoopGroup 是多个EventLoop 的管理着, 负责分配和管理多个EventLoop, 并支持多并发处理多个Channel</p>
<h2 id="为什么需要将网络容器从tomcat-换成Netty"><a href="#为什么需要将网络容器从tomcat-换成Netty" class="headerlink" title="为什么需要将网络容器从tomcat 换成Netty"></a>为什么需要将网络容器从tomcat 换成Netty</h2><pre><code class="hljs">vmstat 1
可以检测上下文切换是否很高,
1. 实现机制上:
     serverlet 通过 startAsync 本质上依赖线程池去进行处理, netty天生为异步非阻塞的, 使用事件驱动的方式, 每个EventLoop 可以处理多个IO操作事件,可以极大的降低了线程数和线程切换的开销
2. 线程模型:
    serverlet 3.0异步依赖容器的线程管理, 在并发增加的情况下可能会导致线程的耗尽; netty 中使用少量的worker 线程来处理事件, 减少了上下文的切换, 避免了传统线程池模型的问题.
3. IO 模型
    serverlet 3.0 虽然支持异步处理, 但是底层依赖于阻塞IO模型; netty 使用java NIO 的非阻塞式, 从底层上确保了高并发表现的性能
4. 并发高的情况下 tomcat 由于采用的是BIO 加上异步线程的方式去处理的, 会有大量的线程产生, CPU 内存 文件描述符都会发生资源竞争，netty 是通过NIO 方式去做的，使用少量的worker 线程就可以去处理
</code></pre>
<h2 id="为什么要用netty"><a href="#为什么要用netty" class="headerlink" title="为什么要用netty"></a>为什么要用netty</h2><pre><code class="hljs">事件驱动模型:
    基于reactor模式去做的, 通过EventLoop来管理IO 操作事件, 并将这些事件派发给相关的channelHandler, 实现高效的网络通信, 可以处理大量的并发连接
    核心组建:
        eventLoop
        channel
        channelPipeline: 是一个处理链, 每个IO 事件都会按照顺序通过channelPipeline, 将多个channelHandler连接起来, 形成一条链, 每个channelHandler只负责处理特定的事件
        channelHandler: 用于处理特定类型事件的处理器, 不同的channelHandler 实现不同的功能, 有的可以用来编解码, 有的可以用来处理连接事件
        Selector: 用于监听多个Channel 上的IO 事件, 当selector 发现某个Channel 上有事件发生的时候, 会通过EvenetLoop 来进行处理
    工作流程:
        boosGroup 和 workerGroup
            bossGroup 负责监听客户端的连接请求事件, 将接收请求并将连接交给workerGroup进行处理
            workerGroup负责处理具体的IO 操作
        事件的监听与触发
            当有IO发生的时候, EventLoop 会从selector 中获取到该事件, 并将其传递给绑定的channel
            事件会按照事件类型依次在channelPipeline 上流过, 通过channelHandler 来具体处理
        channelHandler 处理事件
            入站事件有inbounder 处理, 出站事件由outbounder 处理
            每个channelHandler 可以对事件进行处理, 处理完成后让下一个处理器进行处理
    线程模型
        EventLoop 绑定一个线程, 因此EventLoop管理的channel 也是在同一个线程上去运行的, 确保每个channel 上的事件处理是安全的, 从而减少了上下文切换的开销		
支持零拷贝
    零拷贝指的是全程不需要CPU 进行参与, 所有数据都是通过DMA来进行传输的
    全程只需要2次上下文切换, 2次DMA数据copy
ByteBuf 好处:
    1. 容量可以动态的调整
    2. 支持零拷贝, 减少数据在不同内存区域之间的复制, 
    3. polling 机制 从而进行重复利用
</code></pre>
<h1 id="场景题"><a href="#场景题" class="headerlink" title="场景题"></a>场景题</h1><h2 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h2><pre><code class="hljs">高并发场景下, 怎么保证最可能的一致性
    缓存扰动: 刚更新的缓存没有被读取到, 再次被更新的情况下
    Cache-Aside
        读请求中: 首先请求缓存, 如果命中缓存, 则直接返回缓存中的数据, 如果没有命中缓存, 则将查询出来的数据更新到缓存中, 然后返回查询出来的结果数据
        写请求: 先更新数据库, 再删除缓存
            为什么是删除缓存, 而不是更新
                直接删除的时候性能高: 缓存中的数据可能是由多个条件下聚合出来的,
                更加安全: 可能将旧的值放入到缓存中, 两个线程同时去更新数据的情况下
            先更新数据库, 在删除缓存防止 缓存中的数据是老的

            删除缓存, 更新缓存, 更新数据库
    先更新数据库	 -&gt; 删除缓存
            优点: 删除缓存是因为性能更高, 写请求中更新可能导致数据的不一致性
            缺点: 在读写下面也会有并发问题 T1 去读取数据, T2 去更新数据, T1 中更新晚于T2的缓存删除更新
    删除缓存 -&gt; 更新数据库
            读写并发的时候可能导致缓存脏数据, 可以通过延迟双删
                1. 或者是在写请求的情况下加锁, 保证更新数据库和删除缓存串行处理
            缓存删除失败的情况下 需要引入MQ 或者是 监听数据库消费来解决
            优点
            缺点
    Write-Through
    更新数据库 -&gt; 更新缓存
        通过分布式锁 来解决更新数据库和更新缓存的一致性, 或者是将请求放到MQ中去处理
            优点
            缺点
    Write-Through
        或者是后续批量去进行写, 针对写特别多的情况下去做
    更新缓存 -&gt; 更新数据库
            优点
            缺点
        加上补偿机制
        分布式锁
    读多写少的情况下:
        Cache-Aside 结合数据库日志做补偿
    写多读少的情况下, 并且对于一致性要求比较高的情况下
        Write-Through结合分布式锁:	
            写后去更新缓存
        极端情况下:Write-Behind
</code></pre>
<h2 id="为什么需要将网络容器从tomcat-换成Netty-1"><a href="#为什么需要将网络容器从tomcat-换成Netty-1" class="headerlink" title="为什么需要将网络容器从tomcat 换成Netty"></a>为什么需要将网络容器从tomcat 换成Netty</h2><pre><code class="hljs">1. 实现机制上:
     serverlet 通过 startAsync 本质上依赖线程池去进行处理, netty天生为异步非阻塞的, 使用事件驱动的方式, 每个EventLoop 可以处理多个IO操作事件,可以极大的降低了线程数和线程切换的开销
2. 线程模型:
    serverlet 3.0异步依赖容器的线程管理, 在并发增加的情况下可能会导致线程的耗尽; netty 中使用少量的worker 线程来处理事件, 减少了上下文的切换, 避免了传统线程池模型的问题.
3. IO 模型
    serverlet 3.0 虽然支持异步处理, 但是底层依赖于阻塞IO模型; netty 使用java NIO 的非阻塞式, 从底层上确保了高并发表现的性能
4. 并发高的情况下 tomcat 由于采用的是BIO 加上异步线程的方式去处理的, 会有大量的线程产生, CPU 内存 文件描述符都会发生资源竞争，netty 是通过NIO 方式去做的，使用少量的worker 线程就可以去处理
</code></pre>
<h1 id="面试"><a href="#面试" class="headerlink" title="面试"></a>面试</h1><h2 id="SHEIN"><a href="#SHEIN" class="headerlink" title="SHEIN"></a>SHEIN</h2><pre><code class="hljs">Netty
事件驱动模型:
    基于reactor模式去做的, 通过EventLoop来管理IO 操作事件, 并将这些事件派发给相关的channelHandler, 实现高效的网络通信, 可以处理大量的并发连接
    核心组建:
        eventLoop
        channel
        channelPipeline: 是一个处理链, 每个IO 事件都会按照顺序通过channelPipeline, 将多个channelHandler连接起来, 形成一条链, 每个channelHandler只负责处理特定的事件
        channelHandler: 用于处理特定类型事件的处理器, 不同的channelHandler 实现不同的功能, 有的可以用来编解码, 有的可以用来处理连接事件
        Selector: 用于监听多个Channel 上的IO 事件, 当selector 发现某个Channel 上有事件发生的时候, 会通过EvenetLoop 来进行处理
    工作流程:
        boosGroup 和 workerGroup
            bossGroup 负责监听客户端的连接请求事件, 将接收请求并将连接交给workerGroup进行处理
            workerGroup负责处理具体的IO 操作
        事件的监听与触发
            当有IO发生的时候, EventLoop 会从selector 中获取到该事件, 并将其传递给绑定的channel
            事件会按照事件类型依次在channelPipeline 上流过, 通过channelHandler 来具体处理
        channelHandler 处理事件
            入站事件有inbounder 处理, 出站事件由outbounder 处理
            每个channelHandler 可以对事件进行处理, 处理完成后让下一个处理器进行处理
    线程模型
        EventLoop 绑定一个线程, 因此EventLoop管理的channel 也是在同一个线程上去运行的, 确保每个channel 上的事件处理是安全的, 从而减少了上下文切换的开销		
异步非阻塞体现:
    1. 基于java NIO 的非阻塞IO
        基于NIO 中的selector 和 channel 来实现非阻塞的IO, 意味着每个IO 操作都是非阻塞的
    2. selector 机制
        使用selector 来监听channel 上的IO 事件
    3. 异步操作的提交与处理
        通过future 机制, IO 操作实现异步化
    4. 异步事件的派发
        eventLoop 监听到selector 上的IO 事件后, 异步派发给worker 去进行处理
异步非阻塞和线程安全
    线程安全通过单线程的eventLoop 去处理channel, 避免了多线程下的并发访问, 实现了一个channel 的线程安全
支持零拷贝
    零拷贝指的是全程不需要CPU 进行参与, 所有数据都是通过DMA来进行传输的
    全程只需要2次上下文切换, 2次DMA数据copy
ByteBuf 好处:
    1. 容量可以动态的调整
    2. 支持零拷贝, 减少数据在不同内存区域之间的复制, 
    3. polling 机制 从而进行重复利用
epool pool selector 的区别
    epool 采用事件驱动的方式, 
    原理是通过内核维护的事件通知机制，将已注册的文件描述符放入红黑树中管理，并在文件描述符上发生事件时将其加入就绪队列（双向链表），应用程序通过 epoll_wait() 高效地等待并处理这些就绪事件
    poll：需要定时扫描文件描述符, 
    每次调用时传入所有待监控的文件描述符，内核通过线性扫描检查文件描述符状态，返回已准备好进行 I/O 操作的文件描述符，性能随监控的文件描述符数量增加而线性下降
动态代理
    1. 进行接口定义, 创建一个自定义接口
    2. 实现InvocationHandler接口, 类中的invoke 方法参数中有proxy 代理类, method 方法, args 对应的相关参数
        proxy :动态生成的代理类
        method : 与代理类对象调用的方法相对应
        args : 当前 method 方法的参数

    3. 创建代理类
        通过java.lang.reflect.Proxy 类生成一个代理对象	
            Proxy.newProxyInstance(classLoader, interface, invocationHandler)
                loader :类加载器，用于加载代理对象。
                interfaces : 被代理类实现的一些接口；
                h : 实现了 InvocationHandler 接口的对象；
    4. 调用代理方法
        通过newProxyInstance 创建出来的代理类, 去调用方法的时候, 实际上会去调用InvocationHandler 接口类中的invoke 方法, 因此可以再invoke 方法中自定义处理逻辑
字节码增强:
    cglib 通过生成目标类的子类的方法来创建代理对象
            定义一个类；
            自定义 MethodInterceptor 并重写 intercept 方法，intercept 用于拦截增强被代理类的方法，和 JDK 动态代理中的 invoke 方法类似；
            通过 Enhancer 类的 create()创建代理类；
        cglib 不可以代理声明为final 类型的类和方法
    asm 是可以直接修改字节码的
其中spring 默认是使用clglib

高并发
    GC 
异步
    future
promise
Spring 的常见问题
    
HTTP
TCP
    三次握手 四次挥手 各个阶段, 以及每个阶段的问题
动态代理
    jdk cglib asm
ByteBuf
Spring 的IOC 和 AOP
    IOC 指的是控制反转, 将对象的创建和管理委托给spring容器, 而不是直接有应用程序代码直接控制
    AOP 指的是允许不修改代码的情况下, 方便的添加或者修改横切关注点
        AOP 一般通过动态代理来进行实现
            jdk 自身的动态代理: 基于java 的反射来进行实现的
            cglib 
反射
    获取class 对象的方式:
        1. Class alunbarClass = TargetObject.class;
        2. Class alunbarClass1 = Class.forName(&quot;cn.javaguide.TargetObject&quot;);
        3. TargetObject o = new TargetObject();
                Class alunbarClass2 = o.getClass();
        4. ClassLoader.getSystemClassLoader().loadClass(&quot;cn.javaguide.TargetObject&quot;);
    反射的操作
        创建一个我们要使用反射操作的类 TargetObject
        使用反射操作这个类的方法以及参数
            获取方法:	Method[] methods = targetClass.getDeclaredMethods();
            获取方法并调用: Method publicMethod = targetClass.getDeclaredMethod(&quot;publicMethod&quot;,String.class);
            publicMethod.invoke(targetObject, &quot;JavaGuide&quot;);
            获取指定参数:Field field = targetClass.getDeclaredField(&quot;value&quot;);
            对指定参数进行修改
                field.setAccessible(true);
                field.set(targetObject, &quot;JavaGuide&quot;);
Arraylist 与 LinkedList 区别?
</code></pre>
<p>是否保证线程安全： ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全；<br>底层数据结构： ArrayList 底层使用的是 Object 数组；LinkedList 底层使用的是 双向链表 数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！）<br>插入和删除是否受元素位置的影响：<br>ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element)），时间复杂度就为 O(n)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位&#x2F;向前移一位的操作。<br>LinkedList 采用链表存储，所以在头尾插入或者删除元素不受元素位置的影响（add(E e)、addFirst(E e)、addLast(E e)、removeFirst()、 removeLast()），时间复杂度为 O(1)，如果是要在指定位置 i 插入和删除元素的话（add(int index, E element)，remove(Object o),remove(int index)）， 时间复杂度为 O(n) ，因为需要先移动到指定位置再插入和删除。<br>是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList（实现了 RandomAccess 接口） 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。<br>内存空间占用： ArrayList 的空间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。</p>
<pre><code class="hljs">问题:
    1. 
    2. 堆外内存的排障
    3. gdb --batch --pid 36563 --ex &#39;call malloc_trim() 进行内存释放
    2. 并发压不上去怎么处理
    3. dubbo
    4. grpc
    5. kafka
    6. redis
    7. HTTP 1.1 2.0 等
    8. jdk 各个版本的差异 为了解决什么问题
    9. spring spring boot 
    各个协议的问题, 并在下一个协议上怎么去解决的
</code></pre>
<h2 id="极兔速递"><a href="#极兔速递" class="headerlink" title="极兔速递"></a>极兔速递</h2><pre><code class="hljs">1. 网关为什么要用netty
2. 线程数怎么去定的 为什么大多数是CPU 核数+1
    2. 每个请求耗时比较高
    3. 
4. pipeline handler 是做什么用的
5. 后端机器上下线
    下游应用存在非RPC 或者是非
6. 鉴权怎么做的?
7. 限流怎么做的
    7.1 为什么要自己去进行限流
8. 为什么使用4C 8G 升级到4C 16G
9. 全链路灰度怎么做的
    全链路定义:
    请求头的识别
        9.1 header、body、param、cookie、流量比例
10. 网关自身怎么灰度
11. 针对异步的请求怎么去做灰度
12. 配置中心怎么去做灰度的, 数据库等的话 需要影子库
13. 自动生成API 文档怎么说的 -&gt; 自动性怎么体现
14. serverless 架构思想怎么体现的
15. 流量怎么监控, 监控的告警阈值怎么配置??????????  告警 限流 等治理?????
16. Agent
17. 个人评估觉得厉害的:
    17.1 
    17.2 
    17.3 MQ 延迟队列、灰度功能

18. spring boot 的扩展点有哪些
19. 什么是动态代理
20. 如果自己去实现动态代理怎么去做
21. MQ 的消息扭转, 生产者 消费者怎么消费
22. 长轮训 怎么理解???
    为什么要用长轮训去做
23. 时间轮 怎么做的
24. 语言表达不清楚
</code></pre>
<h2 id="霸王茶姬"><a href="#霸王茶姬" class="headerlink" title="霸王茶姬"></a>霸王茶姬</h2><pre><code class="hljs">1. 请求的URL 配置
2. 全链路灰度怎么做的
3. 自研网关和spring cloud 或者zuul 
4. 限流的模式是什么
    4.1 和sentional 
5. zk 脑裂问题
6. netty 中的 channel 作用是什么
7. netty 中的 eventLoop 作用
8. 线程数中各个参数的关系是什么
9. mysql 的隔离级别
10. 幻读怎么解决的
11. 缓存和数据库的一致性问题
12. redis 缓存穿透和 击穿
13. synchronized
14. hashMap 中的扩容因子选取
    14.1 为什么是0.75
</code></pre>
<h2 id="神舟"><a href="#神舟" class="headerlink" title="神舟"></a>神舟</h2><pre><code class="hljs">1. 集群化分
2. 和spring Cloud 怎么去对比
3. 后端 IP信息怎么动态感知
4. 日志是怎么记录的
6. spring 注解 和 配置中心加载读取的顺序
</code></pre>
<h2 id="华泰准备"><a href="#华泰准备" class="headerlink" title="华泰准备"></a>华泰准备</h2><pre><code class="hljs">1. 存储数据量很大 变化很大怎么处理
        几百万条数据怎么处理
        1.1 引入metaserver？？？？ 客户端主动向metaserver 去拉去数据, 注册中心只需要维护provider 的ip:port 信息
        负载均衡算法
        协议:
            http2.0 Triple grpc http3.0
        一些常用的配置????
        一些常见的用户问题, 做了哪些功能？？？
    2. 服务端不健康的时候, 怎么主动从注册中心上将自己给剔除掉
    网关在协议转换上会不会常见很多个对象出来
1. dubbo 
    失败重试的策略
        1.1 快速失败策略: 请求失败, 直接把异常跑出去
        1.2 失败安全策略: 
        1.3 失败自动恢复策略: 后台记录失败请求, 通过定时任务对失败请求进行充实
        1.4 并行调用多个服务: 把消息广播给服务提供者集群, 只需要一个返回成功即可
        1.5 广播调用策略: 逐个调用服务提供者的集群, 只要集群中任何一个节点返回异常, 表示本次请求失败
    核心组建:
        服务的提供方
        服务的消费者
        注册中心
    请求的过程
        服务注册:
            服务的提供方在启动的时候将请求接口、方法、版本协议等信息注册到注册中心上
            服务的消费者从注册中心订阅所依赖服务的信息, 注册中心会返回服务提供者地址的列表
        服务发现
            服务发现的过程, 服务的消费者会从注册中心拉取到服务提供者的列表并保存到本地缓存中, 当有新的服务的提供方或者老的服务提供方需要下线的时候, 注册中心会通知消费者, 消费者动态更新服务的提供者列表
        服务准备调用
            proxy 生成: 服务的消费者使用动态代理机制, 生成服务接口的代理对象, 当消费者调用接口方法时, 实际上是调用这个接口对象的方法
            Cluster &amp; LoadBalance
        网络通信准备
            编码和序列化: 代理对象将方法调用, 参数信息封装成一个RPC请求, 通过编解码器对请求进行序列化和反序列化
            Netty 通道管理: 使用Netty 作为底层通信框架, 消费者和提供方之间的通信依赖Netty 去进行传输数据
        发送请求
            consumer: 消费者通过Netty 客户端将序列化后的RPC 请求发送到指定的服务提供方
            provider: 提供方的Netty server 会去接收请求, 并将其传递给指定的服务处理线程池去进行处理
        请求处理
            服务的提供方接收到请求并对接收到的数据进行反序列化, 恢复出原始请求对象
            调用服务: 服务的提供方根据请求对象的服务名、方法名、通过反射的方式执行实际的业务逻辑
            返回结果: 提供方将执行结果返回给响应对象, 并序列化后, 返回给发送方
        接收响应
            consumer: 消费者的Netty 客户端接收到响应后, 并将其反序列化成对象
            结果处理: 将拿到的结果反序列化成对象返回给上层调用者
        服务调用完成
            上层的程序获得结果, 整个RPC 请求结束

2. grpc 和 dubbo 的对比
    grpc 直接基于http2.0 的, 默认使用 protobuf 来进行序列化和反序列化

    dubbo 可以使用 Hessian、Kryo、Java 序列化 等
http 1.1 2.0 quic 协议对比
HTTP 1.X 存在的问题  
    单向请求: 只能单向请求, 不可以服务端主动给客户端发送响应
    协议开销大: header里携带的内容过大，且不能压缩，增加了传输的成本。
    队头阻塞: 下个请求必须要等待前面请求返回后, 才可以发出。导致带宽无法被利用
HTTP2.0 怎么针对上述问题解决的
    多路复用:  通过使用二进制帧来对数据进行传输, 不再是Http 1.x 的纯文本协议, 所有的请求都被分割成了更小的数据帧, 这些帧可以在网络中按照任意顺序发送, 接收方再根据帧的标识符进行重组, 提高了带宽的利用率
    消除对头阻塞: 通过多路复用来允许多个请求和响应再同一个TCP 连接上进行传输, 从而消除了对头阻塞问题
    减少了延迟: 多路复用可以使得数据流并行传输, 每个数据流有唯一的标示, 并且可以是无序的, 降低了延迟
    减少连接开销: 可以共用链接
HTTP2.0的问题
    TCP 层面的队头堵塞问题: 
        TCP的顺序性:  发送方的某个数据包在传输过程中丢失了, 接收段需要等待重传的丢失包才可以处理后续的数据包, 导致了TCP 的队头堵塞
        TCP 传输时某个数据流的数据包丢失了, 会导致后续的数据流堵塞, 因为TCP 需要等待丢失的数据包和重传
    对比Http1.x 的话: 使得TCP的队头堵塞影响整个链接上的请求和响应, HTTP1.x 的话只影响对应链接的请求和响应
可以通过QUIC 和 http3.0 去进行解决
    基于UDP 去实现的
    QUIC 实现了TCP + HTTPS + HTTP/2的功能，目的是保证可靠性的同时降低网络延迟
    安全性: 
        1. 对于首次建立链接的: 需要交换密钥 消耗一次RTT, 再发送业务数据
        2. 对于非首次的, 通过diff-Hellman 来进行密钥交换, 
    链接的唯一性基于64位的connection id
    如何解决队头堵塞问题:
        1. 基于UDP
        2. 数据包级别的确认, 如何确定数据包是否一致 : 通过Stream ID 来标识当前数据流属于哪个资源请求, 同时增加stream offset 确认在数据流中的位置, 两个确定数据包重传

    7. 总结
    Protobuf：适合需要高效、跨语言通信和数据存储的场景，特别是在需要数据结构化的分布式系统和微服务架构中非常有用。
    Kryo：专注于Java生态系统，提供高效的二进制序列化，适用于高性能计算和需要优化网络传输的应用。
    FastJson：适合Web开发，特别是需要与前端进行数据交换的场景，尽管在性能上不如二进制序列化框架，但其易用性和广泛的语言支持使其非常流行。
    Hessian2：用于分布式系统中的跨语言通信，适合需要轻量级二进制传输协议的场景，但在Java内部应用中，Kryo可能会有更好的性能表现。    
4. HTTPS 的过程
    1. 客户端发起请求
    2. 服务器收到请求后, 向客户端发送数字证书(SSL/TLS 证书), 证书包含服务器的公钥和CA 签名的信息
    3. 客户端验证证书
    3.1 客户端检验证书、查看证书的有效期、证书链接、证书的域名是否和服务器匹配       防止中间人攻击
    3.2 如果证书不可信, 客户端会警告用户并提示
    4. 客户端使用生成会话密钥, 信息通过公钥进行加密, 服务器使用私钥进行解密。        确保只有对应私钥的才可以进行揭秘
    5. 客户端和服务端双方拥有会话密钥后, 通过会话密钥进行对数据传输
    6. 数据传输
    7. 
4. zk 和其他注册中心对比 Eureka
    ZK CP Eureka 是AP 
    防止ZK 脑裂
            如何解决ZK 脑裂问题
            1. 确保奇数个节点
            2. 网络分区的监控和恢复
            4. 启用Observer 节点
            5. 事物的日志和快照定期备份
            6. Quorums: 当集群中存活节点少于法定人数的时候, 集群不可用
            7. 冗余通信
5. SPI 
    SPI 的具体原理是这样的：我们将接口的实现类放在配置文件中，我们在程序运行过程中读取配置文件，通过反射加载实现类。这样，我们可以在运行的时候，动态替换接口的实现类
        META-INF/dubbo
6. HTTP RPC 区别
    1. 服务发现上的区别
        HTTP 通过DNS 解析获取背后的地址
        RPC 通过注册中心
    2. 底层连接
        HTTP keep-alive 
        RPC polling 机制
    3. 传输内容
        HTTP 传输内容多 冗余
        RPC 定制化程度高
7. 动态代理
        jdk 动态代理通过Proxy 类生成一个代理对象, 这个代理对象实现了目标类的接口, 并将方法调用委托给InvocationHandler 来进行处理
        1. 接口定义
            1.1 创建一个自定义的接口
        2. 实现InvocationHandler 接口
            2.1 这个类的invoke 方法 会处理所有代理类上的方法调用
                    proxy :动态生成的代理类
                    method : 与代理类对象调用的方法相对应
                    args : 当前 method 方法的参数
        3. 创建代理类
            MyInterface target = new MyInterfaceImpl();

            // 创建InvocationHandler
            MyInvocationHandler handler = new MyInvocationHandler(target);
                	loader :类加载器，用于加载代理对象。
                    interfaces : 被代理类实现的一些接口；
                    h : 实现了 InvocationHandler 接口的对象；
            // 创建代理实例
            MyInterface proxyInstance = (MyInterface) Proxy.newProxyInstance(
                target.getClass().getClassLoader(),
                target.getClass().getInterfaces(),
                handler
            );
        4. 调用代理类的方法
8. 线程数的配置方式
    计算密集型
        一般设置为接近于或等于CPU核心数。
            计算密集型任务主要依赖于CPU执行计算。过多的线程会导致线程上下文切换增加，反而可能降低性能。因此，线程数与核心数保持一致或略多于核心数即可充分利用CPU。
    IO 密集型
        通常是CPU核心数的多倍。
            IO密集型任务通常会有大量时间在等待IO操作完成，如网络或磁盘操作。在等待期间，CPU会空闲，因此可以通过增加线程数来提高并发量，减少CPU空闲时间。
9. jdk 新版本特性
        jdk11. 
            可以开始使用zgc, 
            移除的模块：Java EE 和 CORBA 模块 包的变化
        jdk21: 
            虚拟线程
            线程是映射到操作系统的本地线程去做的, 虚拟线程直接由jvm 去进行管理, 避免了上下文开销的切换
</code></pre>
<h2 id="茄子科技"><a href="#茄子科技" class="headerlink" title="茄子科技"></a>茄子科技</h2><pre><code class="hljs">1. rocketMQ 
    生产消息的过程:
    1. producer 发送消息之前, 先向NameServer 获取消息Topic 的路由信息
    2. NameServer 返回 该 topic 的 路由表和 broker 列表
    3. producer 根据代码指定的queue 选择策略, 从queue 列表中选择一个queue 进行存储
        轮训
        最小投递延迟
    4. producer 向选出queue 所在的broker 发出rpc 请求, 将消息发送到选择出来的queue
    消费者消费消息:
        广播消费: 所有的consumer 实例 都会接受同一个Topic 的全量消息
        集群消费: 每条消息只会发送给其中一个consumer
        consumer 向Nameserver 获取Broker 的地址,
        consumer 链接到Broker 上, 并订阅指定的topic
        broker 根据ConsumerQueue 文件找到消息的偏移量和大小
        broker 根据commitLog 文件读取消息数据
        Broker 将消息数据返回给consumer
    rebalance:
    rocketMQ 怎么保证那么快的
        使用了顺序存储, page cache、异步刷磁盘、 mmap 零拷贝技术
        不是直接写入到磁盘的, 是写入到page cache 中, 随后以异步的方式pdflush 到磁盘上去
        读操作的话也是走page cache 
    如何保证不被重复消费

    如何保证消息可靠性
        可达性保证: 
            生产者: 
                提供了sync 发送消息方式, 等待Broker 返回,
                    支持同步, 线程池回调 
                发送消息的时候失败或者是超时了, 则重新发送
                    默认3次的重试次数
                broker 提供了多master, 当某台broker 宕机了, 保证消息可以投递到另外一台上去
                    利用多主的方式进行重试
            broker 处理
                提供同步的刷盘策略
                当主的broker 磁盘损坏的时候, 可以给broker 指定slave, 同时设置slave 为同步刷盘策略, 设置master 为SYNC_MASTER, 保证消息同时落到master 和 slave
            consumer 消费端
                consmuer 默认提供 at least one 策略: consumer pull 消息到本地后, 消费完成才响应ack
                提供重新消费的能力, 防止消费的时候异常
    如何解决消息堆积的问题
        耗时高原因: 	CPU  内部计算, 外部IO: 读写数据库, 访问redis, 下游RPC 调用
        消息堆积带来影响: 
            存储压力上涨, 延迟增加, 一致处理积压的消息
        怎么解决消息堆积
            1. 梳理消费耗时: 是否计算逻辑过于复杂, 是否存在死循环, 是否可以做异步处理, 
            2. 增加 消费端 的并发度, 增加单个节点消费者的消费线程, 增加消费节点
                消费节点 = 流量峰值 / 单个节点消息吞吐量
redis
    支持的数据结构:
        String、Hash、List、Set、ZSet
    可以持久化保存在磁盘中
    redis 单线程
        接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端 整个过程是单线程的
        单线程为什么那么快:
            1. 大部分操作都是在内存当中操作的, 采用了高效的数据结构,  
            2. I/O 多路复用去处理大量客户端的Socket 请求, 
            使用单线程的原因:
                CPU 不是Redis 性能的瓶颈, 更多的是在内存上和网络I/O的限制, 同时单线程可维护性高, 多线程的话增加系统复杂度, 存在线程切换等问题
        6.0 后用多线程去做
            为什么要在6.0 后用多线程去做: 提升网络I/O, 命令的执行仍然是单线程的
    Redis 如何实现数据不丢失
        1. 读写操作在内存中, 同时有做持久化
        2. 持久化日志: 
            AOF 日志、每一个写的命令, 将对应的命令写入到该文件中
                先执行命令操作, 再记录到AOF 文件日志中
                写回的策略
                always			EverySyc 				No
                同步写回			每秒回写					由操作系统控制
                可靠性高,			性能适中, 				性能好
                但是开销大		宕机丢失一秒数据			宕机丢失的数据多
                
            RDB 日志: 将某一时刻的内存数据, 以二进制的方式写入磁盘
                生成rdb 文件: save(会阻塞主线程) 和 bgsave(后台线程操作)
                使用bgsave 的时候可以继续处理命令
            混合持久化方式
    Redis 如何实现集群的高可用
        1. 主从复制
            主从复制采用读写分离的方式, 写数据的时候写到主节点, 主节点收到写的命令后会更新给从节点,  客户端无须等到从节点都更新完再拿到响应的结果
        2. 哨兵模式
            可以对主从进行监控, 同时进行主从切换
        3. 切片集群
            数据量很大的时候, 可以用redis cluster
        redis cluster 或者主从的时候出现脑裂怎么办
            当主节点发现从节点下线, 或者通信的数量少于阈值时, 那么禁止主节点进行写数据, 直接把错误返回给客户端
            min-slave-to-write x 主节点至少要和 x 个节点进行连接, 如果小于这个数量, 主节点会禁止写数据
            min-slave-to-lag x   主从复制的延迟同步不可以超过 x 秒,  如果超过的话, 会禁止 主节点写数据
            上述的配置可以防止主节点故障的时候进行写数据, 只有新的主库才可以写数据
    删除策略
        1. 主库通过lazy 的方式进行删除
        2. 主库会发送一个del 事件给从库, 从库收到后对数据进行删除
    内存满了后怎么处理
        1. 进行淘汰
    Redis 缓存设计
        如何避免缓存失效
            1. 不给热点key 设置过期时间
            2. 将缓存失效的事件随机打散, 防止集体失效
        如何避免缓存击穿
            1. 热点key 要过期的时候, 通知后台线程进行更新
        如何避免缓存穿透 数据不存在数据库中, 要不存在redis 中
            1. 对恶意请求进行限制拦截
            2. 设置默认值
            3. 通过布隆过滤器 去设置值是否存在, 不是直接通过数据库进行查询
    更新缓存策略
        1. cache aside: 
            针对读多写少的场景: 先更新数据库, 再去删除缓存
        写多读少的场景
            Write Through 策略
            数据更新的时候, 如果数据库中有数据, 则先更新缓存中的数据,通过缓存组建同步更新到数据库中, 缓存组建告知应用程序更新完成
            如果没有数据的话 则直接进行更新即可
        Write back
            更新数据库的时候, 只更新缓存, 将缓存数据设置为脏数据, 然后立马返回, 数据库的更新 再通过批量更新
    大key 的影响
        1. 客户端阻塞超时
        2. 引发网络阻塞
        3. 内存分布不均匀
        4. 阻塞工作线程
    如果找到大key
        1. redis-cli --bigkeys
        2. scan 找大key

mmap
    mmap 是一种将文件或其他对象映射到进程的虚拟内存空间的机制。通过 mmap，进程可以直接访问文件内容，就像访问内存中的数据一样，而不需要调用传统的 read 或 write 系统调用
零拷贝
    零拷贝是一种优化技术，旨在减少数据在用户态和内核态之间的拷贝次数，从而提高 I/O 性能。传统的文件 I/O 操作需要多次数据拷贝，例如从磁盘到内核缓冲区、从内核缓冲区到用户态缓冲区等。而零拷贝技术通过直接在内核空间中处理数据，避免了这些不必要的拷贝操作
为什么要分代
    1. 大多数对象的存活时间比较短, 少数对象存活时间比较长, 可以减少GC 扫描的范围, 提升GC 的效率
    2. 不同年代的GC 算法采取不一样的, 年轻代 标记复制算法, 老年代, 标记清除 或者是标记整理
问题:
    1. 内部服务治理有哪些
    2. 限流机制
    3. 网关下游处理时长抖动怎么保证网关的可用性
    4. 一次RPC 调用的过程
    5. Netty 的一次网络请求过程是什么
        客户端
            初始化:
                EventLoopGroup 的创建, 用于管理和服务之间网络链接和IO 操作, Bootstrap 配置客户端的各种参数, 包括线程模型, NioSocketChannel, 远端服务器的地址, 以及客户端的handler
            建立链接
                连接服务器: 通过Bootstrap.connect() 方法启动连接过程, 链接成功后会将channel 注册到event loop 上
                等待建立连接完成:  connect() 返回一个ChannelFuture, 可以通过sync() 或者是addListener 进行完成
            发送请求
                构造数据进行请求, 连接成功后, 通过channel 向服务器发送数据, 通常是将请求封装成ByteBuf 
                对数据进行writeAndFlush 写数据, 数据会通过ChannelPipeline 的outbounder 进行处理, 通过底层的socket 发送到服务器
            接收响应
                pipeline 处理, 当服务器响应数据到的时候, 数据会到channelHander 的inbounder,
                处理响应数据: 业务逻辑进行处理, 处理完后返回给应用层
            关闭连接
                主动关闭连接: channel.close 关闭连接, 释放资源
                监听关闭操作: close 返回的future 进行监听, 进行监听关闭是否成功。
            资源清理
                group.shutDownGracefully() 进行清理
        服务端
            初始化阶段
                创建EventLoopGroup, bossGroup 和 workerGroup, bossGroup 负责接受请求, workerGroup 负责处理BossGroup 分配过来的IO 操作
                配置serverBootstrap: 使用ServerBootstrap 来配置Netty 服务, 包括channel 的类型, 指定EventLoopGroup, 配置channelPipeline, 以及设置服务器的监听端口
            绑定端口
                serverBootStrap.bind() 方法绑定服务器的监听端口, 会启动一个异步操作过程, bossGroup 中的线程会监听这个连接请求
                bind() 返回一个future, 可以通过sync()  或者是addListener 来等待响应
            接受客户端请求
                bossGroup 中的线程会去监听端口的连接请求, 当有新的请求进来的时候, Netty会为这个连接创建一个channel, 并将其分配给worker 的EventLoop上,
                注册channel: 新的channel 会被注册在worker Group 中的eventLoop 上, 接下来和这个连接的相关读写操作都是在这个EventLoop 上
            处理客户端请求
                每个channel 关联的channelpipeline, 包含了一系列的handler
                当客户数据到达的时候, 数据会通过channelPipeline 中的inbounder 来进行处理, 负责数据的读取, 解码，业务逻辑处理等
            响应客户端
                当业务逻辑处理完后, 通过会通过ChannelHandlerContext.writeAndFlush() 将数据响应回给客户端
                数据会通过channelpipeline 中的outbounder，然后通过底层的socket 发送给客户端
            关闭连接
                客户端关闭连接, 或者是服务端主动关闭连接的时候, Netty 会处发ChannelInbounderHandler 的channelInactive 或者是channelUnregistered, 可以进行资源清理
                在关闭服务器的时候, 需要调用bossGroup 和worker Group 的shutdownGracefully 进行线程资源的释放
    6. TCP 流式处理怎么对流量进行拆分
    7. Redis 的高可用怎么保证的, 
        哨兵模式和主从模式
        哨兵负责三个事情: 
            监控: 
                主观下线
                    发送Ping 命令给主节点, 如果主节点在一定时间内没有相应的话, 会被标记为SDOWN, 主观下线,
                客观下线
                    多个哨兵节点通信认为某个节点不可用, 则认为改节点为客观下线, ODOWN
            哨兵节点的选主:
                在主节点被标记为ODOWN 后, 哨兵节点会通过RAFT进行一次投票选举, 确定哪个哨兵节点作为领导者, 负责执行故障转移, 每个哨兵节点可以发起投票,并且每个哨兵节点只能投票给一个哨兵节点
                获得多数票的哨兵节点被选为领导者, 负责后续的主从切换
            选择主节点
                哨兵的leader 从可用的从节点中选主一个新的主节点, 主节点标准:
                    1. 从节点的优先级高的更可能被选中
                    2. 复制偏移量, (代表和主节点是否更接近的,) 更有可能选中
                    3. 链接状态好的
                哨兵的leader 会向其他哨兵节点通知选主的主节点
            主从切换
                选中的从节点会倍提升为主节点, 新的主节点会停止从旧的主节点同步数据, 并且开始接受写入操作
                重新配置集群,  其他从节点开始从新的主节点上去同步数据, 包含和旧的主节点连接的断开. 从新的主节点获取数据
                通知客户端, 客户端根据配置更新配置
            恢复正常运行
    8. 问题:
        底层技术不是太差? 广度上不够, 需要对各个原理有了解
</code></pre>
<h2 id="美团"><a href="#美团" class="headerlink" title="美团"></a>美团</h2><pre><code class="hljs">1. mysql
    char 和 varchar的区别
        char: 固定长度的字符类型, 定义时需要指定字符长度, 不够的时候会在末尾补足空格, 适合存储固定长度的
        varchar:  可变长度的字符串类型, 存储时需要指定最大长度,存储的时候根据实际长度占用存储空间
    in 和 exist 的区别
        in 表示左边表达式是否存在于右边, 返回true or false
        exist 可以返回一行数据
        性能上的差异:
            exists 的性能要比in 好, 尤其是在表比较大的情况下, 因为exist 找到一条后就立刻返回停止查询, in 需要遍历整个子查询
        使用场景:
            查询子集合较小并且变动属于低频的, in 更加直观,  当子查询涉及到外部查询的每一行判断的时候,  并且子查询效率较高, exist 更为合适
        null 值的处理:
            in 可以正确处理子查询中包含null 的情况, 而exist 不受子查询结果中null  值的影响
    执行一条sql 请求的过程
        1. 客户端发送请求
            客户端通过网络连接向数据库发送一条sql 语句, 
        2. 连接管理
            连接处理: 数据库服务器收到客户端的请求后, 检查是否有可用的连接池, 如果有的话 则用现有的处理连接, 没有的话创建一个新的连接
            权限验证: 服务器会去验证客户端的身份, 检查客户端是否有执行这条sql 命令的权限, 如果校验失败, 则返回错误
        3. SQL 解析
            词法分析
            语法分析
            语义检查
        4. 查询优化
            生成查询计划: 数据库会根据语法树生成多个可能的查询计划, 查询计划是SQL 执行的方案, 描述了如何访问和处理
            选择最优计划: 数据库会根据执行的代价选择一个最优的方案, 代价评估包含有IO成本, CPU 资源消耗 内存使用等
        5. 查询计划
            执行计划: 根据选定的查询计划, 逐步执行sql 语句
            中间结果处理: 执行过程中, 可能会有一些中间结果, 中间结果会在最终结果生成前被处理
        6. 返回结果
            结果集生成: 将最终的结果集返回给客户端, 可能是查询的结果, 可能是更新的影响数等等
            资源释放: 清理执行过程中使用的临时资源, 并对资源进行释放
        7. 事物处理
            如果SQL 是在事物中执行的, 数据库还需要执行事物的提交或回滚
        8. 日志记录
    存储引擎为什么默认选择innodb
        1. 支持事物
        2. innodb 是聚集索引, MyISAM 是非聚集索引
        3. 锁力度: innodb 最小是行锁，myIsam 是表锁
    索引
        适合当主键的字段
            1. 唯一性, 且不为空
            2. 递增的
                原因: 
                    1. 避免页分裂
                        1.1 尽可能的顺序写, 无需在中间插入数据
                        1.2 避免页分裂: 如果是随机的话, 新数据可能要在中间插入, 导致数据库对现有数据进行分割
                     	1.3 插入效率高
                    2. 缓存命中率比较高
                        2.1 减少缓存压力, 新的数据可以顺序写入和读取, 减少缓存中不断去进行对老数据替换
                        2.2 数据和索引的缓存优化: 如果主键是递增的, 最新的数据往往是在相邻页上, 这些页面可能已经被加载到了缓存中, 从而提高缓存命中率
                    3. 索引维护简单
                        3.1 顺序更新, 减少维护索引结构的复杂性
                        3.2 避免索引碎片: 随机主键会导致叶子结点不断被打乱, 产生大量的碎片, 需要频繁的进行索引重组. 顺序可以保证索引结构的稳定性增长
                    4. 空间利用率高
                        4.1 有助于更好的利用磁盘空间
                        4.2 减少数据碎片

            3. 不建议用业务字段, 无法预测未来是否重复
            4. 大多数情况下用唯一自增id

        聚集索引 和 非聚集索引区别:
            1. 数据存储上
                聚集索引和数据是存放在一起的, 聚集索引的叶子结点就是实际的数据行, 非聚集索引的叶子结点不包含完整的数据行, 而是包含指向完整数据行的指针或者是主键值, 数据行本身存储在聚集索引中
            2. 索引和数据关系上
                直接通过聚集索引可以找到数据行, 不需要额外的步骤去进行查找, 非聚集索引查找数据的时候, 现在非聚集索引中找到对应的主键值, 再通过主键值回溯到聚集索引上去找对应的数据行
            3. 唯一性上
                聚集索引是基于主键构建的, 每个表只能有一个主键, 一个表可以有多个非聚集索引
            4. 效率
                对于范围查询和排序查询, 聚集索引的查询效率更高, 因为避免了额外的寻址查询
                非聚集索引在使用覆盖索引进行查询的时候效率更高, 无需进行回表操作
            5. 使用场景
                聚集索引适合频繁的范围查询, 顺序插入, 大量返回完整行数据的
                非聚集索引适合更加频繁的多列查询, 覆盖索引查询
        B+ 树的叶子结点是双向链表
        联合索引的条件
            将区分度大的字段放在前面
        需要回表的：
            如果要查询的数据不再二级索引中, 就会先检查二级索引,  找到对应的叶子结点, 获取到主键的值, 再去主键索引查找
        覆盖索引
            一个索引列包含了查询的所有列, 不需要回表就可以完成查询
        查询的时候会尽量用联合索引
        索引的缺点
            1. 占用物理空间
            2. 创建和维护需要耗时, 随着数据量的变大而变大
            3. 降低表增删改的效率, 每次增删改, 需要动态更新索引
        需要用索引:
            1. 字段有唯一性限制
            2， 经常用于where 条件的
            3. 经常用于group by 或者是order by 的
        不适合的
            1. where group by order by 中用不到的字段
            2. 大量重复的字读
            3. 数据表很少的情况下
            4. 经常更新的字段
        防止索引失效
            1. like %xx 的 或者是like %xx% 的
            2. 索引列进行计算的
            3. 遵循最左匹配原则
            4. where 条件中 or 前后不是索引列的
        mysql 如何解决并发问题的
            1. 锁机制, 行级锁、表锁、页锁等
            2. 事物隔离级别
            3. MVCC
        隔离级别如何实现
            读已提交: 事物中只能读取到其他已提交的数据
                通过在语句语句执行之前生成一个read view, 因此可以保证每次读取的时候可以读取到其他事物提交后的数据
            可重复读 是通过在启动事物时生成一个read view, 整个事物期间都在用这个read view, 因此没办法防止幻读, 因为整个事物期间基于的视图时一样的

        MVCC: 多版本并发控制协议
            通过维护数据的多个版本, 允许事物在不加锁的条件下并发的读取数据,  从而提高系统的并发性和数据的一致性
            innodb 在每行的数据库上额外记录两个隐藏字段:
                创建版本号: 标识插入或者更新这行数据事物的id
                删除版本号: 标识删除这行数据事物的id，实际指向undo log的指针, 用于回滚或者读取旧版本
            工作过程:	
                1. 插入操作:
                    插入新行的时候, innodb会为这行记录事物ID 并创建版本号, 删除版本号为空
                2. 更新操作
                    更新数据的时候, 会在当前数据上创建新的版本, 更新创建版本号, 同时保留旧的版本号用于并发事物读取
                3. 删除操作
                    删除数据的时候, 不会立马去进行物理删除, 而是将删除记录在undo log 中, 同时给该行数据的删除版本号写入当前事物id
                4. 读取操作
                    根据当前的事物隔离级别, 会通过事物的id 和 版本号来判定是否可以看到特定的数据版本
            read view:
                是MVCC 中的一个概念, 表明特定时间点当前事物可以看到哪些数据f
                一致性试图: 当事物开始读取数据的时候,  该视图定义了可以看到的数据版本, 
                事物的范围: 当前系统中未提交的最早事物的id, 当前系统中最新的事物id, 当前还未提交的事物id
            优点: 
                高并发: 读操作不需要加锁, 避免了读写之间的冲突, 提升系统的能力
                数据一致性: 保证数据的一致性的同时, 提供了更高的查询能力
                避免思索: 读操作不需要加锁, 减少了死锁的发生
            缺点:
                额外的存储空间: 由于需要维护多个版本的数据, MVCC 会占用额外的存储空间
                版本链的管理: 随着数据的更新, 版本链可能变长
                复杂的实现
        mysql 中的锁:
            全局锁
                flush tables with read lock: 会将整个库设置为只读状态
            表锁

            行锁
                例如在select for update 的时候 或者update 的时候会用到拍他锁
                innodb 支持行锁
                记录锁
                    S锁
                    X锁
                gap 锁
                    防止幻读
                    BEGIN;
                    SELECT * FROM orders WHERE order_date &gt;= &#39;2023-01-01&#39; AND order_date &lt; &#39;2023-02-01&#39; FOR UPDATE;
                    -- 对指定日期范围内的间隙加锁，防止其他事务插入新的订单记录
                    COMMIT;
                next-key-lock

        一条update 是不是原子性的 
            是的, 通过undolog 来实现的
        大事物带来的问题
            1. 一个事物特别多的sql, 锁定的数据会特别多, 
            2. 回滚的时候会占用大量的空间
            3. 执行时间长 会导致主从延迟
        日志的分类:
            redo log: 实现了事物的持久性, 用于掉电等故障
            undo log: 实现了事物的原子性, 用于事物的回滚和MVCC
            bin log: server 生成的日志, 用于数据备份和主从复制
            relay log
        binlog: 记录了数据库表结构变更, 表数据修改的日志
            格式有STATEMENT(每一条修改数据的SQL 都会记录到日志中) 、row(记录每条数据的最终数据)、 MIXED
            主要用于主从复制的一致性, 可以精准的重新主库中所有数据的变更
        undoLog: 用于撤销回退的日志, 保证了ACID中的原子性
            在事物没有提交之前, 会将之前的日志记录到undoLog 中, 可以用来回滚
        redoLog: 保证数据的持久化
            1. redoLog 中记录事物完成后的数据, 记录的是更新后的值
            2. 可以确保在崩溃后, 通过redolog 可以将数据恢复到一致性状态
            3. 性能优化, redolog 允许mysql数据页的修改 可以异步的刷新到磁盘中去, 不必每次去写, 提高写性能
        能不能只有binlog 没有redoLog
            不能, binlog 是server 层的日志, 没办法记录哪些脏页还没有刷盘, redoLog 是引擎层的日志, 可以记录哪些数据没有刷盘, 崩溃恢复的时候可以通过它来进行恢复数据
        binlog redolog  undolog 关系
            binlog 是逻辑层面sql 的修改, 主要用于主从复制和数据恢复
            redolog 是物理层面数据页更改, 保证事物的持久性和恢复
            undolog 是数据的旧版本, 用于事物回滚和MVCC
        WAL 技术: 先写日志, 再在合适的时间点将数据刷新到磁盘上去
        事物提交的过程起的作用:
            undolog 记录旧版本数据, redolog 记录新数据, 事物提交时, redo log会先标记事物为prepare状态, 再写入binlog, 最后将事物标记为commit 再进行提交
        恢复的时候:
            redolog 来完成所有已提交事物的操作, 使用undolog 来进行事物的回滚, binlog 用于主从复制或者是后续重演事物
        binlog 的两阶段提交
            目的: 
                保持binlog 和 redo log 的一致性: 确保数据库崩溃后, 保证事物提交的原子性和一致性
                防止数据丢失: 如果事物已经提交到了redo log，但是没有写入到binlog 中, 在系统奔溃后恢复, 由于binlog 没有该事物的记录, 从而影响主从复制
                防止数据不一致: 如果事物已经写入到binlog 但是没有写入到redolog， 奔溃后恢复的时候会导致binlog 中有记录, 但是实际数据库没有应用, 导致数据不一致
            过程
                1. prepare 阶段
                    事物执行, innondb 会将事物的更改记录写入到redo log 中, 并将这些日志标记为 prepare 状态, 这意味着这些事物已经在操作了, 但是还未提交, 数据的修改刷新了内存中, 但是还没有刷新到磁盘
                2. commit 阶段
                    写入binlog， 在事物提交之前, 将事物的更改写入到binlog 中, 此时binlog 记录的是最终持久化的数据, 此时redolog 中数据还是处于prepare 状态
                    提交事物, 将redolog 中的事物标记为commit 状态, 一旦事物标记为commit, 数据页的修改会被刷新到磁盘上
            关键:
                顺序性和原子性:
                    先记录redolog 的prepare 状态, 再写入binlog, 最后提交redo log， 防止奔溃恢复时出现数据的不一致
                奔溃恢复
                    如果在写入binlog 后, 但是在提交redolog 之前的 发生了奔溃, mysql 在恢复时根据redolog 的prepare状态 和binlog 的记录继续完成提交, 确保事物的一致性
            update 的具体过程
                服务端处理的过程, 假设校验这些都过了
                1. 调用执行引擎查找对应的记录, 如果数据本来就是在buffer pool 中, 则直接返回, 没有的话从磁盘中读取到buffer pool。再返回
                2. 执行器查看更新后的数据是否和前面的是一样的，一样的话不做任何处理, 不一样的话，将更新前后的值传递给innodb 进行处理
                3. 开启事物, 先将记录记录到undo log 中, 将更新的旧数据记录到undo log中
                4. innodb 开始更新记录, 先更新内存, 同时标记为脏页, 将记录写入redolog 中, 为了减少磁盘的IO, 由后台线程将脏页数据写入到磁盘中
                5. 更新完成后, 记录该语句对应的binlog, 此时binlog 会保存到binlog cache 中, 在事物提交的时候统一将所有binlog刷新的磁盘上
                6. 事物提交
                    prepare 阶段 redolog 设置事物状态为prepare, 将redolog 刷盘
                    commit 阶段 binlog刷盘, 将redolog设置为commit
        主从复制
            主从复制: 
                1. 写入binlog
                2. 同步binlog
                3. 回放binlog
            主库在收到客户端的提交事物请求后, 先将数据写入到binlog 中,更新存储引擎中的数据, 再返回给客户端
            从库会起一个专门的IO 线程, 连接主库的log dump 线程, 接收主库的binlog日志, 再将binlog 信息relay log 到从库的中继日志
            从库创建一个专门回放binlog的线程, 去读relay log 中日志, 回放binlog 更新存储引擎中数据
            保证写数据的时候只写主库, 读的时候从从库读取
        主从延迟怎么处理
            强制从主库上读取
        分库分表
            分库: 将数据按照一定的规则划分到多个库中, 每个库只负责部分数据的存储, 为了解决单台mysql 扛不住的问题
            分表: 将数据分摊到不同的表上, 为了解决单个表太大的问题
            垂直分库: 按照业务功能
            水平分库: 同一个表按照一定的规则拆分
        MHA 如何实现主从切换
            MHA manager 会对主库的状态进行检测, 发送探测请求,ping 命令, 同时监控mysql 的错误日志和系统日志, 用来捕捉异常信息, 根据设定的阈值来判别主库是否发生了异常,
            重新选主的策略
                1. 复制延迟小, 选择延迟最小的从库, 减少数据不一致的风险
                2. 数据一致性 优先选择最具完整事物日志的从库
                3. 可用性: 当前运行良好的从库
            提升主库
                停止新主库的slave 进程, 使得不再继续同步, 重新命名realy log, 确保从库变为主库
                修改每个从库的change master to 命令, 让他指向到新的主库
                启动从库的slave 进程, 开始从新的主库上同步数据
        write-set
            每次提交的时候, 相当于对事物的写操作生成了一个集合
        WriteSet
            WriteSet 是一个集合, 包含了某个事物修改的所有操作的元数据,  可以用来冲突检测(将提交事物的writeset 和 其他节点中未提交的进行比较, 检测是否有冲突), 全局一致性

        MGR
            使用Paxos 一致性协议, 支持多主的模式, 集群内所有结点通过一致性写作, 决定事物的提交顺序, 检测到节点故障的时候, 自动从剩余的节点中选举出新的主节点(如果是单主的情况下)
            如何解决数据的冲突
                1. 基于组内通信的全局事物一致性
                    基于paxos 实现事物的全局一致性, 一个节点发起事物投票后, 事物会被广播到组内, 确保所有结点对该事物达成一致
                2. 冲突与检测处理
                    基于writeSet 的冲突检测机制: 每个事物提交的时候, MGR 会生成一个write-set, 记录了该事物中所有的修改, 相当于对该事物的写操作生成了一个集合
                    冲突检测: 当一个节点尝试提交事物的时候, 会将该事物的write-set 与组内其他节点已提交但未应用的事物write-set 进行比较, 判断是否有冲突发生
                3. 检测到冲突
                    丢弃冲突的事物: 根据事物的先后顺序, 来决定保留哪个事物, 通常是保留先提交的事物
                4. 冲突处理后的应用
                    处理完冲突后, MGR会将所有成功提交的事物 应用到每个节点上去. 确保所有结点数据的一致性
                5. 用户对冲突自行处理
                    1. 默认将数据写到某个节点上去, 按照节点的轮训, 避免冲突
    DTS:
        1. 怎么保证网络可用
        2. 高效同步???
        3. HA
        1. 语法转换和解析
        2. 迁移过程的一个高可用
            2.1 日志读取高可用
            2.2 日志回放高可用
            2.3 数据拉取的时候怎么控制速率和大小
        3. 源数据所在集群发生了变化怎么处理
        4. 全量迁移的时候需要同时进行增量
        5. 顺序ABA 问题


        零拷贝 
            1. 零拷贝指的是在IO时减少或者消除数据内存拷贝的次数以及CPU的参与, 使得数据在IO的时候可以更加高效
            主要实现手段:
            1. sendfile() 系统调用: 是linux 提供的一种系统调用, 可以直接将数据从文件描述符传输到网络套接字上, 不需要将数据复制到用户空间, 内核直接通过mmap 和 DMA 进行数据传输
            2. mmap 系统调用: 可以将文件映射到进程的地址空间, 这样进程可以直接在自己的地址空间访问文件内容, 不需要显示的读写
            3. DMA 技术, 通过DMA 允许设备直接访问内存, 无需经过CPU, 通过DMA,
            优点:
                1. 减少CPU的开销, 避免了不必要的内存拷贝
                2. 提高数据传输效率. 减少了数据的传输效率
                3. 减少上下文的切换. 减少用户态和内核态的上下文切换
        page cache
            是磁盘上的数据缓存到内存中的操作, 加速读写
            读操作:
                如果读取的时候数据已经在page cache 中, 则说明命中了直接返回, 避免了磁盘的IO
                如果读取的时候数据没有在page cache 中, 则从磁盘中获取并缓存到page cache中
            写操作
                预先将数据写入到page cache 中, 操作系统会在后台将page cache 数据写入到磁盘上去
            优点:
                提高读取速度: 加速磁盘的读取, 降低磁盘IO
                减少写入次数: 集中写的机制
                提高内存利用率: 操作系统会动态调整大小
            缺点:
                内存占用
                写入延迟

        netty 高低水位怎么控制发送速率, netty 怎么进行流量限流
            通过检测给外部发送的缓冲区数据是否超过了高低水位, 从而控制TCP的发送速率
            config.setWriteBufferHighWaterMark(64 * 1024); // 64KB 高水位线
            config.setWriteBufferLowWaterMark(32 * 1024);  // 32KB 低水位线
        java agent 机制

        ringBuffer
            是一种固定的环形缓冲区, 
            优点: 
                固定长度
                循环利用
                低延迟
                由于是固定内存的 因此减少GC压力


        id 生成器, 雪花算法,twitter 那个
            雪花算法的64位组成如下
            符号(1)_时间戳(41)_数据中心(5)_机器id(5)_序列号(12)


        



        磁盘 堆外读取

        mysql 中 Event 怎么理解????

        heartbeat_event 怎么理解???

        通过WRITE_BUFFER_WATER_MARK 控制发送速率


        数据一致性保证
        1. 时序保证: replicator 消费时顺序发送给applier
        2. At Least Once
            2.1 一边重启怎么处理
                replicator 重启的话 通过读取本地的gtid set
                applicator 重启的话 通过目标数据库当前执行过的gtid set 进行对比
            2.2 解决循环复制的问题
                set gtid_next 将该事物的gtid 设置为同步过来的gtid_event 中的GTID
                set gtid_next=GTID
        3. DDL 	

        netty
        java agent proxy-client


        ringbuffer

        DDL 怎么处理
        回环怎么处理
        大数据怎么处理??
        分布式id 生成器 算法
</code></pre>
<h4 id="netty-组建介绍"><a href="#netty-组建介绍" class="headerlink" title="netty 组建介绍"></a>netty 组建介绍</h4><h5 id="Channel-的作用-1"><a href="#Channel-的作用-1" class="headerlink" title="Channel 的作用"></a>Channel 的作用</h5><pre><code class="hljs">负责网络IO操作相关的
    1.1 管理IO 操作
        对数据读取、发送、和连接的管理
    1.2 处理事件
        从网络传输到channelPipeline, 将channelPipeline 处理后的数据返回到网络中去
    1.3 支持异步IO
        即将数据异步写入到网络中,不会阻塞当前线程
</code></pre>
<h5 id="EventLoop-作用-1"><a href="#EventLoop-作用-1" class="headerlink" title="EventLoop 作用"></a>EventLoop 作用</h5><pre><code class="hljs">1.每一个EventLoop 维护着一个 Selector 和 线程
2.处理IO 事件和任务
    监视和处理IO事件, 基于Java NIO 的selector 事件
3. 任务的调度
    还可以管理定时任务和普通任务, 可以提交任务到eventLoop上, 按照顺序和指定周期执行
4. 线程管理
    一个eventLoop通常和一个线程绑定, 每个eventLoop 可以维护多个channel, 但一个channel 始终绑定在一个eventLoop 上, 确保了同一个channel 上的事件处理是线程安全的
5. 事件的派发与处理
    负责从IO操作中获取事件, 将这些事件派发到对应的ChannelHandler中, 每个channel 代表一个连接或者IO操作, 在其pipeline中的一系列处理
</code></pre>
<h5 id="EventLoopGroup-作用-1"><a href="#EventLoopGroup-作用-1" class="headerlink" title="EventLoopGroup 作用"></a>EventLoopGroup 作用</h5><pre><code class="hljs">用于管理所有的EventLoop, 一个 EventLoopGroup 用于管理多个线程来并发去处理执行IO 事件
</code></pre>
<p>Channel 是网络通信的管道, 负责实际数据的读写, EventLoop 是负载驱动Channel 的 执行, 通过循环监听IO 事件来处理这些事件, EventLoopGroup 是多个EventLoop 的管理着, 负责分配和管理多个EventLoop, 并支持多并发处理多个Channel</p>
<h5 id="为什么需要将网络容器从tomcat-换成Netty-2"><a href="#为什么需要将网络容器从tomcat-换成Netty-2" class="headerlink" title="为什么需要将网络容器从tomcat 换成Netty"></a>为什么需要将网络容器从tomcat 换成Netty</h5><pre><code class="hljs">vmstat 1
可以检测上下文切换是否很高,
1. 实现机制上:
     serverlet 通过 startAsync 本质上依赖线程池去进行处理, netty天生为异步非阻塞的, 使用事件驱动的方式, 每个EventLoop 可以处理多个IO操作事件,可以极大的降低了线程数和线程切换的开销
2. 线程模型:
    serverlet 3.0异步依赖容器的线程管理, 在并发增加的情况下可能会导致线程的耗尽; netty 中使用少量的worker 线程来处理事件, 减少了上下文的切换, 避免了传统线程池模型的问题.
3. IO 模型
    serverlet 3.0 虽然支持异步处理, 但是底层依赖于阻塞IO模型; netty 使用java NIO 的非阻塞式, 从底层上确保了高并发表现的性能
4. 并发高的情况下 tomcat 由于采用的是BIO 加上异步线程的方式去处理的, 会有大量的线程产生, CPU 内存 文件描述符都会发生资源竞争，netty 是通过NIO 方式去做的，使用少量的worker 线程就可以去处理
</code></pre>
<h2 id="为什么要用netty-1"><a href="#为什么要用netty-1" class="headerlink" title="为什么要用netty"></a>为什么要用netty</h2><pre><code class="hljs">事件驱动模型:
    基于reactor模式去做的, 通过EventLoop来管理IO 操作事件, 并将这些事件派发给相关的channelHandler, 实现高效的网络通信, 可以处理大量的并发连接
    核心组建:
        eventLoop
        channel
        channelPipeline: 是一个处理链, 每个IO 事件都会按照顺序通过channelPipeline, 将多个channelHandler连接起来, 形成一条链, 每个channelHandler只负责处理特定的事件
        channelHandler: 用于处理特定类型事件的处理器, 不同的channelHandler 实现不同的功能, 有的可以用来编解码, 有的可以用来处理连接事件
        Selector: 用于监听多个Channel 上的IO 事件, 当selector 发现某个Channel 上有事件发生的时候, 会通过EvenetLoop 来进行处理
    工作流程:
        boosGroup 和 workerGroup
            bossGroup 负责监听客户端的连接请求事件, 将接收请求并将连接交给workerGroup进行处理
            workerGroup负责处理具体的IO 操作
        事件的监听与触发
            当有IO发生的时候, EventLoop 会从selector 中获取到该事件, 并将其传递给绑定的channel
            事件会按照事件类型依次在channelPipeline 上流过, 通过channelHandler 来具体处理
        channelHandler 处理事件
            入站事件有inbounder 处理, 出站事件由outbounder 处理
            每个channelHandler 可以对事件进行处理, 处理完成后让下一个处理器进行处理
    线程模型
        EventLoop 绑定一个线程, 因此EventLoop管理的channel 也是在同一个线程上去运行的, 确保每个channel 上的事件处理是安全的, 从而减少了上下文切换的开销		
支持零拷贝
    零拷贝指的是全程不需要CPU 进行参与, 所有数据都是通过DMA来进行传输的
    全程只需要2次上下文切换, 2次DMA数据copy
ByteBuf 好处:
    1. 容量可以动态的调整
    2. 支持零拷贝, 减少数据在不同内存区域之间的复制, 
    3. polling 机制 从而进行重复利用
</code></pre>
<h5 id="Netty-的一次网络请求过程是什么-1"><a href="#Netty-的一次网络请求过程是什么-1" class="headerlink" title="Netty 的一次网络请求过程是什么"></a>Netty 的一次网络请求过程是什么</h5><pre><code class="hljs">        客户端
            初始化:
                EventLoopGroup 的创建, 用于管理和服务之间网络链接和IO 操作, Bootstrap 配置客户端的各种参数, 包括线程模型, NioSocketChannel, 远端服务器的地址, 以及客户端的handler
            建立链接
                连接服务器: 通过Bootstrap.connect() 方法启动连接过程, 链接成功后会将channel 注册到event loop 上
                等待建立连接完成:  connect() 返回一个ChannelFuture, 可以通过sync() 或者是addListener 进行完成
            发送请求
                构造数据进行请求, 连接成功后, 通过channel 向服务器发送数据, 通常是将请求封装成 ByteBuf 
                对数据进行writeAndFlush 写数据, 数据会通过ChannelPipeline 的outbounder 进行处理, 通过底层的socket 发送到服务器
            接收响应
                pipeline 处理, 当服务器响应数据到的时候, 数据会到channelHander 的inbounder,
                处理响应数据: 业务逻辑进行处理, 处理完后返回给应用层
            关闭连接
                主动关闭连接: channel.close 关闭连接, 释放资源
                监听关闭操作: close 返回的future 进行监听, 进行监听关闭是否成功。
            资源清理
                group.shutDownGracefully() 进行清理
        服务端
            初始化阶段
                创建EventLoopGroup, bossGroup 和 workerGroup, bossGroup 负责接受请求, workerGroup 负责处理 BossGroup 分配过来的IO 操作
                配置 serverBootstrap : 使用 ServerBootstrap 来配置 Netty 服务, 包括 channel 的类型, 指定 EventLoopGroup, 配置 channelPipeline , 以及设置服务器的监听端口
            绑定端口
                serverBootStrap.bind() 方法绑定服务器的监听端口, 会启动一个异步操作过程, bossGroup 中的线程会监听这个连接请求
                bind() 返回一个future, 可以通过sync()  或者是addListener 来等待响应
            接受客户端请求
                bossGroup 中的线程会去监听端口的连接请求, 当有新的请求进来的时候, Netty会为这个连接创建一个channel, 并将其分配给worker 的EventLoop上,
                注册channel: 新的channel 会被注册在worker Group 中的eventLoop 上, 接下来和这个连接的相关读写操作都是在这个EventLoop 上
            处理客户端请求
                每个channel 关联的channelpipeline, 包含了一系列的handler
                当客户数据到达的时候, 数据会通过channelPipeline 中的inbounder 来进行处理, 负责数据的读取, 解码，业务逻辑处理等
            响应客户端
                当业务逻辑处理完后, 通过会通过ChannelHandlerContext.writeAndFlush() 将数据响应回给客户端
                数据会通过channelpipeline 中的outbounder，然后通过底层的socket 发送给客户端
            关闭连接
                客户端关闭连接, 或者是服务端主动关闭连接的时候, Netty 会处发ChannelInbounderHandler 的channelInactive 或者是channelUnregistered, 可以进行资源清理
                在关闭服务器的时候, 需要调用bossGroup 和worker Group 的shutdownGracefully 进行线程资源的释放
</code></pre>
<h3 id="项目准备"><a href="#项目准备" class="headerlink" title="项目准备"></a>项目准备</h3><pre><code class="hljs">1. yong gc 和full GC 如何优化的
    1.1 full gc 找到大的文件
    1.2 yong gc 在配置的快速变更期间, 导致客户端全都重新建立长轮训请求, 导致服务端的压力比较大, 服务端为了保证配置检测到配置文件的快速变更下发, 需要解析所有的配置文件版本号,以及和本地对比, 这部分数据都是瞬时压力比较大的, 因为客户端的数量比较多, 每次变更都是需要重新连上来, 因此一开始怀疑是不是Yong 区太小了, 导致yong 区GC 比较频繁, 因此将yong 区的大小调大 G1NewSizePercent, 观察效果. 同时由于我们采用的是G1 的算法, 他在yong gc 的时候会有STW, 导致处理耗时变长, 并且此时由于yong 区的对象比较多, 因此我们决定将G1 换成zgc, 第一步就是需要jdk 从1.8 升级到jdk11
    升级jdk 的时候有一些依赖 包的调整,  因为jdk11 引入了一些模块化, 一些类都废弃掉了. 升级完后再去将gc 方式换成zgc
</code></pre>
<ol>
<li>网关如何提高性能<br> 4C 8G<br> 请求方式就是一个healthCheck 响应ok 这种的<br> 1.1 一开始压测<br> 如何解决压不上去的问题<br> 1.2 发现CPU 一下子就上去了<br> 1.3 更换网络框架<br> 1.4 更换IO 模型</li>
<li>配置中心如何提升性能</li>
<li>用户体验上的???</li>
<li>单元测试上的</li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E9%9D%A2%E8%AF%95/" class="category-chain-item">面试</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>面经</div>
      <div>http://localhost:4000/2024/08/17/interview/面经/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>pc-xie</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年8月17日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/08/11/jvm/jvm%20%E6%95%B4%E7%90%86/" title="jvm 整理">
                        <span class="hidden-mobile">jvm 整理</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
