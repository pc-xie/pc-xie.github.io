

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="pc-xie">
  <meta name="keywords" content="">
  
    <meta name="description" content="操作系统epool 介绍 select: 允许程序监听一组文件描述符, 检查这些文件描述符是否可读、可写、是否发生异常 优点: 简单 缺点: 单进程有监听上限, 每次调用的时候需要遍历fd_set, 即使大部分文件描述符没有事件发生, 但是仍然需要去进行扫描 pool: 使用动态数组来存储文件描述符及其感兴趣的事件, 而不是固定的大小fd_set 优点: 可以解决select 中对于文件描述符上限">
<meta property="og:type" content="article">
<meta property="og:title" content="技术总结">
<meta property="og:url" content="http://localhost:4000/2024/08/17/interview/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/index.html">
<meta property="og:site_name" content="pc-xie">
<meta property="og:description" content="操作系统epool 介绍 select: 允许程序监听一组文件描述符, 检查这些文件描述符是否可读、可写、是否发生异常 优点: 简单 缺点: 单进程有监听上限, 每次调用的时候需要遍历fd_set, 即使大部分文件描述符没有事件发生, 但是仍然需要去进行扫描 pool: 使用动态数组来存储文件描述符及其感兴趣的事件, 而不是固定的大小fd_set 优点: 可以解决select 中对于文件描述符上限">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://localhost:4000/img/tcp/tcp_start_connection.png">
<meta property="og:image" content="http://localhost:4000/img/tcp/tcp_finish_connection.png">
<meta property="og:image" content="http://localhost:4000/img/jdk/threadState.png">
<meta property="og:image" content="http://localhost:4000/img/jdk/hashMap_put.png">
<meta property="article:published_time" content="2024-08-17T05:20:30.839Z">
<meta property="article:modified_time" content="2024-10-11T08:34:42.198Z">
<meta property="article:author" content="pc-xie">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/img/tcp/tcp_start_connection.png">
  
  
  
  <title>技术总结 - pc-xie</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"localhost","root":"/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="技术总结"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-08-17 13:20" pubdate>
          2024年8月17日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          94k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          781 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">技术总结</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h1><h2 id="epool-介绍"><a href="#epool-介绍" class="headerlink" title="epool 介绍"></a>epool 介绍</h2><ol>
<li>select: 允许程序监听一组文件描述符, 检查这些文件描述符是否可读、可写、是否发生异常<br> 优点: 简单<br> 缺点: 单进程有监听上限, 每次调用的时候需要遍历fd_set, 即使大部分文件描述符没有事件发生, 但是仍然需要去进行扫描</li>
<li>pool: 使用动态数组来存储文件描述符及其感兴趣的事件, 而不是固定的大小fd_set<br> 优点: 可以解决select 中对于文件描述符上限的限制<br> 缺点: 每次调用的时候需要遍历文件描述符</li>
<li>epool: 基于事件的通知机制, 只会通知应用程序哪些文件描述符发生了变化, 而不是遍历所有的文件描述符<br> 过程:<br>     1. epool_create: 创建一个epool 实例<br>     2. epool_ctl: 使用epool_ctl 进行注册, 修改 或者删除要监控的文件描述符, 文件描述符及其感兴趣的事件会放到红黑树中去进行管理<br>         epool 使用红黑树的目的:<br>             高效的插入和删除, 对于频繁的注册和注销 操作复杂度为logn<br>             有序性:<br>             支持快速查找: 在支持大量的文件描述符时, 可以快速的查找,红黑树可以以logn 的时间去进行查找<br>             避免退化: 最坏情况下可以避免退化<br>     3. epool_wait: 等待事件发生, 当有事件发生的时候, epool 会将发生事件的文件描述符放入到一个链表中, 并通过epool_wait 返回<br> 两种工作模式:<br>     1. 水平触发: 默认模式, 只要文件描述符上有事件未处理, epool_wait 会持续返回<br>         特性: 只要文件描述符状态为可读或者可写, epool wait 每次调用都会返回该文件描述符, 意味着如果有数据可读, 会进行持续通知<br>         优点: 简单易用, 不容易丢失事件,适合处理高并发 和 不确定性高的场景, 尤其是应用程序可能未及时处理所有可读数据<br>     2. 边缘触发: 只在事件发生瞬间通知一次, 之后不会再次通知<br>         特性: 只有在状态发生变化的时候才进行通知, 例如从不可读变为可读, 要求应用程序尽快接受到事件后处理所有数据<br>         优点: 提高性能, 减少系统的调用次数, 适合处理大量并发连接的场景, 因为减少了不必要的通知<br> 事件复杂度为O(1)<br>     netty 中可以通过设置EpollChannelOption 来进行设置</li>
</ol>
<h2 id="进程间调度算法"><a href="#进程间调度算法" class="headerlink" title="进程间调度算法"></a>进程间调度算法</h2><pre><code class="hljs">1. 先来先服务
    原理: 按照进程到达就绪队列的顺序分配CPU时间, 最早到的进程先运行
    优点: 简单, 进程不需要设置优先级或者是复杂处理
    缺点: 平均等待时间长, 不可抢占
2. 短作业优先
    原理: 优先调度运行时间最短的进程, 以减少系统的平均等待时间
    优点: 在理想情况下, 可以最大化吞吐量,以最小化平均等待时间
    缺点: 不可预测性, 无法提前知道进程运行的时间, 可能导致某个进程长时间无法得到运行
3. 优先调度
    为每个进程设置一个优先级, 优先级高的优先获得CPU的分配, 优先级可以调整
    优点: 可以根据进程的优先级按照重要的进程先运行
    缺点: 饥饿问题, 低优先级的可能永远无法运行
4. 轮训
    每个进程按照时间片的顺序进行执行, 每个进程执行一小段时间后就让出CPU, 如果时间片用完了, 进程放回到就绪队列的末尾
    优点: 适用于时间共享的系统, 保证所有进程公平的得到CPU 时间
    缺点: 时间片大小对系统的性能影响比较大
5. 公平调度
</code></pre>
<h2 id="进程间通信"><a href="#进程间通信" class="headerlink" title="进程间通信"></a>进程间通信</h2><pre><code class="hljs">管道: 父子进程之间使用较为简单, 不适合跨多个无关的进程
消息队列: 支持异步通信, 可以在不同进程之间传递数据
共享内存: 但是需要同步机制避免多个进程之间访问产生的竞争条件
信号: 信号是异步的, 可以用于进程的中断, 但是不可以传递大量数据
socket: 适合在不同机器或者是跨网络的进程之间通信
</code></pre>
<h2 id="线程间通信"><a href="#线程间通信" class="headerlink" title="线程间通信"></a>线程间通信</h2><pre><code class="hljs">共享变量
wait / notify
信号量
锁
</code></pre>
<h2 id="发送整个请求的流程"><a href="#发送整个请求的流程" class="headerlink" title="发送整个请求的流程"></a>发送整个请求的流程</h2><pre><code class="hljs">1. 客户端生成请求
    1.1 用户对请求进行触发
    1.2 DNS 解析, 将域名转换成服务器的IP 地址
    1.3 生成HTTP 请求
2. TCP 建立连接
    2.1 三次握手
    2.2 如果是HTTPS 的话, 客户端和服务端还需要进行TLS 握手, 协商加密算法, 交换密钥, 确保通信的安全
3. HTTP 请求发送
    3.1 请求发送, 客户端通过已建立的TCP 连接向服务端发送HTTP 请求, 包括请求的URL, 请求方法, HTTP 版本, 请求头, 请求体等信息
    3.2 如果请求比较大, 会进行份块发送
4. 服务端接受请求并进行处理
    4.1 解析HTTP 请求, 服务端收到TCP 数据包后, 解析出HTTP 请求内容, 包括请求行, 请求头和请求体
    4.2 路由和控制器处理
    4.3 后端处理
    4.4 生成HTTP 响应
5. HTTP 响应发送
    响应封装: 服务端将处理好后的数据打包生成HTTP 响应报文
    数据发送: 响应报文可能被拆分为多个TCP 包, 通过网络发送到客户端
6. 客户端接受响应
    解析HTTP 响应: 客户端收到响应的数据并进行解析, 获取状态吗, 响应头和响应体
    现实结果
7. TCP 关闭连接

如何优化:
    减少DNS解析的时间
    优化TCP 握手: 使用keepa-live 使用长连接
    优化TLS: 使用http2
    压缩和优化数据: gzip 压缩
    使用缓存
    负载均衡和CDN
    优化数据库访问
</code></pre>
<h2 id="stackoverflow-通常是怎么引起的"><a href="#stackoverflow-通常是怎么引起的" class="headerlink" title="stackoverflow 通常是怎么引起的"></a>stackoverflow 通常是怎么引起的</h2><pre><code class="hljs">1. 递归深度过深
2. 虚拟机栈 -xss 设置太小了
</code></pre>
<h2 id="一致性哈希"><a href="#一致性哈希" class="headerlink" title="一致性哈希"></a>一致性哈希</h2><ol>
<li>步骤:<br>1.1 哈希环构建: 将哈希空间看成一个环, 哈希值的范围是0 到 2^32 -1, 第一个哈希值和最后一个哈希值连成一个环<br>     每个节点: 通过哈希函数的到哈希值, 将这个节点映射到环上的一个点<br>     每个数据: 通过相同的哈希计算哈希值, 并将数据映射到环上<br>1.2 数据映射到节点: 数据存储的节点通过顺时针查找的方式确定, 顺时针找到的第一个节点就是存储该数据的节点<br>1.3 节点增加或删除的数据移动<br>     增加节点: 将新节点负载的哈希区间数据移动到该点<br>     删除节点: 将该节点负责的数据移动到下一个节点</li>
<li>防止数据分配不均匀<br> 虚拟节点: 增加虚拟节点, 让在哈希环上的分布变得均匀</li>
</ol>
<h1 id="网络协议"><a href="#网络协议" class="headerlink" title="网络协议"></a>网络协议</h1><h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><h3 id="TCP-粘包"><a href="#TCP-粘包" class="headerlink" title="TCP 粘包"></a>TCP 粘包</h3><p>TCP 面向连接的流式传输, 他将应用层的数据看成是一个连续的数据流, 不关心数据的边界, 因此在发送数据的时候, 可能将多个小的数据块合并成一个大的数据块, 从而导致发生了粘包</p>
<h3 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h3><p>三次握手（Three-way Handshake）其实就是指建立一个TCP连接时，需要客户端和服务器总共发送3个包。进行三次握手的主要作用就是为了确认双方的接收能力和发送能力是否正常、指定自己的初始化序列号为后面的可靠性传送做准备。实质上其实就是连接服务器指定端口，建立TCP连接，并同步连接双方的序列号和确认号，交换TCP窗口大小信息。<br>刚开始客户端处于 Closed 的状态，服务端处于 Listen 状态。<br>进行三次握手：</p>
<ol>
<li>第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN(c)。此时客户端处于 SYN_SEND 状态。<br>其中SYN&#x3D;1，初始序号seq&#x3D;x，SYN&#x3D;1的报文段不能携带数据，但要消耗掉一个序号。</li>
<li>第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)。同时会把客户端的 ISN + 1 作为ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_RCVD 的状态。<br>在确认报文段中SYN&#x3D;1，ACK&#x3D;1，确认号ack&#x3D;x+1，初始序号seq&#x3D;y。</li>
<li>第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 ESTABLISHED 状态。服务器收到 ACK 报文之后，也处于 ESTABLISHED 状态，此时，双方已建立起了连接。<br>确认报文段ACK&#x3D;1，确认号ack&#x3D;y+1，序号seq&#x3D;x+1（初始为seq&#x3D;x，第二个报文段所以要+1），ACK报文段可以携带数据，不携带数据则不消耗序号。<br>发送第一个SYN的一端将执行主动打开（active open），接收这个SYN并发回下一个SYN的另一端执行被动打开（passive open）。<br>在socket编程中，客户端执行connect()时，将触发三次握手。<br><img src="/../img/tcp/tcp_start_connection.png" srcset="/img/loading.gif" lazyload alt="三次握手"></li>
</ol>
<h3 id="为什么需要三次握手"><a href="#为什么需要三次握手" class="headerlink" title="为什么需要三次握手"></a>为什么需要三次握手</h3><ol>
<li>可以阻止重复历史连接的初始化: 客户端先发送了一个SYN 报文, 然后客户端宕机了, 同时这个SYN 报文被网络阻塞了, 服务端没有收到, 接着客户端重启, 又向服务端发起了建立连接, 发送了SYN 报文. 三次握手可以进行阻止, 如果旧的报文先到, 那服务端响应的ACK的给客户端的时候, 客户端会响应一个RST, 如果是两次握手的话, 服务端在第一次握手后就进入了ESTABLISHED 状态, 但是服务端无法识别是否为历史连接, 此时服务端由于是established, 那可以进行数据的传输, 但是由于客户端是知道的, 再客户端响应RST 之前, 数据传输是浪费的</li>
<li>同步双方的初始化序列号</li>
<li>避免资源的浪费: 假设只有两次握手, 第一个发过去的包, 由于网络等原因, 滞后了,然后又重新发送了一个数据包给服务端,此时服务端收到了第二次发过来的数据包, 并进行了建立链接,进行了响应, 后面发送过去的第一个数据包也到了服务端,服务端进行了建立链接, 等到客户端数据传输,此时客户端由于没有数据需要传输会忽略这个请求, 而服务端一直等着数据的传输,造成资源的浪费。</li>
</ol>
<h3 id="三次握手中传输数据可以不"><a href="#三次握手中传输数据可以不" class="headerlink" title="三次握手中传输数据可以不"></a>三次握手中传输数据可以不</h3><p>  在第三位次握手的时候可以进行发送数据, 在第一次握手的时候是不行的, 防止被恶意攻击,如果第一次就可以进行数据传输的话, 攻击者可以发送大量的SYN 包, 其中携带了大量的数据,由于服务端收到数据后要对数据进行解析处理, 造成服务端资源的浪费</p>
<h3 id="三次握手的目的"><a href="#三次握手的目的" class="headerlink" title="三次握手的目的"></a>三次握手的目的</h3><p>  交换初始化序列号和确认号, 为后面的可靠性传输做保证, 阻止历史连接的初始化</p>
<h4 id="第二次握手的报文丢失了"><a href="#第二次握手的报文丢失了" class="headerlink" title="第二次握手的报文丢失了"></a>第二次握手的报文丢失了</h4><ol>
<li>客户端会重传SYN 报文</li>
<li>服务端会重传SYN+ACK 报文</li>
</ol>
<h4 id="第三次握手的报文丢失了"><a href="#第三次握手的报文丢失了" class="headerlink" title="第三次握手的报文丢失了"></a>第三次握手的报文丢失了</h4><ol>
<li>ACK 报文不会重传, 因此服务端会重发</li>
</ol>
<h4 id="半连接和全连接"><a href="#半连接和全连接" class="headerlink" title="半连接和全连接"></a>半连接和全连接</h4><pre><code class="hljs">半连接队列: SYN 队列
    定义: 用来存储尚未完成三次握手的 TCP 连接的请求队列, 当服务端收到来自客户端的 SYN  包时, 会将该请求队列放到 SYN 队列中, 并响应一个 SYN-ACK
    状态: 此时连接处于 SYNC_RECEIVE 状态, 表示服务端收到了连接的请求, 但是尚未完成连接的建立
    容量: 当 SYN 队列满了后, 新的请求连接将会被拒绝或者丢弃, 可能导致客户端的连接超时或者重试
全连接队列: ACCEPT 队列
    定义: 用于存储完成三次握手的TCP 请求连接队列, 当服务端发送一个 SYN_ACK 后, 客户端会响应一个ACK 报文, 连接建立完成, 服务端将该连接放入到 ACCEPT 队列中
    状态: 在此阶段, 连接处于 established 状态, 表示建立连接完成, 可以用来对数据进行传输
    处理: 应用程序调用 accept 函数, 从accept 队列中获取一个可用的连接, 每次调用的accept, 都会将accept 队列中的一个连接转移到用户空间
</code></pre>
<h3 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h3><p>建立一个连接需要三次握手，而终止一个连接要经过四次挥手（也有将四次挥手叫做四次握手的）。这由TCP的半关闭（half-close）造成的。所谓的半关闭，其实就是TCP提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力。<br>TCP 的连接的拆除需要发送四个包，因此称为四次挥手(Four-way handshake)，客户端或服务器均可主动发起挥手动作。<br>刚开始双方都处于 ESTABLISHED 状态，假如是客户端先发起关闭请求。四次挥手的过程如下：</p>
<p>第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于 FIN_WAIT1 状态。<br>即发出连接释放报文段（FIN&#x3D;1，序号seq&#x3D;u），并停止再发送数据，主动关闭TCP连接，进入FIN_WAIT1（终止等待1）状态，等待服务端的确认。<br>第二次挥手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 +1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT 状态。<br>即服务端收到连接释放报文段后即发出确认报文段（ACK&#x3D;1，确认号ack&#x3D;u+1，序号seq&#x3D;v），服务端进入CLOSE_WAIT（关闭等待）状态，此时的TCP处于半关闭状态，客户端到服务端的连接释放。客户端收到服务端的确认后，进入FIN_WAIT2（终止等待2）状态，等待服务端发出的连接释放报文段。<br>第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。<br>即服务端没有要向客户端发出的数据，服务端发出连接释放报文段（FIN&#x3D;1，ACK&#x3D;1，序号seq&#x3D;w，确认号ack&#x3D;u+1），服务端进入LAST_ACK（最后确认）状态，等待客户端的确认。<br>第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 +1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过2MSL(2个报文最大生存周期)以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态，服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。其中MSL 的默认值60 秒<br>即客户端收到服务端的连接释放报文段后，对此发出确认报文段（ACK&#x3D;1，seq&#x3D;u+1，ack&#x3D;w+1），客户端进入TIME_WAIT（时间等待）状态。此时TCP未释放掉，需要经过时间等待计时器设置的时间2MSL后，客户端才进入CLOSED状态。<br>其中重传的超时事件和MSL 没关联<br>重传超时时间为1s + 2s + 4s + 8s 在120以内即可</p>
<p>收到一个FIN只意味着在这一方向上没有数据流动。客户端执行主动关闭并进入TIME_WAIT是正常的，服务端通常执行被动关闭，不会进入TIME_WAIT状态。<br><img src="/../img/tcp/tcp_finish_connection.png" srcset="/img/loading.gif" lazyload alt="四次挥手"></p>
<h3 id="假设中间有丢失的"><a href="#假设中间有丢失的" class="headerlink" title="假设中间有丢失的"></a>假设中间有丢失的</h3><ol>
<li>第一次挥手丢失<br> 客户端会进行重传, 如果重传到一定次数后, 会进入到closed 状态</li>
<li>第二次挥手丢失<br> 由于ACK 是不会进行重传的, 因此客户端会进行重传FIN</li>
<li>第三次挥手丢失<br> 服务端会进行重传, 到达最大次数后, 服务端会断开链接</li>
<li>第四次挥手丢失<br> 服务端会重发FIN,</li>
</ol>
<h3 id="为什么是四次挥手-三次可以不"><a href="#为什么是四次挥手-三次可以不" class="headerlink" title="为什么是四次挥手, 三次可以不"></a>为什么是四次挥手, 三次可以不</h3><p>  四次挥手是由于TCP 链接中, 发送方在结束他的发送后, 还能继续接受另外一端的数据, 在关闭连接的时候, 服务端收到了客户端发过来的FIN报文, 此时数据传输不一定完成了, 因此不可以直接对客户端响应一个ACK+FIN, 先对客户端进行响应一个ACK, 等需要发送的数据全都发完后, 再去发送一个FIN报文给发送方</p>
<h3 id="2MSL-作用是什么"><a href="#2MSL-作用是什么" class="headerlink" title="2MSL 作用是什么"></a>2MSL 作用是什么</h3><ol>
<li>保证客户端发送的最后一个ACK报文段能够到达服务端。<br>  假设客户端发送完ACK后不去等待直接进行关闭,如果客户端在发送完ACK后不等待直接进行关闭，那么在网络原因等情况下，最后一个ACK报文段可能会丢失，导致服务器无法收到客户端发送的FIN-ACK的确认报文，从而无法正常进入关闭连接状态。此时，服务器会超时重传FIN-ACK报文，而客户端却已经关闭了连接。此时，服务器会收到客户端发送的RST报文，导致连接异常关闭。另外，如果客户端在2MSL时间内重新发送了一个新的连接请求，而这个连接请求的端口与之前的连接相同，服务器可能会收到之前连接的滞留报文，从而导致混淆。因此，2MSL的等待时间可以避免这种混淆的发生，保证连接的正常关闭。</li>
<li>防止“已失效的连接请求报文段”出现在本连接中。<br>  客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段。</li>
</ol>
<h3 id="TIME-WAIT-过多的危害"><a href="#TIME-WAIT-过多的危害" class="headerlink" title="TIME_WAIT 过多的危害"></a>TIME_WAIT 过多的危害</h3><ol>
<li>占用系统的资源</li>
<li>占用端口多<br> 怎么优化:<br> net.ipv4.tcp_tw_reuse 和 tcp_timestamps: 可以复用TIME_WAIT 的socket 为新的连接, 会选择time_wait 超过1秒的连接给新的连接复用<br> 程序中使用 SO_LINGER 程序中跳过TIME_WAIT 返回RST关闭<br>到达上限的原因: 使用短链接, 长连接超时, 请求过多</li>
</ol>
<h3 id="TCP-保活机制"><a href="#TCP-保活机制" class="headerlink" title="TCP 保活机制"></a>TCP 保活机制</h3><p>发生宕机后, 服务端可以感知客户端的宕机事件<br>    1. 对端正常, 则等待下一个保活事件<br>    2. 对端重启, 对方相应一个RST, 说明连接被重置<br>    3. 对端死亡, 到达一定次数后, TCP 连接死亡</p>
<h3 id="四次挥手的目的"><a href="#四次挥手的目的" class="headerlink" title="四次挥手的目的:"></a>四次挥手的目的:</h3><p>通信双方可以正确的关闭并释放连接资源</p>
<h2 id="dubbo、http-各个版本协议对比"><a href="#dubbo、http-各个版本协议对比" class="headerlink" title="dubbo、http 各个版本协议对比"></a>dubbo、http 各个版本协议对比</h2><h3 id="dubbo-失败重试的策略"><a href="#dubbo-失败重试的策略" class="headerlink" title="dubbo 失败重试的策略"></a>dubbo 失败重试的策略</h3><p>失败重试的策略<br>    1.1 快速失败策略: 请求失败, 直接把异常跑出去<br>    1.2 失败安全策略:<br>    1.3 失败自动恢复策略: 后台记录失败请求, 通过定时任务对失败请求进行充实<br>    1.4 并行调用多个服务: 把消息广播给服务提供者集群, 只需要一个返回成功即可<br>    1.5 广播调用策略: 逐个调用服务提供者的集群, 只要集群中任何一个节点返回异常, 表示本次请求失败</p>
<h3 id="dubbo-核心组建"><a href="#dubbo-核心组建" class="headerlink" title="dubbo 核心组建"></a>dubbo 核心组建</h3><ol>
<li>服务的提供方</li>
<li>服务的消费者</li>
<li>注册中心</li>
</ol>
<h3 id="dubbo-请求过程"><a href="#dubbo-请求过程" class="headerlink" title="dubbo 请求过程"></a>dubbo 请求过程</h3><pre><code class="hljs">服务注册:
    服务的提供方在启动的时候将请求接口、方法、版本协议等信息注册到注册中心上
    服务的消费者从注册中心订阅所依赖服务的信息, 注册中心会返回服务提供者地址的列表
服务发现
    服务发现的过程, 服务的消费者会从注册中心拉取到服务提供者的列表并保存到本地缓存中, 当有新的服务的提供方或者老的服务提供方需要下线的时候, 注册中心会通知消费者, 消费者动态更新服务的提供者列表
服务准备调用
    proxy 生成: 服务的消费者使用动态代理机制, 生成服务接口的代理对象, 当消费者调用接口方法时, 实际上是调用这个接口对象的方法
    Cluster &amp; LoadBalance
网络通信准备
    编码和序列化: 代理对象将方法调用, 参数信息封装成一个RPC请求, 通过编解码器对请求进行序列化和反序列化
    Netty 通道管理: 使用Netty 作为底层通信框架, 消费者和提供方之间的通信依赖Netty 去进行传输数据
发送请求
    consumer: 消费者通过Netty 客户端将序列化后的RPC 请求发送到指定的服务提供方
    provider: 提供方的Netty server 会去接收请求, 并将其传递给指定的服务处理线程池去进行处理
请求处理
    服务的提供方接收到请求并对接收到的数据进行反序列化, 恢复出原始请求对象
    调用服务: 服务的提供方根据请求对象的服务名、方法名、通过反射的方式执行实际的业务逻辑
    返回结果: 提供方将执行结果返回给响应对象, 并序列化后, 返回给发送方
接收响应
    consumer: 消费者的Netty 客户端接收到响应后, 并将其反序列化成对象
    结果处理: 将拿到的结果反序列化成对象返回给上层调用者
服务调用完成
    上层的程序获得结果, 整个RPC 请求结束
</code></pre>
<h3 id="grpc-和-dubbo-的对比"><a href="#grpc-和-dubbo-的对比" class="headerlink" title="grpc 和 dubbo 的对比"></a>grpc 和 dubbo 的对比</h3><pre><code class="hljs">grpc 直接基于http2.0 的, 默认使用 protobuf 来进行序列化和反序列化
dubbo 可以使用 Hessian、Kryo、Java 序列化 等
dubbo 反序列化
    Protobuf：适合需要高效、跨语言通信和数据存储的场景，特别是在需要数据结构化的分布式系统和微服务架构中非常有用。
    Kryo：专注于Java生态系统，提供高效的二进制序列化，适用于高性能计算和需要优化网络传输的应用。
    FastJson：适合Web开发，特别是需要与前端进行数据交换的场景，尽管在性能上不如二进制序列化框架，但其易用性和广泛的语言支持使其非常流行。
    Hessian2：用于分布式系统中的跨语言通信，适合需要轻量级二进制传输协议的场景，但在Java内部应用中，Kryo可能会有更好的性能表现。   
</code></pre>
<h3 id="http1-1-2-0-QUIC-协议对比"><a href="#http1-1-2-0-QUIC-协议对比" class="headerlink" title="http1.1 2.0 QUIC 协议对比"></a>http1.1 2.0 QUIC 协议对比</h3><pre><code class="hljs">HTTP 1.X 存在的问题  
    单向请求: 只能单向请求, 不可以服务端主动给客户端发送响应
    协议开销大: header里携带的内容过大，且不能压缩，增加了传输的成本。
    队头阻塞: 下个请求必须要等待前面请求返回后, 才可以发出。导致带宽无法被利用
HTTP2.0 怎么针对上述问题解决的
    多路复用:  通过使用二进制帧来对数据进行传输, 不再是Http 1.x 的纯文本协议, 所有的请求都被分割成了更小的数据帧, 这些帧可以在网络中按照任意顺序发送, 接收方再根据帧的标识符进行重组, 提高了带宽的利用率
    消除对头阻塞: 通过多路复用来允许多个请求和响应再同一个TCP 连接上进行传输, 从而消除了对头阻塞问题
    减少了延迟: 多路复用可以使得数据流并行传输, 每个数据流有唯一的标示, 并且可以是无序的, 降低了延迟
    减少连接开销: 可以共用链接
http1.1 升级到2.0
    服务端和客户端需要升级改动
    其中https 加密不是必须的
HTTP2.0的问题
    TCP 层面的队头堵塞问题: 
        TCP的顺序性:  发送方的某个数据包在传输过程中丢失了, 接收段需要等待重传的丢失包才可以处理后续的数据包, 导致了TCP 的队头堵塞
        TCP 传输时某个数据流的数据包丢失了, 会导致后续的数据流堵塞, 因为TCP 需要等待丢失的数据包和重传
    对比Http1.x 的话: 使得TCP的队头堵塞影响整个链接上的请求和响应, HTTP1.x 的话只影响对应链接的请求和响应
可以通过QUIC 和 http3.0 去进行解决
    基于UDP 去实现的
    QUIC 实现了TCP + HTTPS + HTTP/2的功能，目的是保证可靠性的同时降低网络延迟
    安全性: 
        1. 对于首次建立链接的: 需要交换密钥 消耗一次RTT, 再发送业务数据
        2. 对于非首次的, 通过diff-Hellman 来进行密钥交换, 
    链接的唯一性基于64位的connection id
    如何解决队头堵塞问题:
        1. 基于UDP
        2. 数据包级别的确认, 如何确定数据包是否一致 : 通过Stream ID 来标识当前数据流属于哪个资源请求, 同时增加stream offset 确认在数据流中的位置, 两个确定数据包重传 
</code></pre>
<h3 id="HTTPS-的过程"><a href="#HTTPS-的过程" class="headerlink" title="HTTPS 的过程"></a>HTTPS 的过程</h3><pre><code class="hljs">1. 客户端发起请求
2. 服务器收到请求后, 向客户端发送数字证书(SSL/TLS 证书), 证书包含服务器的公钥和CA 签名的信息
3. 客户端验证证书
3.1 客户端检验证书、查看证书的有效期、证书链接、证书的域名是否和服务器匹配       防止中间人攻击
3.2 如果证书不可信, 客户端会警告用户并提示
4. 客户端使用生成会话密钥, 信息通过公钥进行加密, 服务器使用私钥进行解密。        确保只有对应私钥的才可以进行揭秘
5. 客户端和服务端双方拥有会话密钥后, 通过会话密钥进行对数据传输
6. 数据传输
</code></pre>
<h1 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h1><h2 id="Mysql"><a href="#Mysql" class="headerlink" title="Mysql"></a>Mysql</h2><h3 id="char-和-varchar的区别"><a href="#char-和-varchar的区别" class="headerlink" title="char 和 varchar的区别"></a>char 和 varchar的区别</h3><pre><code class="hljs">char: 固定长度的字符类型, 定义时需要指定字符长度, 不够的时候会在末尾补足空格, 适合存储固定长度的
varchar:可变长度的字符串类型, 存储时需要指定最大长度,存储的时候根据实际长度占用存储空间
</code></pre>
<h3 id="in-和-exist-的区别"><a href="#in-和-exist-的区别" class="headerlink" title="in 和 exist 的区别"></a>in 和 exist 的区别</h3><pre><code class="hljs">in 表示左边表达式是否存在于右边, 返回true or false
exist 可以返回一行数据
性能上的差异:
    exists 的性能要比in 好, 尤其是在表比较大的情况下, 因为exist 找到一条后就立刻返回停止查询, in 需要遍历整个子查询
使用场景:
    查询子集合较小并且变动属于低频的, in 更加直观,  当子查询涉及到外部查询的每一行判断的时候,  并且子查询效率较高, exist 更为合适
null 值的处理:
    in 可以正确处理子查询中包含null 的情况, 而exist 不受子查询结果中null  值的影响
</code></pre>
<h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><h4 id="索引分类"><a href="#索引分类" class="headerlink" title="索引分类"></a>索引分类</h4><ol>
<li>逻辑功能分类:<br>1.1 普通索引:没有任何约束条件, 用户提高查询的效率<br>1.2 唯一索引: 在普通索引的基础上增加了唯一性约束的条件, 一张表里面可以有多个唯一索引<br>1.3 主键索引: 在唯一索引的基础上增加了不为空的约束条件, 一张表里面最多有一个主键索引</li>
<li>物理实现分类<br>2.1 聚集索引: 基于表的主键列的索引, 索引的叶子节点存储了实际的数据行, 一张表只能有一个聚集索引, 通常为主键索引<br>2.2 非聚集索引: 叶子节点存储了索引的值和一个指向数据实际存储位置的指针, 一个表可以有多个非聚集索引</li>
<li>字段个数<br>3.1 单一索引: 索引列为一个的索引<br>3.2 联合索引: 多个列组合在一起的索引</li>
</ol>
<h4 id="什么时候需要创建索引"><a href="#什么时候需要创建索引" class="headerlink" title="什么时候需要创建索引:"></a>什么时候需要创建索引:</h4><ol>
<li>字段的数值有唯一性的限制，比如用户名</li>
<li>频繁作为 WHERE 查询条件的字段</li>
<li>需要经常 GROUP BY 和 ORDER BY 的列</li>
<li>UPDATE、DELETE 的 WHERE 条件列</li>
</ol>
<h4 id="无需创建索引"><a href="#无需创建索引" class="headerlink" title="无需创建索引:"></a>无需创建索引:</h4><ol>
<li>如果表记录太少</li>
<li>where 条件中用不到的列</li>
<li>字段中如果有大量重复数据，也不用创建索引，比如性别字段</li>
</ol>
<h4 id="索引失效"><a href="#索引失效" class="headerlink" title="索引失效"></a>索引失效</h4><ol>
<li>如果索引进行了表达式计算、使用函数</li>
<li>在 WHERE 子句中，如果在 OR 前的条件列进行了索引，而在 OR 后的条件列没有进行索引</li>
<li>当我们使用 LIKE 进行模糊查询的时候，前面不能是 %</li>
<li>我们在使用联合索引的时候要注意最左原则</li>
</ol>
<h4 id="最左前缀匹配"><a href="#最左前缀匹配" class="headerlink" title="最左前缀匹配"></a>最左前缀匹配</h4><p>索引的最左前缀原则，可以是联合索引的最左N个字段。比如你建立一个组合索引（a,b,c），其实可以相当于建了（a），（a,b）,(a,b,c)三个索引，大大提高了索引复用能力。</p>
<h3 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h3><p>传统查询过程: MySQL 服务器先从存储引擎层获取满足条件的所有数据, 然后再根据条件在MySQL服务层去进行过滤, 这可能导致存储引擎层返回大量的不必要的数据到MySQL 的服务层, 增加了网络传输和数据的处理<br>索引下推通过将查询条件推送至存储引擎层进行过滤，可以在存储引擎层尽可能地提前过滤掉不符合条件的数据，从而减少从存储引擎返回到MySQL服务器层的数据量</p>
<h4 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h4><p>适用于某些查询条件在索引上进行处理的情况</p>
<h3 id="索引数据结构"><a href="#索引数据结构" class="headerlink" title="索引数据结构"></a>索引数据结构</h3><h4 id="hash表"><a href="#hash表" class="headerlink" title="hash表"></a>hash表</h4><p>不支持范围查询</p>
<h4 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h4><p>当数据量增多的情况下, 索引层数也会变高</p>
<h4 id="树"><a href="#树" class="headerlink" title="树"></a>树</h4><h5 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h5><p>在极端情况下，如果每次插入的数据都是最小或者都是最大的元素，那么树结构会退化成一条链表。查询数据是的时间复杂度就会是O(n)</p>
<h5 id="平衡二叉查找树（AVL树"><a href="#平衡二叉查找树（AVL树" class="headerlink" title="平衡二叉查找树（AVL树"></a>平衡二叉查找树（AVL树</h5><p>让每个节点的左右子树高度差不能超过 1。： 随着数据量的变多, 导致树的高度变高, 意味着磁盘的IO变化, 影响整体的查询销量</p>
<h5 id="B树"><a href="#B树" class="headerlink" title="B树"></a>B树</h5><p>叶子节点没有形成链表, 范围查询的时候需要多次随机IO, 性能较低</p>
<h5 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h5><p>B+树中的非叶子节点都不存储数据，而是只作为索引。由叶子节点存放整棵树的所有数据。而叶子节点之间构成一个从小到大有序的链表互相指向相邻的叶子节点，也就是叶子节点之间形成了有序的双向链表</p>
<h5 id="B树和-B-树对比"><a href="#B树和-B-树对比" class="headerlink" title="B树和 B+树对比"></a>B树和 B+树对比</h5><ol>
<li>更好的磁盘IO性能：B+树相较于B树，更适合在磁盘上进行存储和访问。B+树的内部节点（非叶子节点）只包含索引键值，而不存储实际数据，使得每个节点可以容纳更多的索引项。这意味着在同样的索引大小下，B+树的高度更低，减少了磁盘IO的次数，提高了数据访问的效率。</li>
<li>有序性和范围查询：B+树的叶子节点使用链表连接，使得B+树的叶子节点在磁盘上是有序的。这使得B+树在范围查询时更加高效，因为可以利用顺序访问特性，避免随机磁盘IO。而B树的叶子节点并没有进行链表连接，导致范围查询需要进行多次随机IO，性能较低。</li>
<li>更适合顺序访问：由于B+树的叶子节点形成了一个有序链表，对于顺序访问（如范围扫描、顺序遍历）的查询操作更加高效。相比之下，B树需要在内部节点和叶子节点之间进行来回跳跃，不利于顺序访问。</li>
<li>更适合大规模数据存储：B+树适用于大规模数据存储，因为它具有更高的数据密度和更好的IO性能。B+树的内部节点只存储索引键值，相较于B树，可以容纳更多的索引项，减少了树的高度，降低了存储开销。</li>
</ol>
<h4 id="使用B-树的原因"><a href="#使用B-树的原因" class="headerlink" title="使用B+树的原因"></a>使用B+树的原因</h4><ol>
<li>高效的查找性能：B+树是一种高效的平衡树结构，具有非常高效的查找性能。它的平均查找时间复杂度为O(logN)，能够快速地定位到目标数据的位置</li>
<li>高效的范围查询：B+树是一种有序树结构，能够非常高效地支持范围查询操作。它可以快速地找到满足条件的起始位置和结束位置，从而快速地定位到需要查询的数据。</li>
<li>内存友好：B+树的内部节点只存储索引信息，而不存储具体的数据，因此它的内存占用比较小。此外，B+树的叶子节点是顺序存储的，能够利用操作系统的预读特性，从而更加高效地利用内存。</li>
<li>支持高效的插入和删除：B+树的平衡特性使得它支持高效的插入和删除操作。对于插入操作，B+树只需要在叶子节点上插入新的数据即可。对于删除操作，B+树只需要删除叶子节点上的数据即可。</li>
</ol>
<h3 id="数据库回表"><a href="#数据库回表" class="headerlink" title="数据库回表"></a>数据库回表</h3><h4 id="回表定义-如果返回的列不在索引列中-就需要到主键索引或者数据页当中读取对应的数据行"><a href="#回表定义-如果返回的列不在索引列中-就需要到主键索引或者数据页当中读取对应的数据行" class="headerlink" title="回表定义: 如果返回的列不在索引列中,就需要到主键索引或者数据页当中读取对应的数据行"></a>回表定义: 如果返回的列不在索引列中,就需要到主键索引或者数据页当中读取对应的数据行</h4><p>回表会增加I&#x2F;O 开销和数据库的负载, 对数据库性能有负面影响</p>
<h4 id="如何降低回表"><a href="#如何降低回表" class="headerlink" title="如何降低回表"></a>如何降低回表</h4><ol>
<li>使用覆盖索引: 指的是索引查询返回了所有的列, 不需要回表既可以返回查询结果, 从而避免回表操作, 提高性能</li>
<li>合理设计索引: 查询所需的列尽可能包含在索引中, 从而减少回表的次数; 但是索引本身也是需要消耗存储空间和进行维护</li>
<li>使用查询缓存: 查询缓存指的是查询结果被写入磁盘前, 将查询结果缓存到内存当中, 下一次查询直接从内存当中去进行获取,避免回表的操作</li>
<li>优化查询语句: 尽可能将查询条件放在索引列上, 从而减少回表的次数</li>
</ol>
<h4 id="Mysql索引底层数据结构-为什么用B-树"><a href="#Mysql索引底层数据结构-为什么用B-树" class="headerlink" title="Mysql索引底层数据结构, 为什么用B+树"></a>Mysql索引底层数据结构, 为什么用B+树</h4><pre><code class="hljs">B+树
支持高效的搜索、稳定的搜索效率,支持范围查找、内存占用比较低
        ## 索引各个场景
        有5个字段 a,b,c,d,e,f,g,h 
        (a,b,c) 是一个联合索引, (d,e)是一个联合索引
        1. 创建联合索引(a,b,c)
        符合最左匹配原则 走索引
        explain select * from not_dice.testPerson where a = &quot;1&quot;;                               
        索引

        explain select * from not_dice.testPerson where b = &quot;1&quot;;
        全表
        explain select * from not_dice.testPerson where c = &quot;1&quot;;
        全表

        explain select * from not_dice.testPerson where a = &quot;1&quot; and b = &quot;1&quot;;
        索引
        explain select * from not_dice.testPerson where b = &quot;1&quot; and a = &quot;1&quot;;
        索引

        explain select * from not_dice.testPerson where a = &quot;1&quot; and c = &quot;1&quot;;
        索引下推
        explain select * from not_dice.testPerson where c = &quot;1&quot; and a = &quot;1&quot;;
        索引

        explain SELECT * FROM not_dice.testPerson where  c  = &quot;1&quot; and b = &quot;1&quot;;
        进行全表扫描了
        explain select * from not_dice.testPerson where a = &quot;1&quot; and b = &quot;1&quot; and c = &quot;1&quot;;
        索引
        explain select * from not_dice.testPerson where b = &quot;1&quot; and a = &quot;1&quot; and c = &quot;1&quot;;
        索引
        explain select * from not_dice.testPerson where c = &quot;1&quot; and b = &quot;1&quot; and a = &quot;1&quot;;
        索引
        explain select * from not_dice.testPerson where a = &quot;1&quot; and c = &quot;1&quot; and b = &quot;1&quot;;
        索引

        explain select * from not_dice.testPerson where a = &quot;1&quot; and c = &quot;1&quot; and b = &quot;1&quot; and d = &quot;1&quot;;
        索引

        explain select * from not_dice.testPerson where c = &quot;1&quot; and b = &quot;1&quot; and d = &quot;1&quot;;
        走d_f的索引
        explain select * from not_dice.testPerson where c = &quot;1&quot; and b = &quot;1&quot; and f = &quot;1&quot;;
        全表
</code></pre>
<h3 id="索引下推应用范围"><a href="#索引下推应用范围" class="headerlink" title="索引下推应用范围"></a>索引下推应用范围</h3><pre><code class="hljs">1. 适用于执行计划是range, ref, eq_ref等
2. 对于Innodb 表, 非聚集索引, 索引下推可以减少全行读取次数, 从而减少IO
3. 子查询不能使用索引下推
4. 存储过程不能使用索引下推
</code></pre>
<h3 id="索引下推使用场景"><a href="#索引下推使用场景" class="headerlink" title="索引下推使用场景"></a>索引下推使用场景</h3><pre><code class="hljs">1. 联合索引
2. 部分索引列的过滤
</code></pre>
<h4 id="explain-中各个参数的作用"><a href="#explain-中各个参数的作用" class="headerlink" title="explain 中各个参数的作用"></a>explain 中各个参数的作用</h4><pre><code class="hljs">type: 连接类型从高效到低效依次为 system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL
key: 查询使用到的索引, 如果为null 则说明没有用到索引
rows: 扫描需要的行数, 越大 说明执行时间越长
filtered: where 条件过滤的百分比, 百分比越小 性能越高
possible_keys: 可能的索引
key: 索引
Extra: 查询的额外信息
</code></pre>
<h4 id="慢sql"><a href="#慢sql" class="headerlink" title="慢sql"></a>慢sql</h4><pre><code class="hljs">慢sql 怎么定位  怎么优化sql 
    查看数据库的慢sql日志
    explain 去进行查询
优化sql:
    1. 优化数据库 和 数据表
        如果单表数据量超过了千万, 考虑将大表拆分成小表
        引入redis 等缓存
    2. 查询优化, 每次查询的时候只需要返回需要的列, 或者是进行分页优化
    3. 使用 explain 查看执行计划
    4. 使用索引
    5. select 的时候只选择需要的列
    6. 优化where 条件, 如避免使用子函数
    7. 优化join、group by 和 order by
        join 的时候确保on 条件上有索引, 减少表的连接
        order by 和 group by 上有索引
        order by 和 group by 先用where 条件对数据去进行过滤, 减少数据集的大小
</code></pre>
<h3 id="事物"><a href="#事物" class="headerlink" title="事物"></a>事物</h3><h4 id="事物的四大特性"><a href="#事物的四大特性" class="headerlink" title="事物的四大特性"></a>事物的四大特性</h4><pre><code class="hljs">A 原子性: 事物时最小的执行单位, 不允许分割, 事物的原子性动作要么都执行成功, 要么都执行失败
    通过undo log 来保证 回滚日志   
C 一致性: 事物之行前后, 数据保持一致
    持久性+原子性+隔离性
I 隔离性: 并发访问数据库, 一个事物的执行不被其他事物所干扰
    通过 MVCC（多版本并发控制） 或锁机制
D 持久性: 一个事物提交以后, 他对数据库中的数据改变是持久的
    redo log （重做日志）可以实现事物的持久性
</code></pre>
<h5 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h5><pre><code class="hljs">redo log: 事物的持久性
undo log: 实现了事物的原子性, 用于事物的回滚
bin log: server 生成的日志, 用于数据备份和主从复制
relay log 用于主从的数据同步

undolog 记录旧版本数据, redolog 记录新数据, 事物提交时, redo log会先标记事物为prepare状态, 再写入binlog, 最后将事物标记为commit 再进行提交
</code></pre>
<h4 id="redo-log-和-bin-log"><a href="#redo-log-和-bin-log" class="headerlink" title="redo log 和 bin log"></a>redo log 和 bin log</h4><pre><code class="hljs">redo log 中WAL 技术(先写日志, 再去更新内存, 最后更新磁盘的技术)
1. 为什么redo log 写数据而不是buffer pool 或者binlog 数据库做持久化, 要快, 损失性能要小
1.1 buffer pool 落数据是随机的, 每次修改数据的位置是随机的, redo log 是属于追加的, 是顺序IO
1.2 刷脏是需要等待数据收集到一定的数据量后, 例如默认是16KB, redo log 	中只包含小量数据, 无效IO比较少

binlog 数据库的逻辑日志
需要通过redo log 来进行crash safe 的功能

两阶段提交:
    redo log 的prepare 和 commit 阶段
    保证redo log 和 bin log 的数据一致性

bin log 日志格式
1. row: 数据量大而全: 记录了每一行数据的变化, 变化之前是是什么样子的, 变化之后是什么样子
2. statement: 选择默认的语句模式:记录了每一句的sql, 对于非确定性的now()、复杂的sql 语句不进行记录.
3. mixed
bin log 和redo log 区别:
1. 存储内容上
    1. bin log 修改的数据逻辑变化
    2. redo log 修改的是物理变化
2. 功能上
    1. redo log 是为了做持久化。        redo log 	
    2. bin log 是为了做复制和数据恢复
需要bin log 和 redo log 数据一致才可以保证事物的成功
</code></pre>
<h4 id="buffer-pool-和-redis-对比"><a href="#buffer-pool-和-redis-对比" class="headerlink" title="buffer pool 和 redis 对比"></a>buffer pool 和 redis 对比</h4><pre><code class="hljs">1. buffer Pool 通常为16KB, 意味着查询一行数据, 也是需要加载整页, redis 是基于健值的存储, 颗粒度更细. 他的目的是为了优化磁盘的IO
</code></pre>
<h4 id="relay-log"><a href="#relay-log" class="headerlink" title="relay log"></a>relay log</h4><pre><code class="hljs">relay log: 用于slave 进行数据同步的
undo log: 回滚和多版本mvcc
事物commit 后清除undo log 信息
mvcc 读的时候只需要返回前面一个版本的数据即可
</code></pre>
<h4 id="mvcc-原理"><a href="#mvcc-原理" class="headerlink" title="mvcc 原理"></a>mvcc 原理</h4><pre><code class="hljs">mvcc 原理
隐藏列:trx_id
通过readView 去解决读已提交和可重复读两个隔离级别中的问题
    readView 包含内容:
        1. m_ids: 在生成read view 时当前系统中活跃的读写事物的事物id 列表
        2. min_trx_id:  生成read view 时当前系统中活跃读写事物中最小的事物id
        3. max_trx_id: 生成read view 时系统中应该分配给下一个事物的id
        4. create_trx_id: 生成该readView 的事物id
    如何判断该版本是否可见
        1. 对比需要访问trx_id 和create_trx_id, 如果是一样的, 说明是在访问自己修改过的事物, 则该版本可见
        2. 如果访问的trx_id 小于 min_trx_id, 说明访问的版本是在当前事物生成之前提交的, 可以被访问
        3. 如果访问的trx_id 大于 max_trx_id, 说明访问的版本是在当前事物后开启的, 则不可以被访问
        4. 如果访问的trx_id 在 min_trx_id 和 max_trx_id 之间的, 则需要判断trx_id 是否属于 m_ids , 如果属于的话说明还是活跃的, 不可以被访问, 否则可以访问
    读已提交和 可重复读就是在生成read view 的时间点不一样
        读已提交每次执行的时候都会会生成一个read view
        可重复度是在事物的第一次查询的时候创建一个, 并在整个事物期间不变
    MVCC 多版本体现
        1. 每行数据有多个版本, 每个版本关联一个事物ID,
            1.1 当某事物读取一行数据的时候, 会读取一个快照, 快照是这行数据最开始的版本, 即使是这行数据在此期间被修改过, 当前事物看到的也是最初的版本
            1.2 某个事物修改一行数据的时候, 不会直接去修改数据, 而是创建这行数据的新版本, 旧版本仍然保留
        2. 版本直接和事物隔离级别挂钩
            2.1 读已提交: 在每次执行的时候读取数据的read view
            2.2 可重复读: 在同一个事物内, 读取的是同一个read view
        3. 版本回收机制
            3.1 当没有任何一个事物会依赖这个旧版本的数据, 可以进行清理
            3.2 数据库删除旧版本时, 不会影响正在运行的事物
        4. MVCC 和 undo log 关系
                4.1 undo log 作用
                    4.1.1 数据的版本管理, 由于在MVCC 中 读事物是读取某一行数据的历史版本, 这些版本就是存放在undo log中
                    4.1.2 快照隔离: 每个事物在读取数据的时候, 会获取事物的read view, 其他事物进行了修改, 还是可以通过undo log获取到旧版本的数据
                    4.1.3 并发控制: 在高并发下可以读取旧版本数据
                4.2 MVCC 和 undolog 关系
                    MVCC 的多版本记录是通过undo log 来实现的, 事物每次对数据的修改, 都是生成一条undo log 记录
</code></pre>
<h4 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h4><pre><code class="hljs">mysql 并行复制
writeset
GTID: 全局事物id
主从复制的时候发生了延迟
    1. 硬件层面怎么处理
        1.1 网络带宽是不是被打满了
        1.2 CPU load
        1.3 磁盘层面是不是可以升级
    2. 软件
        2.1 IO线程
        2.2 SQL 线程
    3. 监控 告警
部分写失效了怎么处理
    场景: 发起一个update 的过程, 更改的数据落了redo log, 在需要刷盘的时候, 写了4K数据, 写了一部分数据, 但是没有写完, 不完整的数据页无法通过redo log 恢复
    解决办法: 通过double write 的方式: 给这个page 做一个备份, 重启的时候先恢复对应的页, 再去恢复数据
    将数据同步到double writer buffer 上去, 如果double write buffer 不完整则直接丢弃
</code></pre>
<h4 id="update-x-set-a-x3D-1-where-b-x3D-2"><a href="#update-x-set-a-x3D-1-where-b-x3D-2" class="headerlink" title="update x set a &#x3D; 1 where b &#x3D; 2;"></a>update x set a &#x3D; 1 where b &#x3D; 2;</h4><pre><code class="hljs">1. 客户端发起操作
2. 将b 为2 的这一行的数据中的a 列的值改为1
3. 将修改数据更新到内存中
4. 记录a 在数据页x 的地方进行了y 操作, 并将记录设置为prepare的状态
5. 修改好redo log 后, 可以对事物进行提交
6. 写入bin log
7. commit 提交事物
8. 将redo log 这个事物相关的状态设置为commit
</code></pre>
<h4 id="sql-执行过程"><a href="#sql-执行过程" class="headerlink" title="sql 执行过程"></a>sql 执行过程</h4><pre><code class="hljs">1. 客户端发送请求
    客户端通过网络连接向数据库发送一条sql 语句, 
2. 连接管理
    连接处理: 数据库服务器收到客户端的请求后, 检查是否有可用的连接池, 如果有的话 则用现有的处理连接, 没有的话创建一个新的连接
    权限验证: 服务器会去验证客户端的身份, 检查客户端是否有执行这条sql 命令的权限, 如果校验失败, 则返回错误
3. SQL 解析
    词法分析
    语法分析
    语义检查
4. 查询优化
    生成查询计划: 数据库会根据语法树生成多个可能的查询计划, 查询计划是SQL 执行的方案, 描述了如何访问和处理
    选择最优计划: 数据库会根据执行的代价选择一个最优的方案, 代价评估包含有IO成本, CPU 资源消耗 内存使用等
5. 查询计划
    执行计划: 根据选定的查询计划, 逐步执行sql 语句
    中间结果处理: 执行过程中, 可能会有一些中间结果, 中间结果会在最终结果生成前被处理
6. 返回结果
    结果集生成: 将最终的结果集返回给客户端, 可能是查询的结果, 可能是更新的影响数等等
    资源释放: 清理执行过程中使用的临时资源, 并对资源进行释放
7. 事物处理
    如果SQL 是在事物中执行的, 数据库还需要执行事物的提交或回滚
8. 日志记录
</code></pre>
<h4 id="索引的开销"><a href="#索引的开销" class="headerlink" title="索引的开销"></a>索引的开销</h4><pre><code class="hljs">1. 空间上的开销: 建立索引需要创建一颗B+树, 每棵B+树都是一个数据页, 	一个页会默认占用16KB的空间
2. 时间上的开销: 每次数据的增加、删除、修改, 需要对索引进行维护修改
</code></pre>
<h4 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h4><pre><code class="hljs">对数据表中的行记录进行加锁, 比如事物A更新了一行, 事物B也要更新一行数据, 则必须要等事物A操作完成后才可以去进行更新
间隙锁可以用来解决幻读:
    幻读的原因: 行锁只能锁住行, 但是新插入记录这个动作, 是要更新的记录之间的 间隙 , 因此通过间隙锁去解决幻读这个问题
间隙锁, 导致锁的影响范围变大
    对update 的语句进行范围上锁
行锁命令分析
show status like &#39;innodb_row_lock%&#39;; 
</code></pre>
<h4 id="存储引擎为什么默认选择innodb"><a href="#存储引擎为什么默认选择innodb" class="headerlink" title="存储引擎为什么默认选择innodb"></a>存储引擎为什么默认选择innodb</h4><pre><code class="hljs">1. 支持事物
2. innodb 是聚集索引, MyISAM 是非聚集索引
3. 锁力度: innodb 最小是行锁，myIsam 是表锁
</code></pre>
<h4 id="一条事物update-的时候各个日志在什么时候会用到"><a href="#一条事物update-的时候各个日志在什么时候会用到" class="headerlink" title="一条事物update 的时候各个日志在什么时候会用到"></a>一条事物update 的时候各个日志在什么时候会用到</h4><pre><code class="hljs">1. 开启事物, 先将记录记录到undo log 中, 将更新的旧数据记录到undo log中
2. innodb 开始更新记录, 先更新内存, 同时标记为脏页, 将记录写入redolog 中, 为了减少磁盘的IO, 由后台线程将脏页数据写入到磁盘中
3. 更新完成后, 记录该语句对应的binlog, 此时binlog 会保存到binlog cache 中, 在事物提交的时候统一将所有binlog刷新的磁盘上
4. 事物提交
    prepare 阶段 redolog 设置事物状态为prepare, 将redolog 刷盘
    commit 阶段 binlog刷盘, 将redolog设置为commit
</code></pre>
<h4 id="为什么需要两阶段提交"><a href="#为什么需要两阶段提交" class="headerlink" title="为什么需要两阶段提交"></a>为什么需要两阶段提交</h4><pre><code class="hljs">binlog 的两阶段提交
    目的: 
        防止数据丢失和保证数据的一致性
        保持binlog 和 redo log 的一致性: 确保数据库崩溃后, 保证事物提交的原子性和一致性
        防止数据丢失: 如果事物已经提交到了redo log，但是没有写入到binlog 中, 在系统奔溃后恢复, 由于binlog 没有该事物的记录, 从而影响主从复制.  如果数据只是存在redo log 中, 不存在 binlog 中, 则对数据页不进行同步
        防止数据不一致: 如果事物已经写入到binlog 但是没有写入到redolog， 奔溃后恢复的时候会导致binlog 中有记录, 但是实际数据库没有应用, 导致数据不一致
    过程
        1. prepare 阶段
            事物执行, innondb 会将事物的更改记录写入到redo log 中, 并将这些日志标记为 prepare 状态, 这意味着这些事物已经在操作了, 但是还未提交, 数据的修改刷新了内存中, 但是还没有刷新到磁盘
        2. commit 阶段
            写入binlog， 在事物提交之前, 将事物的更改写入到binlog 中, 此时binlog 记录的是最终持久化的数据, 此时redolog 中数据还是处于prepare 状态
            提交事物, 将redolog 中的事物标记为commit 状态, 一旦事物标记为commit, 数据页的修改会被刷新到磁盘上
    关键:
        顺序性和原子性:
            先记录redolog 的prepare 状态, 再写入binlog, 最后提交redo log， 防止奔溃恢复时出现数据的不一致
        奔溃恢复
            如果在写入binlog 后, 但是在提交redolog 之前的 发生了奔溃, mysql 在恢复时根据redolog 的prepare状态 和binlog 的记录继续完成提交, 确保事物的一致性
</code></pre>
<h4 id="事物隔离级别-什么是脏读、幻读"><a href="#事物隔离级别-什么是脏读、幻读" class="headerlink" title="事物隔离级别, 什么是脏读、幻读"></a>事物隔离级别, 什么是脏读、幻读</h4><pre><code class="hljs">读未提交 允许读取到未提交的事物, 可能导致脏读、不可重复读、幻读
读已提交 允许读取到事物已经提交的数据, 可以防止脏读, 可能导致不可重复读、幻读
可重复读 对于多次读取的数据是一致的, 可以防止脏读、不可以重复读, 可能导致幻读
串行化   事物的最高级别, 所有事物都是要串行的去执行, 可以防止脏读、幻读、不可重复读

脏读: 读区到其他未提交事物的数据											
不可重复读:  对于同一条数据, 在同一个事物中前后读区结果不一致						
幻读: 在同一个事物中, 对于一个范围内的数据进行多次多去, 发现返回的数据结果行数不一致					
</code></pre>
<h4 id="可重复读为什么不能解决幻读"><a href="#可重复读为什么不能解决幻读" class="headerlink" title="可重复读为什么不能解决幻读"></a>可重复读为什么不能解决幻读</h4><pre><code class="hljs">读已提交: 事物中只能读取到其他已提交的数据
    通过在语句执行之前生成一个read view, 因此可以保证每次读取的时候可以读取到其他事物提交后的数据
可重复读 是通过在启动事物时生成一个read view, 整个事物期间都在用这个read view, 因此没办法防止幻读, 因为整个事物期间基于的视图时一样的
</code></pre>
<!-- #### 	存储引擎为什么默认选择innodb
    1. 支持事物
    2. innodb 是聚集索引, MyISAM 是非聚集索引
    3. 锁力度: innodb 最小是行锁，myIsam 是表锁 -->
<h2 id="redis"><a href="#redis" class="headerlink" title="redis"></a>redis</h2><h3 id="支持的数据结构"><a href="#支持的数据结构" class="headerlink" title="支持的数据结构:"></a>支持的数据结构:</h3><pre><code class="hljs">    String、Hash、List、Set、ZSet
可以持久化保存在磁盘中
</code></pre>
<h3 id="redis-单线程"><a href="#redis-单线程" class="headerlink" title="redis 单线程"></a>redis 单线程</h3><pre><code class="hljs">接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端 整个过程是单线程的
单线程为什么那么快:
    1. 大部分操作都是在内存当中操作的, 采用了高效的数据结构,  
    2. I/O 多路复用去处理大量客户端的Socket 请求, 
    使用单线程的原因:
        CPU 不是Redis 性能的瓶颈, 更多的是在内存上和网络I/O的限制, 同时单线程可维护性高, 多线程的话增加系统复杂度, 存在线程切换等问题
6.0 后用多线程去做
    为什么要在6.0 后用多线程去做: 提升网络I/O, 命令的执行仍然是单线程的
</code></pre>
<h3 id="Redis-如何实现数据不丢失"><a href="#Redis-如何实现数据不丢失" class="headerlink" title="Redis 如何实现数据不丢失"></a>Redis 如何实现数据不丢失</h3><pre><code class="hljs">1. 读写操作在内存中, 同时有做持久化
2. 持久化日志: 
    AOF 日志、每一个写的命令, 将对应的命令写入到该文件中
        先执行命令操作, 再记录到AOF 文件日志中
        写回的策略
        always			EverySyc 				No
        同步写回			每秒回写					由操作系统控制
        可靠性高,			性能适中, 				性能好
        但是开销大		宕机丢失一秒数据			宕机丢失的数据多
        
    RDB 日志: 将某一时刻的内存数据, 以二进制的方式写入磁盘
        生成rdb 文件: save(会阻塞主线程) 和 bgsave(后台线程操作)
        使用bgsave 的时候可以继续处理命令
    混合持久化方式
</code></pre>
<h3 id="Redis-如何实现集群的高可用"><a href="#Redis-如何实现集群的高可用" class="headerlink" title="Redis 如何实现集群的高可用"></a>Redis 如何实现集群的高可用</h3><pre><code class="hljs">1. 主从复制
    主从复制采用读写分离的方式, 写数据的时候写到主节点, 主节点收到写的命令后会更新给从节点,  客户端无须等到从节点都更新完再拿到响应的结果
2. 哨兵模式
    可以对主从进行监控, 同时进行主从切换
3. 切片集群
    数据量很大的时候, 可以用redis cluster
redis cluster 或者主从的时候出现脑裂怎么办
    当主节点发现从节点下线, 或者通信的数量少于阈值时, 那么禁止主节点进行写数据, 直接把错误返回给客户端
    min-slave-to-write x 主节点至少要和 x 个节点进行连接, 如果小于这个数量, 主节点会禁止写数据
    min-slave-to-lag x   主从复制的延迟同步不可以超过 x 秒,  如果超过的话, 会禁止 主节点写数据
    上述的配置可以防止主节点故障的时候进行写数据, 只有新的主库才可以写数据
</code></pre>
<p>哨兵模式和主从模式</p>
<h4 id="哨兵负责三个事情"><a href="#哨兵负责三个事情" class="headerlink" title="哨兵负责三个事情:"></a>哨兵负责三个事情:</h4><pre><code class="hljs">监控: 
    主观下线
        发送Ping 命令给主节点, 如果主节点在一定时间内没有相应的话, 会被标记为SDOWN, 主观下线,
    客观下线
        多个哨兵节点通信认为某个节点不可用, 则认为改节点为客观下线, ODOWN
哨兵节点的选主:
    在主节点被标记为ODOWN 后, 哨兵节点会通过RAFT进行一次投票选举, 确定哪个哨兵节点作为领导者, 负责执行故障转移, 每个哨兵节点可以发起投票,并且每个哨兵节点只能投票给一个哨兵节点
    获得多数票的哨兵节点被选为领导者, 负责后续的主从切换
选择主节点
    哨兵的leader 从可用的从节点中选主一个新的主节点, 主节点标准:
        1. 从节点的优先级高的更可能被选中
        2. 复制偏移量, (代表和主节点是否更接近的,) 更有可能选中
        3. 链接状态好的
    哨兵的leader 会向其他哨兵节点通知选主的主节点

主从切换
    选中的从节点会倍提升为主节点, 新的主节点会停止从旧的主节点同步数据, 并且开始接受写入操作
    重新配置集群,  其他从节点开始从新的主节点上去同步数据, 包含和旧的主节点连接的断开. 从新的主节点获取数据
    通知客户端, 客户端根据配置更新配置
恢复正常运行
</code></pre>
<h3 id="删除策略"><a href="#删除策略" class="headerlink" title="删除策略"></a>删除策略</h3><pre><code class="hljs">1. 主库通过lazy 的方式进行删除
2. 主库会发送一个del 事件给从库, 从库收到后对数据进行删除
</code></pre>
<h3 id="内存满了后怎么处理"><a href="#内存满了后怎么处理" class="headerlink" title="内存满了后怎么处理"></a>内存满了后怎么处理</h3><pre><code class="hljs">1. 进行淘汰
</code></pre>
<h3 id="Redis-缓存设计"><a href="#Redis-缓存设计" class="headerlink" title="Redis 缓存设计"></a>Redis 缓存设计</h3><pre><code class="hljs">如何避免缓存失效
    1. 不给热点key 设置过期时间
    2. 将缓存失效的事件随机打散, 防止集体失效
如何避免缓存击穿
    1. 热点key 要过期的时候, 通知后台线程进行更新
如何避免缓存穿透 数据不存在数据库中, 要不存在redis 中
    1. 对恶意请求进行限制拦截
    2. 设置默认值
    3. 通过布隆过滤器 去设置值是否存在, 不是直接通过数据库进行查询
</code></pre>
<h3 id="更新缓存策略"><a href="#更新缓存策略" class="headerlink" title="更新缓存策略"></a>更新缓存策略</h3><pre><code class="hljs">1. cache aside: 
读多写少的场景
    针对读多写少的场景: 先更新数据库, 再去删除缓存
    如果是更新缓存的话
        性能上: 缓存的更新可能是多张表聚合之后的结果得到的, 写操作中更新性能开销比较大
        安全上: 写请求中更新 容易引发不一致问题:  T1 和 T2. T1 更新数据库, T2 更新数据库, 同时更新缓存, 此时T1 可能更新缓存的话 可能比T2 要晚. 导致数据不一致
    为什么是先更新数据库, 在删除缓存, 而不是先删除缓存, 再更新
        T1 和 T2, T1 写删除了缓存, T2 查询拿到老数据进行了更新. 导致缓存数据是老的
        同时先删除缓存的话, 会导致DB 压力大
写多读少的场景
    Write Through 策略
    数据更新的时候, 如果数据库中有数据, 则先更新缓存中的数据,通过缓存组建同步更新到数据库中, 缓存组建告知应用程序更新完成
    如果没有数据的话 则直接进行更新即可
Write back
    更新数据库的时候, 只更新缓存, 将缓存数据设置为脏数据, 然后立马返回, 数据库的更新 再通过批量更新
</code></pre>
<h3 id="大key-的影响"><a href="#大key-的影响" class="headerlink" title="大key 的影响"></a>大key 的影响</h3><pre><code class="hljs">1. 客户端阻塞超时
2. 引发网络阻塞
3. 内存分布不均匀
4. 阻塞工作线程
</code></pre>
<h3 id="如果找到大key"><a href="#如果找到大key" class="headerlink" title="如果找到大key"></a>如果找到大key</h3><pre><code class="hljs">1. redis-cli --bigkeys
2. scan 找大key
</code></pre>
<h1 id="java-基础"><a href="#java-基础" class="headerlink" title="java 基础"></a>java 基础</h1><h2 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h2><h3 id="拆装箱"><a href="#拆装箱" class="headerlink" title="拆装箱"></a>拆装箱</h3><pre><code class="hljs">什么是自动拆装箱？
java 中将基本数据类型和对象之间转换的过程, 目的是将基本类型和对象的转换更加方便. 
装箱：将基本类型用它们对应的引用类型包装起来；
拆箱：将包装类型转换为基本数据类型
int short byte long double float boolean char
</code></pre>
<h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><pre><code class="hljs">成员变量与局部变量的区别？
    语法形式: 从语法形式上看，成员变量是属于类的，而局部变量是在代码块或方法中定义的变量或是方法的参数
    存储方式: 如果成员变量是使用 static 修饰的，那么这个成员变量是属于类的，如果没有使用 static 修饰，这个成员变量是属于实例的; 而对象存在于堆内存，局部变量则存在于栈内存。
    生存时间：从变量在内存中的生存时间上看，成员变量是对象的一部分，它随着对象的创建而存在，而局部变量随着方法的调用而自动生成，随着方法的调用结束而消亡。
</code></pre>
<h3 id="抽象类和接口"><a href="#抽象类和接口" class="headerlink" title="抽象类和接口"></a>抽象类和接口</h3><pre><code class="hljs">1. 共同点
    1.1 都不能被实例化, 接口只能被实现或者是抽象来被继承才可以实例话
    1.2 都可以包含抽象方法, 抽象方法没有方法体, 必须在子类或者实现类中实现
2. 不同点
    2.1 设计目的: 接口主要用于对行为进行约束, 抽象类用于代码的复用, 强调所属关系
    2.2 继承和实现: 一个类只能继承一个类, 一个类可以实现多个接口
</code></pre>
<h3 id="浅拷贝和深拷贝"><a href="#浅拷贝和深拷贝" class="headerlink" title="浅拷贝和深拷贝"></a>浅拷贝和深拷贝</h3><pre><code class="hljs">浅拷贝：浅拷贝会在堆上创建一个新的对象（区别于引用拷贝的一点），不过，如果原对象内部的属性是引用类型的话，浅拷贝会直接复制内部对象的引用地址，也就是说拷贝对象和原对象共用同一个内部对象。
深拷贝：深拷贝会完全复制整个对象，包括这个对象所包含的内部对象。
</code></pre>
<h3 id="x3D-x3D-和-equals-的区别"><a href="#x3D-x3D-和-equals-的区别" class="headerlink" title="&#x3D;&#x3D; 和 equals() 的区别"></a>&#x3D;&#x3D; 和 equals() 的区别</h3><pre><code class="hljs">1. 对于基本数据类型来说，== 比较的是值。
2. 对于引用数据类型来说，== 比较的是对象的内存地址。
</code></pre>
<h2 id="string"><a href="#string" class="headerlink" title="string"></a>string</h2><h3 id="为什么是不可变的"><a href="#为什么是不可变的" class="headerlink" title="为什么是不可变的"></a>为什么是不可变的</h3><pre><code class="hljs">1. 保存字符串的数组是被final 修饰, 并且是私有的, 并且string  没有提供修改这个字符串的方法
2. String 类被final 修饰 导致不能被继承
</code></pre>
<h3 id="stringBuilder-和-stringBuffer"><a href="#stringBuilder-和-stringBuffer" class="headerlink" title="stringBuilder 和 stringBuffer"></a>stringBuilder 和 stringBuffer</h3><pre><code class="hljs">stringBuffer: 适用于多线程操作字符串缓冲区下操作大量数据
strinbgBuilder: 适用于单线程操作字符串缓冲区下操作大量数据
</code></pre>
<h2 id="范型"><a href="#范型" class="headerlink" title="范型"></a>范型</h2><pre><code class="hljs">作用: 增强代码的可读性和稳定性
</code></pre>
<h3 id="使用方式"><a href="#使用方式" class="headerlink" title="使用方式"></a>使用方式</h3><pre><code class="hljs">1. 范型类
2. 范型接口
3. 范型方法
</code></pre>
<h3 id="范型擦除"><a href="#范型擦除" class="headerlink" title="范型擦除"></a>范型擦除</h3><pre><code class="hljs">编译器会移除所有的范型类型信息, 从而确保与java 的原始类型兼容. 目的是为了和jdk1.5之前的版本向前兼容, 使得范型在运行的时候类型信息被擦除, 无法获得实际的类型信息
影响:
    1. 运行时类型检查的限制, 不允许对范型类型进行某些运行时检查
        obj instanceof List&lt;String&gt;
    2. 类型安全问题: 擦出后默认都是object
    3. 无法获得范型参数类型
</code></pre>
<h2 id="引用类型"><a href="#引用类型" class="headerlink" title="引用类型"></a>引用类型</h2><pre><code class="hljs">1. 强引用
    定义: 最常见的引用类型, 代码中 new 创建对象后, 赋值给一个变量
    特性: 只要强引用类型存在, JVM 就不会回收, 使用方式就是 Object obj = new Object()
2. 软引用
    定义: 描述还可以保留的, 但是当内存不足的情况下, GC  可以对这部分对象进行回收
    特性: 当JVM 内存不足的时候, 软引用对象会被回收
    用途: 缓存, 实现内存敏感的缓存
    SoftReference&lt;Object&gt; softRef = new SoftReference&lt;&gt;(new Object());

3. 弱引用
    定义: 描述一些不需要强引用, 只要对象被弱引用引用, 就会被GC回收
    特性: 无论内存是否充足, 只要进行GC, 弱引用对象就会被回收
    用途: ThreadLocal
    WeakReference&lt;Object&gt; weakRef = new WeakReference&lt;&gt;(new Object());
4. 虚引用
    定义: 用于跟踪对象的生命周期, 不影响对象的生存状态, 
    特性: 一旦对象被回收, 虚引用会被加入到指定的引用队列中, 虚引用的存在对象没有实际的影响
    用途: 用于对象被GC回收时的一些清理动作, 如释放非内存资源
</code></pre>
<h2 id="反射"><a href="#反射" class="headerlink" title="反射"></a>反射</h2><pre><code class="hljs">获取class 对象的方式:
    1. Class alunbarClass = TargetObject.class;
    2. Class alunbarClass1 = Class.forName(&quot;cn.javaguide.TargetObject&quot;);
    3. TargetObject o = new TargetObject();
            Class alunbarClass2 = o.getClass();
    4. ClassLoader.getSystemClassLoader().loadClass(&quot;cn.javaguide.TargetObject&quot;);
</code></pre>
<h3 id="反射的操作"><a href="#反射的操作" class="headerlink" title="反射的操作"></a>反射的操作</h3><pre><code class="hljs">创建一个我们要使用反射操作的类 TargetObject
使用反射操作这个类的方法以及参数
    获取方法:	Method[] methods = targetClass.getDeclaredMethods();
    获取方法并调用: Method publicMethod = targetClass.getDeclaredMethod(&quot;publicMethod&quot;,String.class);
    publicMethod.invoke(targetObject, &quot;JavaGuide&quot;);
    获取指定参数:Field field = targetClass.getDeclaredField(&quot;value&quot;);
    对指定参数进行修改
        field.setAccessible(true);
        field.set(targetObject, &quot;JavaGuide&quot;);
</code></pre>
<h2 id="动态代理的过程"><a href="#动态代理的过程" class="headerlink" title="动态代理的过程"></a>动态代理的过程</h2><pre><code class="hljs">jdk 动态代理通过 Proxy 类生成一个代理对象, 这个代理对象实现了目标类的接口, 并将方法调用委托给 InvocationHandler 来进行处理
1. 接口定义
    1.1 创建一个自定义的接口
2. 实现 InvocationHandler 接口
    2.1 这个类的invoke 方法 会处理所有代理类上的方法调用
            proxy :动态生成的代理类
            method : 与代理类对象调用的方法相对应
            args : 当前 method 方法的参数
3. 创建代理类
    MyInterface target = new MyInterfaceImpl();
    // 创建InvocationHandler
    MyInvocationHandler handler = new MyInvocationHandler(target);
        	loader :类加载器，用于加载代理对象。
            interfaces : 被代理类实现的一些接口；
            h : 实现了 InvocationHandler 接口的对象；
    // 创建代理实例
    MyInterface proxyInstance = (MyInterface) Proxy.newProxyInstance(
        target.getClass().getClassLoader(),
        target.getClass().getInterfaces(),
        handler
    );
4. 调用代理类的方法
</code></pre>
<h3 id="操作字节码的过程"><a href="#操作字节码的过程" class="headerlink" title="操作字节码的过程"></a>操作字节码的过程</h3><pre><code class="hljs">1. asm: 允许直接生成、分析、修改java 字节码
2. cgLib: 通过生成目标类的子类并覆盖父类的方法来创建代理对象, 因此可以代理普通类, 不仅仅是接口, CGLib 使用asm 来生成字节码
spring 在目标类实现任何的实现接口的时候, 默认使用cgLib 来处理, 如果类实现了一个或者多个接口的时候, 采用JDK 动态代理
</code></pre>
<h3 id="字节码增强"><a href="#字节码增强" class="headerlink" title="字节码增强:"></a>字节码增强:</h3><pre><code class="hljs">cglib 通过生成目标类的子类的方法来创建代理对象
            定义一个类；
            自定义 MethodInterceptor 并重写 intercept 方法，intercept 用于拦截增强被代理类的方法，和 JDK 动态代理中的 invoke 方法类似；
            通过 Enhancer 类的 create()创建代理类；
        cglib 不可以代理声明为final 类型的类和方法
    asm 是可以直接修改字节码的
其中spring 默认是使用clglib
</code></pre>
<h2 id="SPI"><a href="#SPI" class="headerlink" title="SPI"></a>SPI</h2><pre><code class="hljs">专门给服务提供者或者扩展框架功能开发者去使用的一个接口
缺点:
    1. 无法指定默认的实现类
    2. 加载实现类的过程无法定制, 例如无法通过以来注入的方式管理实例
    3. 无法对不同的类做自动注入或者AOP 扩展
</code></pre>
<h3 id="spring-SPI"><a href="#spring-SPI" class="headerlink" title="spring SPI"></a>spring SPI</h3><pre><code class="hljs">主要是通过 SpringFactoriesLoader 实现的
1. 读取spring.factories 文件: 文件中包含了接口到实现类的映射列表, spring 根据接口找到对应的实现类
2. 通过映射关系, 通过反射去实例化类, 并注册到spring 的上下文中
3. spring 根据上下文将这些实现类注册为spring bean, 
4. 执行扩展逻辑: 如果某些接口实现类ApllicationContextInitalization 接口, spring 会在初始化的时候调用init() 方法
</code></pre>
<h3 id="dubbo-SPI"><a href="#dubbo-SPI" class="headerlink" title="dubbo SPI"></a>dubbo SPI</h3><pre><code class="hljs">支持自动注入、支持wrapper 类、支持Adapative 扩展、支持通过配置文件的方式指定默认实现
dubbo SPI 通过 ExtensionLoader 进行加载, 工作机制如下:
    1. 通过@SPI 表示某个接口为扩展点, 该接口可以有多个实现类
    2. 通过 ExtensionLoader 扫描META-INF/dubbo 或 META-INF/services 目录下的配置文件, 找到接口的扩展实现, 并将实现动态加载进来
    3. Wrapper 包装类扩展, 通过构造函数接受扩展实例, 对其功能进行扩展包装
ExtensionLoader 原理
    1. 缓存扩展类定义: ExtensionLoader 会先从缓存中扩展类实例, 如果没有的话, 则从配置文件中加载扩展类, 并进行实例化
    2. 实例化和依赖注入: 通过反射创建扩展类的实例, 并自动注入依赖
    3. wrapper 装饰: 如果存在wrapper, 会将扩展类包括在wrapper 中
    4. 返回扩展类实例: 返回最终构造的扩展类实例
</code></pre>
<h3 id="和API-的区别"><a href="#和API-的区别" class="headerlink" title="和API 的区别"></a>和API 的区别</h3><pre><code class="hljs">1. API: 实现方提供了接口和实现, 我们可以通过实现方的接口从而实现实现方提供给我们的能力.
2. SPI: 接口方确定接口规则, 不同的实现方根据这个规则去进行实现
如 slf4j
</code></pre>
<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><pre><code class="hljs">1. 本质上通过反射实现的, 将要暴露对外使用的具体实现类放在META-INF/services/ 文件下声明
2. 可以提升灵活性
3. 缺点是效率低, 在遍历加载所有的实现类的时候
</code></pre>
<h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><pre><code class="hljs">序列化: 将数据结构或对象转换成可以存储或者是传输的形式, 通常为二进制的字节流
反序列化: 将在序列化过程中所生成的数据转换为原始数据结构或者对象的过程
</code></pre>
<h3 id="java-自身序列化问题"><a href="#java-自身序列化问题" class="headerlink" title="java 自身序列化问题"></a>java 自身序列化问题</h3><pre><code class="hljs">1. 不支持跨语言调用
2. 性能差
</code></pre>
<h2 id="Object-类"><a href="#Object-类" class="headerlink" title="Object 类"></a>Object 类</h2><pre><code class="hljs">1. equals
    比较两个对象是否相等
2. hashCode
    返回对象的哈希码, 用于在哈希表等集合中可以进行快速查找
3. notify
    1. 唤醒该对象在监视器上的等待， 如果有多个线程在等待, 只有一个线程会被唤醒
4. notifyAll
    唤醒该对象上监视器上所有的线程， 会通知所有的等待线程, 可以让他们早日获得锁
5. wait
    使得当前线程在该对象的监视器上等待, 当其他线程调用notify 或 notifyAll 方法时, 调用wait 方法后, 线程可以获得锁
6. wait(long timeout) 
    是的当前线程在该对象的监视器上等待， 最多等到指定的毫秒数, 如果超时之前调用notify 或者是 notifyAll，线程会被唤醒， 如果超时未到， 线程继续等待
7. finalize
    用于对象被GC之前进行一些清理的动作
    7.1 清理资源: 对象生命周期结束时, 确保资源可以正确被释放
    7.2. 默认实现
</code></pre>
<h2 id="final-static-volatile"><a href="#final-static-volatile" class="headerlink" title="final static volatile"></a>final static volatile</h2><h3 id="final"><a href="#final" class="headerlink" title="final"></a>final</h3><pre><code class="hljs">1. 修饰的类不能被继承, 类中的所有成员方法都会被隐式的制定为final 方法
2. 修饰的方法不能被重写
3. 修饰的变量是常量
</code></pre>
<h3 id="static"><a href="#static" class="headerlink" title="static"></a>static</h3><pre><code class="hljs">1. 修饰成员变量和成员方法, 被static 修饰的成员变量 属于类, 不属于单个方法, 被类中所有对象共享. 
2. 修饰静态代码块. 静态代码块在非静态代码块之前执行
3. 静态内部类.
</code></pre>
<h3 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h3><pre><code class="hljs">1. 保证可见性
2. 保证有序性
3. i++ 是分为3部来走的
    3.1 读取原始变量 i 的值
    3.2 将 i 的进行加1, 结果变为 n + 1;
    3.3 将增加后的 n+1 存回变量 i 中
</code></pre>
<h3 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h3><pre><code class="hljs">1. 修饰实例方法。当前对象锁
2. 修饰静态方法。当前类锁
3. 修饰代码块。  当前类 或者 是对象锁
基于 对象头中的 monitorEnter 和 monitorExist 
</code></pre>
<h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><pre><code class="hljs">1. JVM 中线程共享的区域: 堆 metaspace
2. JVM 中线程私有的: 虚拟机栈、本地方法栈、程序计数器。 通过-xss 可以设置
    为什么虚拟机栈和 程序计数器是私有的
        1. 程序计数器是为了线程切换后可以回到正确的位置
        2. 虚拟机栈的作用是每个方法在执行的时候会创建对应的桢栈, 用于存储局部变量表、操作数、常量等信息, 它私有为了保证局部变量不被其他线程访问
    每个线程映射到操作系统线程, 线程的创建、调度运行依赖于原生的线程调度, 操作系统提供实际调度, jvm 提供管理
</code></pre>
<h3 id="线程的状态"><a href="#线程的状态" class="headerlink" title="线程的状态"></a>线程的状态</h3><h4 id="线程的状态-1"><a href="#线程的状态-1" class="headerlink" title="线程的状态"></a>线程的状态</h4><pre><code class="hljs">1. NEW: 初始状态，线程被创建出来但没有被调用 start() 。
2. RUNNABLE: 运行状态，线程被调用了 start()等待运行的状态。
3. BLOCKED：阻塞状态，需要等待锁释放。
4. WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。
5. TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。
6. TERMINATED：终止状态，表示该线程已经运行完毕。
</code></pre>
<p><img src="/../img/jdk/threadState.png" srcset="/img/loading.gif" lazyload alt="线程状态"></p>
<h5 id="start-和-run-的区别"><a href="#start-和-run-的区别" class="headerlink" title="start 和 run 的区别"></a>start 和 run 的区别</h5><pre><code class="hljs">start 方法是Thread 中的一个方法, JVM 会创建一个新的线程, 并调用该线程的 run 方法, 一旦调用 strat 方法, 线程的状态将变为 new, 然后转换成 RUNNABLE, 等待CPU的调度
run 是 runnable 接口中的一个方法, 包含了线程中要执行的代码, 直接调用run 方法不会去启动一个新的线程, 而是以当前线程的上下文 执行 run() 方法中的代码
线程状态的变化:
    strat: 线程状态从 new 变为 runnable, 然后等待CPU的调度, 执行run 方法
    run: 线程状态保持为 new , 不会启动新的线程, 而是在当前线程中进行执行
</code></pre>
<h5 id="WAITING-和-TIME-WAITING-区分的原因"><a href="#WAITING-和-TIME-WAITING-区分的原因" class="headerlink" title="WAITING 和 TIME_WAITING 区分的原因"></a>WAITING 和 TIME_WAITING 区分的原因</h5><pre><code class="hljs">1. 一个是有超时状态的, 到时后将自动恢复执行.  一个是会无限制等待的
2. 通过对线程更加精细化的区分, JVM 需要做不同的处理. 
3. 开发者也更加明确
</code></pre>
<h5 id="什么是线程上下文切换"><a href="#什么是线程上下文切换" class="headerlink" title="什么是线程上下文切换"></a>什么是线程上下文切换</h5><pre><code class="hljs">线程在执行过程中会有自己的运行条件和状态（也称上下文），比如上文所说到过的程序计数器，栈信息等。当出现如下情况的时候，线程会从占用 CPU 状态中退出。
    主动让出 CPU，比如调用了 sleep(), wait() 等。
    时间片用完，因为操作系统要防止一个线程或者进程长时间占用 CPU 导致其他线程或者进程饿死。
    调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。
    被终止或结束运行
</code></pre>
<h5 id="SLEEP-和-WAIT-的区别"><a href="#SLEEP-和-WAIT-的区别" class="headerlink" title="SLEEP  和 WAIT  的区别"></a>SLEEP  和 WAIT  的区别</h5><pre><code class="hljs">1. sleep 没有释放锁, wait 释放锁
2. wait 用于线程交互, sleep 用于暂停
3. wait() 方法被调用后, 线程不会自动苏醒, 需要用其他线程调用notify() 或者是 notifyAll() 方法, sleep 执行完成后, 线程会自动苏醒, 或者可以使用wait(timeOut) 可以让线程苏醒
4. sleep 时 Thread  类中的静态方法, wait 是object 本地方法
    4.1 wait 是让对象锁线程实现等待, 会自动释放当前线程占有的对象, 每个对象拥有对象锁, 既然要释放当前线程占有的对象锁进入waitting 状态, 因此需要操作的是Object 对象
    4.2 sleep 是让当前线程暂停, 而不是对象, 不涉及到对象类上
</code></pre>
<h5 id="可以直接调用-Thread-类的-run-方法吗"><a href="#可以直接调用-Thread-类的-run-方法吗" class="headerlink" title="可以直接调用 Thread 类的 run 方法吗"></a>可以直接调用 Thread 类的 run 方法吗</h5><pre><code class="hljs">new 一个thread, 线程进入了new 状态, 调用start()方法, 会启动一个线程并让线程进入就绪状态, 等待获取到时间片就可以开始运行了. start() 会执行线程的响应准备逻辑, 然后自动执行run() 方法的内容. 如果直接是执行run(), 那么只是main 线程下的一个普通方法去运行
</code></pre>
<h3 id="java-创建线程的方式"><a href="#java-创建线程的方式" class="headerlink" title="java 创建线程的方式"></a>java 创建线程的方式</h3><pre><code class="hljs">Thread
    继承 Thread 实现run方法, 并且通过 start() 来开始执行
Runnable
    实现runnable 接口, 
Callable 和 Future
使用 Executor 线程池来管理线程
runnable 和 callable:
    Runnable 和 callable 都是定义任务的接口, 
    但是runnable 是没有返回值, 也不能抛出异常, 
    callable 有返回值, 允许抛出异常
Thread 和 Runnable
    Thread 类是线程的一个抽象表示, 他实现了 runnable 的接口,
    可以通过继承Thread 或者实现runnable 的接口来创建和启动一个线程
    推荐的做法是使用runnable 接口去创建任务, 并通过Thread 去进行执行, 这样可以将任务的逻辑和管理进行分开
当不需要返回的时候可以用runnable, 有返回结果的时候用callable, Thread 主要用于启动并管理线程
</code></pre>
<h3 id="为什么要用线程池"><a href="#为什么要用线程池" class="headerlink" title="为什么要用线程池"></a>为什么要用线程池</h3><pre><code class="hljs">    有大量异步任务的时候提升性能
    通过一系列参数对线程资源进行管理
线程正在做一个耗时高的任务, 做到一半怎么进行停止 ===========

常用线程池
</code></pre>
<h3 id="线程数的配置方式"><a href="#线程数的配置方式" class="headerlink" title="线程数的配置方式"></a>线程数的配置方式</h3><pre><code class="hljs">1. 计算密集型
    一般设置为接近于或等于CPU核心数。
        计算密集型任务主要依赖于CPU执行计算。过多的线程会导致线程上下文切换增加，反而可能降低性能。因此，线程数与核心数保持一致或略多于核心数即可充分利用CPU。
2. IO 密集型
    通常是CPU核心数的多倍。
        IO密集型任务通常会有大量时间在等待IO操作完成，如网络或磁盘操作。在等待期间，CPU会空闲，因此可以通过增加线程数来提高并发量，减少CPU空闲时间。
</code></pre>
<h3 id="线程池核心参数介绍-有哪些"><a href="#线程池核心参数介绍-有哪些" class="headerlink" title="线程池核心参数介绍 有哪些"></a>线程池核心参数介绍 有哪些</h3><pre><code class="hljs">核心线程数、最大线程数、超时时间、空闲线程存活的时间单位、用于保存等待执行任务的队列、用于创建线程的工厂、当任务队列满了以后, 用于何种策略去
最大线程数包含了核心线程数
</code></pre>
<h3 id="线程池为啥先放阻塞队列-再创建非核心线程"><a href="#线程池为啥先放阻塞队列-再创建非核心线程" class="headerlink" title="线程池为啥先放阻塞队列, 再创建非核心线程"></a>线程池为啥先放阻塞队列, 再创建非核心线程</h3><pre><code class="hljs">1. 提高线程利用率
    核心线程数较少的情况下可以处理所有任务, 而无需频繁的创建和销毁线程, 当只有核心线程数都在忙碌, 并且队列中的任务到达一定的数量的时候, 才会去创建非核心线程数, 可以减少频繁的创建和销毁, 提升线程的利用率
2. 减少系统资源开销
    在高并发的场景下线程的创建和销毁会带来较大的开销, 因此优先使用核心线程数, 再将任务加入到阻塞队列中, 尽可能少的创建非核心线程数, 从而减少系统的资源开销
3. 防止过度创建线程
    如果在任务到达的时候, 直接创建线程, 可能导致线程快速增长, 最终耗尽资源, 通过将任务加入到阻塞队列中, 可以平衡任务的负载, 只有当队列满了, 并且核心线程数无法处理所有的任务的时候, 才创建额外的非核心线程, 防止系统过载
4. 保证任务的有序
    可以确保任务按照一定的顺序执行, 在任务过多时才启用, 确保线程池在高负载的时候可以处理任务
</code></pre>
<h3 id="线程池执行异常了-该线程会怎能样-怎么在主线程中捕获该异常"><a href="#线程池执行异常了-该线程会怎能样-怎么在主线程中捕获该异常" class="headerlink" title="线程池执行异常了, 该线程会怎能样, 怎么在主线程中捕获该异常"></a>线程池执行异常了, 该线程会怎能样, 怎么在主线程中捕获该异常</h3><pre><code class="hljs">execute()
    如果执行线程没有进行catch 捕获, 会导致worker 线程被终止, 同时默认情况下没有配置afterExecute 方法的, 如果当前worker 小于核心线程数, 则会创建一个新的 worker 线程去进行替换, 新创建的worker 是非核心的
submit()
    异常会被封装在返回的future 中, 当对象调用future.get 的时候获取到对应的异常
</code></pre>
<h3 id="什么是线程不安全"><a href="#什么是线程不安全" class="headerlink" title="什么是线程不安全"></a>什么是线程不安全</h3><pre><code class="hljs">1. 多线程下面对同一份数据获取, 获取到的数据混乱, 错误或者是丢失
</code></pre>
<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><h3 id="乐观锁、悲观锁"><a href="#乐观锁、悲观锁" class="headerlink" title="乐观锁、悲观锁"></a>乐观锁、悲观锁</h3><pre><code class="hljs">1. 悲观锁: 假设并发访问冲突会导致数据不一致, 在使用悲观锁的情况下, 线程访问共享资源会事先获得锁, 确保可以独占的进行, 而其他线程则会被阻塞, 悲观锁适用于数据修改比较频繁, 并发冲突比较高的场景下,
2. 乐观锁: 假设并发冲突较少发生, 多个线程可以同时进行读写操作而不去加锁, 乐观锁的实现是通过版本号或者时间戳来判断数据是否被进行了修改, 如果一个线程要更新数据, 会先获取当前版本号, 如果当前版本号发生了变化, 则说明其他线程进行了修改, 如果当前版本号没有发生变化, 说明可以进行修改,适用于读多写少的情况, 冲突比较少的情况

悲观锁通常多用于写比较多的情况（多写场景，竞争激烈），这样可以避免频繁失败和重试影响性能，悲观锁的开销是固定的。不过，如果乐观锁解决了频繁失败和重试这个问题的话（比如LongAdder），也是可以考虑使用乐观锁的，要视实际情况而定。
乐观锁通常多用于写比较少的情况（多读场景，竞争较少），这样可以避免频繁加锁影响性能。不过，乐观锁主要针对的对象是单个共享变量（参考java.util.concurrent.atomic包下面的原子变量类
</code></pre>
<h3 id="锁的使用场景"><a href="#锁的使用场景" class="headerlink" title="锁的使用场景:"></a>锁的使用场景:</h3><pre><code class="hljs">读写锁:
    读多写少的, 高并发的情况下可以提高读取的效率
乐观锁:
    通过版本号机制, 适用于冲突较少, 并发较低的情况下, 适用于读操作比较多,
悲观锁:
        适用于写操作比较多, 并发冲突比较多的场景
        synchronized:
            简单的并发控制, 例如在方法上或者对象上控制并发
        ReentrantLock:
            可以手动的管理锁的粒度, 可中断锁, 可对锁进行超时处理
</code></pre>
<h3 id="ReentrantReadWriteLock"><a href="#ReentrantReadWriteLock" class="headerlink" title="ReentrantReadWriteLock"></a>ReentrantReadWriteLock</h3><pre><code class="hljs">读多, 写少的情况下
读操作的并发性:
    只有没有写操作, 多个线程同时进行读取数据, 在读多写少的场景下面可以显著提高读取的性能
写操作的独占性:
    写操作是独占的, 当一个线程在运行的时候, 其他所有的读取和写都会被阻塞, 直到写操作完成。这样可以保证数据的一致性, 防止读线程读取到错误不完整的数据。
使用场景:
    读多写少的场景, 例如: 缓存, 配置读取
读锁为共享锁，写锁为排他锁
如何保证安全性:
    读锁: 在进行更新数据的时候, 只有所有读锁都释放了以后, 写锁才可以被获取到
    写锁: 写锁获取时, 会检查是否有读锁的存在, 如果有读锁的存在, 写锁会被阻塞, 直到所有的读锁都被释放, 一旦有线程拿到写锁, 会阻止任何新的读锁和其他写锁的获取

    
</code></pre>
<!-- #### 使用场景
##### 乐观锁
    适用于读操作比较多, 并发冲突比较少的场景
##### 悲观锁
    适用于写操作操作比较多, 并发冲突比较多的场景 -->
<h3 id="synchronized、Lock"><a href="#synchronized、Lock" class="headerlink" title="synchronized、Lock"></a>synchronized、Lock</h3><h4 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h4><h4 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h4><h4 id="ReadLock、writeLock"><a href="#ReadLock、writeLock" class="headerlink" title="ReadLock、writeLock"></a>ReadLock、writeLock</h4><h5 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h5><h6 id="ReadLock"><a href="#ReadLock" class="headerlink" title="ReadLock:"></a>ReadLock:</h6><pre><code class="hljs">1. 并发读取, 当多个线程需要读取共享资源的时候, 多个线程可以同时获取锁资源
2. 读多写少, 当共享资源的读取次数远远超过写操作的时候, 允许多个读可以提高并发性能
</code></pre>
<h6 id="WriteLock"><a href="#WriteLock" class="headerlink" title="WriteLock:"></a>WriteLock:</h6><pre><code class="hljs">1. 数据修改, 当一个线程要对共享资源去进行修改的时候, 需要获取WriteLock, 写锁会阻塞其他的读锁和写锁, 确保只有一个线程独占获取锁资源
2. 数据一致性保护, 当涉及到多个步骤的写锁时, 可以通过WriteLock来保证多个步骤的原子性
</code></pre>
<h3 id="乐观锁-悲观锁"><a href="#乐观锁-悲观锁" class="headerlink" title="乐观锁 悲观锁"></a>乐观锁 悲观锁</h3><pre><code class="hljs">并发冲突低的情况下 使用乐观锁
    并发冲突高的时候使用乐观锁, 会导致重试的频率增加, 增加系统的响应时间和资源消耗, 给数据库增加压力, 导致系统的复杂性变高
并发冲突高的情况下是用悲观锁,
    并发冲突低的时候使用悲观锁导致资源的浪费.
</code></pre>
<h3 id="synchronized-cas-lock"><a href="#synchronized-cas-lock" class="headerlink" title="synchronized cas lock"></a>synchronized cas lock</h3><pre><code class="hljs">jdk1.6之前的, 将锁信息放在对象头的Monitor 中, 通过操作系统的Mutex Lock 来实现, 1.7 1.8 以后通过锁升级、锁优化来解决这个问题, 锁升级有无锁, 偏向锁, 轻量级锁, 重量级锁
lock 是基于aqs 来进行实现的
</code></pre>
<h4 id="cas"><a href="#cas" class="headerlink" title="cas"></a>cas</h4><pre><code class="hljs">CAS 经常会用到自旋操作来进行重试，也就是不成功就一直循环执行直到成功。如果长时间不成功，会给 CPU 带来非常大的执行开销。
</code></pre>
<h4 id="synchronized-1"><a href="#synchronized-1" class="headerlink" title="synchronized"></a>synchronized</h4><pre><code class="hljs">1. 修饰实例方法  锁当前对象
2. 修饰静态方法		锁当前类
3. 修饰代码块。   锁执行对象或者是类
</code></pre>
<h4 id="reentrantLocak"><a href="#reentrantLocak" class="headerlink" title="reentrantLocak"></a>reentrantLocak</h4><h3 id="synchronized-和-reentrantLocak-区别"><a href="#synchronized-和-reentrantLocak-区别" class="headerlink" title="synchronized 和 reentrantLocak 区别"></a>synchronized 和 reentrantLocak 区别</h3><pre><code class="hljs">相同点:
    可重入锁, 都是悲观锁
    性能差不多
不同点:
    synchronized 是java 中的关键字, 是语言级别的 reentrantLocak 依赖于AQS 实现,是java 中的一个类
    reentrantLocak 可实现等待中断
    reentrantLocak 可实现公平和非公平锁
公平锁和非公平锁场景
    默认是非公平锁, 非公平锁降低了线程的上下文切换, 具有更高的吞吐量, 降低了锁竞争导致的延迟, 适用于短暂的任务,并发高的情况下
    公平锁场景: 对资源的执行顺序具有严格要求的, 业务逻辑处理要求具有公平性的
</code></pre>
<h3 id="死锁判定"><a href="#死锁判定" class="headerlink" title="死锁判定"></a>死锁判定</h3><pre><code class="hljs">1. 互斥条件: 资源在某个时刻只能由一个线程占用, 如果一个线程占用了一个资源, 其他线程不能访问该资源
2. 持有并等待: 线程已经持有了一个资源, 但又请求新的资源, 并且由于新资源被其他线程占用而陷入等待, 同时不会释放自己所占用的资源
3. 不剥夺条件: 资源不能强制从持有他的线程中剥夺, 只有持有该资源的线程在完成任务后主动释放
4. 循环等待条件: 存在一个线程, 链中的每个线程都在等待下一个线程持有的资源, 从而形成一个循环等待的局面
</code></pre>
<h2 id="ThreadLocal-原理"><a href="#ThreadLocal-原理" class="headerlink" title="ThreadLocal 原理"></a>ThreadLocal 原理</h2><pre><code class="hljs">每个线程维护一个叫threadLocals 的 ThreadLocalMap,每个线程维护自己的ThreadLocalMap, threadLocalMap 中其中key 是ThreadLocal 对象, value 
是要保存的值, 多个threadLocal 通过ThreadLocal 对象的hash值 来定位到table 中的位置,
ThreadLocal 实例被创建的对象持有, ThreadLocal 值也是被线程实例持有, 都是位于堆上的

由于ThreadLocal 保存的时候把自己当作key 防盗了ThreadLocalMap 中, 同时是弱引用的, 由于发生了GC的时候, 会被回收, 但是由于线程一直运行, value 
是无法得到回收的,  在线程池中, 容易造成内存泄漏, 容易导致ThreadLocalMap 中的key 变为了null, 但是由于threadLocal线程还是一直在运行的, 
这个value 一直得不到回收, 导致内存泄漏, 需要在最后使用的地方加上remove, 

如果Entry 中的key 是强引用的, 容易导致key 也内存泄漏
如果k v 都是弱引用的话, 会导致获取值的不确定性

fastThreadLocal 通过InternaleThreadLocal 来避免了内存泄漏, 通过数组的索引可以直接访问数据, 线程退出的时候, 会自动进行清理与该线程相关的FastThreadLocal 信息
</code></pre>
<h2 id="AQS-原理-线程入队列-出队列-唤醒机制-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D"><a href="#AQS-原理-线程入队列-出队列-唤醒机制-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D" class="headerlink" title="AQS 原理, 线程入队列 出队列 唤醒机制			&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;"></a>AQS 原理, 线程入队列 出队列 唤醒机制			&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</h2><pre><code class="hljs">查看 int 的 volatile state 属性
入队列
    CAS 尝试获取锁, 获取锁成功则将当前线程为占用了锁资源 CAS(0, 1)                       					非公平抢占获取锁
    获取锁资源
    2.1 尝试获取锁资源
    2.1.1 查看当前锁是否被占据
    2.1.2 如果没有的话则通过CAS 尝试获取锁, CAS 成功则将当前线程占用了锁资源 												非公平抢占获取锁
    2.1.3 如果本来就是当前线程拿到了锁的资源, 则进行可重入计数+1, 更新当前锁的重入个数
    2.2 获取当前锁资源失败, 则进行入队列等待
    2.2.1 创建一个等待的 Node 节点, 如果队列中有节点存在了, 通过 CAS 的方式加入到队尾节点
    2.2.1.1 如果上一步CAS 入队尾失败了, 则进行自旋的方式加入到队尾
    2.3 尝试入队列
    2.3.1 如果前驱节点为头节点, 则尝试获取锁
    2.3.2 获取锁成功则将当前节点设置为头节点
    2.3.3 如果当前节点不是头节点，或者是获取锁失败
    2.3.4 获取前驱节点的状态, 如果状态为SIGINAL(-1) 则挂起
    2.3.5 当前前驱节点状态大于0, 说明前驱节点取消了排队, 从后向前去找一个新的前驱节点
    2.3.6 当前前驱节点状态为0, 通过 CAS 将当前状态设置为-1
出队列
    完全释放了锁, 对后续节点进行唤醒
        2.1 如果头节点不为空，或者是头节点的状态不是初始状态, 则解除线程挂起
        2.1.1 头节点为空, 说明是第一个节点入队列,
        2.2 对线程解除挂起
        2.2.1 获取头节点的状态值
        2.2.2 如果当前头节点状态值小于0, 则将状态值CAS设置为0
        2.2.3 获取头节点的下一个节点, 如果下一个节点为空, 或者下个节点状态是被cancel 的, 选择从后向前找到第一个waitStatus&lt; 0的
        2.2.3.1 选择从后向前找, 而不是从前向后找, 是因为可能有节点是无效的或者是cancelled的状态
        2.2.4 找到节点后, 进行唤醒
</code></pre>
<h3 id="volatile-关键字原理"><a href="#volatile-关键字原理" class="headerlink" title="volatile 关键字原理"></a>volatile 关键字原理</h3><pre><code class="hljs">保证可见性
防止重排序
happens before 规则
    对于一个volatile 变量写的操作happens-before 任意线程对该变量的读操作, 确保了volatile的可见性
</code></pre>
<h2 id="collection"><a href="#collection" class="headerlink" title="collection"></a>collection</h2><h3 id="hashMap"><a href="#hashMap" class="headerlink" title="hashMap"></a>hashMap</h3><h4 id="hashMap-默认是0-75"><a href="#hashMap-默认是0-75" class="headerlink" title="hashMap 默认是0.75"></a>hashMap 默认是0.75</h4><pre><code class="hljs">扩容因子: 
    更小的话 是更容易创建数组, 占用更大的空间, 会频繁的发生扩缩容
    更大的话降低了内存的浪费, 增加查找的插入、删除的复杂度
0.75 是一个平衡的结果
</code></pre>
<h4 id="hashMap-中扩容因子是2倍"><a href="#hashMap-中扩容因子是2倍" class="headerlink" title="hashMap 中扩容因子是2倍"></a>hashMap 中扩容因子是2倍</h4><pre><code class="hljs">扩大两倍是为了保证hash 函数的分布均匀, 扩大的三倍后, 可能会导致很多hash 值在同一个buckt 中, 从而降低了查询的效率, 扩大两倍是为了保证hash 分布均匀, 从而提高查询效率
扩容到3倍不行 会导致hash 冲突增加, 查询效率变低,
</code></pre>
<h4 id="list-为1-5倍-hashMap-扩容为2倍的原因"><a href="#list-为1-5倍-hashMap-扩容为2倍的原因" class="headerlink" title="list 为1.5倍, hashMap 扩容为2倍的原因"></a>list 为1.5倍, hashMap 扩容为2倍的原因</h4><pre><code class="hljs">1. arrayList 是基于动态数组的 扩容是为了平衡内存利用率和性能, 扩小了可能导致频繁的扩容, 扩大的可能导致内存空间的浪费
2. hashMap是基于散列表, 扩容需要确保hash 散列的均衡性, 在计算hash 的时候只需要取模操作就可以了, 扩容为2倍可以减少冲突, 重新计算的时候可以直接利用位运算进行分布
</code></pre>
<h4 id="hashMap-中链表插入数据的过程"><a href="#hashMap-中链表插入数据的过程" class="headerlink" title="hashMap 中链表插入数据的过程"></a>hashMap 中链表插入数据的过程</h4><pre><code class="hljs">1. 1.8 之前头插法
2. 1.8 以后尾插法
    hashMap 采用尾插法的目的是可以减少多线程下的竞争,减少链表结果的变动
</code></pre>
<h4 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h4><p>大体上, HashMap 是一个数组, 数组每一个元素是个单向链表, 数组是HashMap 的主体， 链表是为了解决hash碰撞存在的， 其中解决hash碰撞是通过拉链法去解决冲突, 在jdk1.8后在解决冲突的时候引入了红黑树，其中当链表中的长度大于8的时候，将链表转换成红黑树</p>
<h5 id="解决hash-冲突方法"><a href="#解决hash-冲突方法" class="headerlink" title="解决hash 冲突方法"></a>解决hash 冲突方法</h5><p>开放地址法<br>拉链法</p>
<h5 id="put"><a href="#put" class="headerlink" title="put"></a>put</h5><p><strong>对putVal方法添加元素的分析如下：</strong></p>
<ul>
<li>①如果定位到的数组位置没有元素 就直接插入。</li>
<li>②如果定位到的数组位置有元素就和要插入的key比较，如果key相同就直接覆盖，如果key不相同，就判断p是否是一个树节点，如果是就调用<code>e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value)</code>将元素添加进入。如果不是就遍历链表插入(插入的是链表尾部)。</li>
</ul>
<p>ps:下图有一个小问题，来自 <a target="_blank" rel="noopener" href="https://github.com/Snailclimb/JavaGuide/issues/608">issue#608</a>指出：直接覆盖之后应该就会 return，不会有后续操作。参考 JDK8 HashMap.java 658 行。</p>
<p><img src="/img/jdk/hashMap_put.png" srcset="/img/loading.gif" lazyload alt="put方法"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> V <span class="hljs-title function_">put</span><span class="hljs-params">(K key, V value)</span> &#123;<br>    <span class="hljs-keyword">return</span> putVal(hash(key), key, value, <span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>);<br>&#125;<br><br><span class="hljs-keyword">final</span> V <span class="hljs-title function_">putVal</span><span class="hljs-params">(<span class="hljs-type">int</span> hash, K key, V value, <span class="hljs-type">boolean</span> onlyIfAbsent,</span><br><span class="hljs-params">                   <span class="hljs-type">boolean</span> evict)</span> &#123;<br>    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; <span class="hljs-type">int</span> n, i;<br>    <span class="hljs-comment">// table未初始化或者长度为0，进行扩容</span><br>    <span class="hljs-keyword">if</span> ((tab = table) == <span class="hljs-literal">null</span> || (n = tab.length) == <span class="hljs-number">0</span>)<br>        n = (tab = resize()).length;<br>    <span class="hljs-comment">// (n - 1) &amp; hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中)</span><br>    <span class="hljs-keyword">if</span> ((p = tab[i = (n - <span class="hljs-number">1</span>) &amp; hash]) == <span class="hljs-literal">null</span>)<br>        tab[i] = newNode(hash, key, value, <span class="hljs-literal">null</span>);<br>    <span class="hljs-comment">// 桶中已经存在元素</span><br>    <span class="hljs-keyword">else</span> &#123;<br>        Node&lt;K,V&gt; e; K k;<br>        <span class="hljs-comment">// 比较桶中第一个元素(数组中的结点)的hash值相等，key相等</span><br>        <span class="hljs-keyword">if</span> (p.hash == hash &amp;&amp;<br>            ((k = p.key) == key || (key != <span class="hljs-literal">null</span> &amp;&amp; key.equals(k))))<br>                <span class="hljs-comment">// 将第一个元素赋值给e，用e来记录</span><br>                e = p;<br>        <span class="hljs-comment">// hash值不相等，即key不相等；为红黑树结点</span><br>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (p <span class="hljs-keyword">instanceof</span> TreeNode)<br>            <span class="hljs-comment">// 放入树中</span><br>            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(<span class="hljs-built_in">this</span>, tab, hash, key, value);<br>        <span class="hljs-comment">// 为链表结点</span><br>        <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">// 在链表最末插入结点</span><br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">binCount</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; ; ++binCount) &#123;<br>                <span class="hljs-comment">// 到达链表的尾部</span><br>                <span class="hljs-keyword">if</span> ((e = p.next) == <span class="hljs-literal">null</span>) &#123;<br>                    <span class="hljs-comment">// 在尾部插入新结点</span><br>                    p.next = newNode(hash, key, value, <span class="hljs-literal">null</span>);<br>                    <span class="hljs-comment">// 结点数量达到阈值，转化为红黑树</span><br>                    <span class="hljs-keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD - <span class="hljs-number">1</span>) <span class="hljs-comment">// -1 for 1st</span><br>                        treeifyBin(tab, hash);<br>                    <span class="hljs-comment">// 跳出循环</span><br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>                <span class="hljs-comment">// 判断链表中结点的key值与插入的元素的key值是否相等</span><br>                <span class="hljs-keyword">if</span> (e.hash == hash &amp;&amp;<br>                    ((k = e.key) == key || (key != <span class="hljs-literal">null</span> &amp;&amp; key.equals(k))))<br>                    <span class="hljs-comment">// 相等，跳出循环</span><br>                    <span class="hljs-keyword">break</span>;<br>                <span class="hljs-comment">// 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表</span><br>                p = e;<br>            &#125;<br>        &#125;<br>        <span class="hljs-comment">// 表示在桶中找到key值、hash值与插入元素相等的结点</span><br>        <span class="hljs-keyword">if</span> (e != <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-comment">// 记录e的value</span><br>            <span class="hljs-type">V</span> <span class="hljs-variable">oldValue</span> <span class="hljs-operator">=</span> e.value;<br>            <span class="hljs-comment">// onlyIfAbsent为false或者旧值为null</span><br>            <span class="hljs-keyword">if</span> (!onlyIfAbsent || oldValue == <span class="hljs-literal">null</span>)<br>                <span class="hljs-comment">//用新值替换旧值</span><br>                e.value = value;<br>            <span class="hljs-comment">// 访问后回调</span><br>            afterNodeAccess(e);<br>            <span class="hljs-comment">// 返回旧值</span><br>            <span class="hljs-keyword">return</span> oldValue;<br>        &#125;<br>    &#125;<br>    <span class="hljs-comment">// 结构性修改</span><br>    ++modCount;<br>    <span class="hljs-comment">// 实际大小大于阈值则扩容</span><br>    <span class="hljs-keyword">if</span> (++size &gt; threshold)<br>        resize();<br>    <span class="hljs-comment">// 插入后回调</span><br>    afterNodeInsertion(evict);<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>&#125;<br></code></pre></td></tr></table></figure>
<h5 id="get"><a href="#get" class="headerlink" title="get"></a>get</h5><h4 id="非线程安全"><a href="#非线程安全" class="headerlink" title="非线程安全"></a>非线程安全</h4><p>原子性: 一个操作是否属于不可分割的<br>可见性:一个线程对变量的操作对于另外一个线程是可见的<br>线程A 去进行判断数组中是否存在元素的时候, 线程B 去对值进行修改, 以及两个线程在往链表中插入的时候<br>有序性:代码的执行顺序和语句顺序是一致的</p>
<h3 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_31709249/article/details/106952137">参照链接1</a><br><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/984814">参照链接2</a><br>通过synchronzed, Node 变量value的volatile 以及CAS 去保证安全性<br>其中synchronize锁的粒度为桶中头结点（包括链表Node结点，包装红黑树的TreeBin结),transient volatile Node&lt;K,V&gt;[] table;<br>① 如果数组未没初始化，则先去初始化<br>② 如果对应的桶中的元素为空，那就新建一个链表节点，然后利用CAS操作将其放到桶中的位置。这个过程是在③前面的，我们知道，扩容过程中，每个桶位置迁移节点结束后，会将这个节点设置为ForwardingNode，所以这种情况下，你尽管放，放了以后，扩容的线程总会遍历到这个节点，然后将这个节点迁移到新数组中<br>③ 如果有线程在扩容，那就先去帮助扩容，扩容结束后，再重新put。<br>④ 最后，如果当前桶中已经有元素了，那就用synchronized锁住当前桶中的节点，然后在桶中插入元素，插入的时候，要么插入到链表中，要么插入到红黑树中。我们发现，这里的锁粒度是很小的，就锁住一个桶，不像JDK1.7中的ConcurrentHashMap，是分段锁，锁住很多的桶，所以并发效率更高。<br>⑤ 插入结束后，如果是插入到链表中，那去看看链表的长度有没有超过长度阈值8，如果超过了，就要将链表转换成红黑树。<br>⑥ 最后，让size加一（这里其实是用baseCount来记录长度的，而且处理的时候很复杂，继续看下面）。</p>
<h4 id="更新size中的addCount"><a href="#更新size中的addCount" class="headerlink" title="更新size中的addCount"></a>更新size中的addCount</h4><p>建立一个CounterCell类型的数组counterCells,每个线程生成一个随机数,用随机数去当线程的hash码, 用来对应到counterCells数组中的位置, 把要更新的值放在CounterCell的value上, 最后同步到baseCount, 获取到一个总的个数</p>
<h5 id="高并发下如何保证addCount的值的正确性"><a href="#高并发下如何保证addCount的值的正确性" class="headerlink" title="高并发下如何保证addCount的值的正确性"></a>高并发下如何保证addCount的值的正确性</h5><h4 id="扩容过程"><a href="#扩容过程" class="headerlink" title="扩容过程"></a>扩容过程</h4><p>实现了并发迁移的过程<br>每个线程承担不小于 16 个桶中的元素的扩容，然后从右向左划分 16 个桶给当前线程去迁移，每当开始迁移一个桶中的元素的时候，线程会锁住当前槽中列表的头元素，扩容完成后会将这个桶中的节点设置为ForwardingNode。假设这时候正好有 get请求过来会仍旧在旧的列表中访问，如果是插入、修改、删除、合并、compute 等操作时遇到 ForwardingNode，就表示正在扩容，那当前线程会一起扩容，扩容结束后再做元素的更新操作</p>
<h4 id="get-1"><a href="#get-1" class="headerlink" title="get"></a>get</h4><p>get 的时候普通链表是不需要去进行加锁, value 是通过volatile去进行修饰的, 保证可见性</p>
<h4 id="hashMap-在1-8-后使用红黑树的的目的"><a href="#hashMap-在1-8-后使用红黑树的的目的" class="headerlink" title="hashMap 在1.8 后使用红黑树的的目的"></a>hashMap 在1.8 后使用红黑树的的目的</h4><pre><code class="hljs">1. 解决链表性能问题, 在发生严重冲突的时候, 健值会以链表的形式保存, 链表的查找删除复杂度位O(n), 当链表很长的时候, 性能会显著下降
2. 提高查找效率, 红黑树的增加、查找、删除的复杂度位O(logn)
</code></pre>
<h4 id="hashTable-和-concurrentHashMap"><a href="#hashTable-和-concurrentHashMap" class="headerlink" title="hashTable 和 concurrentHashMap"></a>hashTable 和 concurrentHashMap</h4><pre><code class="hljs">1. 都是并发安全的, hashTable 的所有方法都是通过synchronized 来进行实现的,concurrentHashMap 通过分段锁来实现的
2. concurrentHashMap 读的时候 通过volatile 来保证安全性
3. concurrentHashMap put
    3.1 通过cas 和 synchronized 来保证安全性
    3.1.1 计算hash 值
    3.1.2 如果要插入的位置是个null 节点, 则直接在该位置插入, 如果不是空节点, 则进行链表采用尾插法, 或者是红黑树插入
</code></pre>
<h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><pre><code class="hljs">    Arraylist 与 LinkedList 区别?
是否保证线程安全： ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全；
底层数据结构： ArrayList 底层使用的是 Object 数组；LinkedList 底层使用的是 双向链表 数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！）
插入和删除是否受元素位置的影响：
ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element)），时间复杂度就为 O(n)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。
LinkedList 采用链表存储，所以在头尾插入或者删除元素不受元素位置的影响（add(E e)、addFirst(E e)、addLast(E e)、removeFirst()、 removeLast()），时间复杂度为 O(1)，如果是要在指定位置 i 插入和删除元素的话（add(int index, E element)，remove(Object o),remove(int index)）， 时间复杂度为 O(n) ，因为需要先移动到指定位置再插入和删除。
是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList（实现了 RandomAccess 接口） 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。
内存空间占用： ArrayList 的空间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。
</code></pre>
<h1 id="jvm"><a href="#jvm" class="headerlink" title="jvm"></a>jvm</h1><h3 id="new-一个对象-过程是什么样子的"><a href="#new-一个对象-过程是什么样子的" class="headerlink" title="new 一个对象, 过程是什么样子的"></a>new 一个对象, 过程是什么样子的</h3><pre><code class="hljs">创建对象的过程和类加载的过程是Java程序执行的两个不同阶段。

创建对象的过程：创建对象是指在程序中通过关键字&quot;new&quot;来实例化一个类，从而在内存中分配一块空间用于存储对象的实例。创建对象的过程包括以下几个步骤：
a. 类加载：如果该类还没有被加载，首先需要进行类加载，即将类的字节码加载到内存中。
b. 分配内存：在堆内存中分配一块空间，用于存储对象的实例。
c. 初始化：对对象的实例进行初始化，设置成员变量的默认值。
d. 调用构造方法：执行类的构造方法，对对象进行初始化。

类加载的过程：类加载是指将类的字节码文件加载到JVM中，并在内存中生成对应的Class对象，从而可以通过这个Class对象获取类的信息和创建类的实例。类加载过程包括以下几个阶段：
a. 加载：查找并加载类的字节码文件。
b. 验证：验证字节码文件的格式是否正确，是否有安全性问题。
c. 准备：为类的静态变量分配内存，并设置默认值。
d. 解析：将类的符号引用转换为直接引用。
e. 初始化：执行类的静态初始化代码块，对静态变量进行赋值。
锁优化
    锁升级
    锁消除
        检查到共享数据不可能存在竞争的, 执行锁消除
</code></pre>
<h3 id="内存模型"><a href="#内存模型" class="headerlink" title="内存模型"></a>内存模型</h3><ol>
<li>共享的:堆、方法区(metaspace)、直接内存</li>
<li>私有的: 程序技术器, 虚拟机栈、本地方法栈</li>
</ol>
<h4 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h4><p>程序计数器是当前线程所执行的字节码的行号指示器。他通过通过改变计数器的值来选取下一条需要执行的字节码指令，其中分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。<br>其中每个线程都是有一个程序计数器的，<br>另外，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器, 因此这部分空间占用的每个线程私有的，也是唯一不会发生OOM的</p>
<h4 id="Java-虚拟机栈"><a href="#Java-虚拟机栈" class="headerlink" title="Java 虚拟机栈"></a>Java 虚拟机栈</h4><p>（除去native 方法）java 方法的调用都是通过虚拟机栈来实现的，每次方法的调用时数据的传递都是通过栈进行传递，每个方法开始调用对应入栈，接受后都是对应到出栈。其中每个帧栈上拥有的数据有局部便量表、操作数栈、动态连接等<br><strong>局部变量表</strong> 主要存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。<br><strong>操作数栈</strong> 主要作为方法调用的中转站使用，用于存放方法执行过程中产生的中间计算结果。另外，计算过程中产生的临时变量也会放在操作数栈中。<br>栈空间虽然不是无限的，但一般正常调用的情况下是不会出现问题的。不过，如果函数调用陷入无限循环的话，就会导致栈中被压入太多栈帧而占用太多空间，导致栈空间过深。那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 <code>StackOverFlowError</code> 错误。<br>栈中国可能会出现两种错误：</p>
<ul>
<li><strong><code>StackOverFlowError</code>：</strong> 若栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 <code>StackOverFlowError</code> 错误。</li>
<li><strong><code>OutOfMemoryError</code>：</strong> 如果栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出<code>OutOfMemoryError</code>异常。</li>
</ul>
<h4 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h4><p>本地方法被执行的时候，本地方法创建的帧栈，用于本地方法存的局部便量表、操作数栈、等信息<br>方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 <code>StackOverFlowError</code> 和 <code>OutOfMemoryError</code> 两种错误。</p>
<h4 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h4><p>Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域。<strong>几乎所有的对象实例以及数组都在这里分配内存。</strong><br>Java 堆是垃圾收集器管理的主要区域，因此也被称作 <strong>GC 堆（Garbage Collected Heap）</strong>。从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代；再细致一点有：Eden、Survivor、Old 等空间。进一步划分的目的是更好地回收内存，或者更快地分配内存。<br>在 JDK 7 版本及 JDK 7 版本之前，堆内存被通常分为下面三部分：</p>
<ol>
<li>新生代内存(Young Generation) 又可以分为Eden区和Survivor 区</li>
<li>老生代(Old Generation)</li>
<li>metaspace 区<br>堆这里最容易出现的就是 <code>OutOfMemoryError</code> 错误，并且出现这种错误之后的表现形式还会有几种，比如：</li>
<li><strong><code>java.lang.OutOfMemoryError: GC Overhead Limit Exceeded</code></strong> ： 当 JVM 花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生此错误。</li>
<li><strong><code>java.lang.OutOfMemoryError: Java heap space</code></strong> :假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发此错误。(和配置的最大堆内存有关，且受制于物理内存大小。</li>
</ol>
<h4 id="方法区（MetaSpace-永久代）"><a href="#方法区（MetaSpace-永久代）" class="headerlink" title="方法区（MetaSpace 永久代）"></a>方法区（MetaSpace 永久代）</h4><p>方法区是各个线程共享的区域，其中存放的数据有类的信息、方法信息、常量、静态变量等等。</p>
<blockquote>
<p>当元空间溢出时会得到如下错误： <code>java.lang.OutOfMemoryError: MetaSpace</code></p>
</blockquote>
<p>可以通过 <code>-XX：MaxMetaspaceSize</code> 标志设置最大元空间大小</p>
<h5 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h5><p>Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有用于存放编译期生成的各种字面量（Literal）和符号引用（Symbolic Reference）的 <strong>常量池表(Constant Pool Table)</strong> 。<br>字面量是源代码中的固定值的表示法，即通过字面我们就能知道其值的含义。字面量包括整数、浮点数和字符串字面量，符号引用包括类符号引用、字段符号引用、方法符号引用和接口方法符号引用。<br>常量池表会在类加载后存放到方法区的运行时常量池中。<br>运行时常量池的功能类似于传统编程语言的符号表，尽管它包含了比典型符号表更广泛的数据。<br>既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 <code>OutOfMemoryError</code> 错误。</p>
<h5 id="字符串常量池"><a href="#字符串常量池" class="headerlink" title="字符串常量池"></a>字符串常量池</h5><p><strong>字符串常量池</strong> 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 在堆中创建字符串对象”ab“</span><br><span class="hljs-comment">// 将字符串对象”ab“的引用保存在字符串常量池中</span><br><span class="hljs-type">String</span> <span class="hljs-variable">aa</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;ab&quot;</span>;<br><span class="hljs-comment">// 直接返回字符串常量池中字符串对象”ab“的引用</span><br><span class="hljs-type">String</span> <span class="hljs-variable">bb</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;ab&quot;</span>;<br>System.out.println(aa==bb);<span class="hljs-comment">// true</span><br></code></pre></td></tr></table></figure>
<p>HotSpot 虚拟机中字符串常量池的实现是 <code>src/hotspot/share/classfile/stringTable.cpp</code> ,<code>StringTable</code> 本质上就是一个<code>HashSet&lt;String&gt;</code> ,容量为 <code>StringTableSize</code>（可以通过 <code>-XX:StringTableSize</code> 参数来设置）。<br><strong><code>StringTable</code> 中保存的是字符串对象的引用，字符串对象的引用指向堆中的字符串对象。</strong><br>JDK1.7 之前，字符串常量池存放在永久代。JDK1.7 字符串常量池和静态变量从永久代移动了 Java 堆中。<br><strong>JDK 1.7 为什么要将字符串常量池移动到堆中？</strong><br>主要是因为永久代（方法区实现）的 GC 回收效率太低，只有在整堆收集 (Full GC)的时候才会被执行 GC。Java 程序中通常会有大量的被创建的字符串等待回收，将字符串常量池放到堆中，能够更高效及时地回收字符串内存。</p>
<h4 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h4><p>本机直接内存的分配不会受到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。</p>
<h3 id="创建对象的过程"><a href="#创建对象的过程" class="headerlink" title="创建对象的过程"></a>创建对象的过程</h3><h4 id="类加载机制"><a href="#类加载机制" class="headerlink" title="类加载机制"></a>类加载机制</h4><pre><code class="hljs">创建对象的过程和类加载的过程是Java程序执行的两个不同阶段。

创建对象的过程：创建对象是指在程序中通过关键字&quot;new&quot;来实例化一个类，从而在内存中分配一块空间用于存储对象的实例。创建对象的过程包括以下几个步骤：
a. 类加载：如果该类还没有被加载，首先需要进行类加载，即将类的字节码加载到内存中。
b. 分配内存：在堆内存中分配一块空间，用于存储对象的实例。
c. 初始化：对对象的实例进行初始化，设置成员变量的默认值。
d. 调用构造方法：执行类的构造方法，对对象进行初始化。

类加载的过程：类加载是指将类的字节码文件加载到JVM中，并在内存中生成对应的Class对象，从而可以通过这个Class对象获取类的信息和创建类的实例。类加载过程包括以下几个阶段：
a. 加载：查找并加载类的字节码文件。
b. 验证：验证字节码文件的格式是否正确，是否有安全性问题。
c. 准备：为类的静态变量分配内存，并设置默认值。
d. 解析：将类的符号引用转换为直接引用。
e. 初始化：执行类的静态初始化代码块，对静态变量进行赋值。
</code></pre>
<h3 id="双亲委派"><a href="#双亲委派" class="headerlink" title="双亲委派"></a>双亲委派</h3><pre><code class="hljs">如，当一个类需要被加载时，首先会由最顶层的启动类加载器（Bootstrap ClassLoader）尝试加载，如果找不到则会依次由扩展类加载器（Extension ClassLoader）和应用程序类加载器（Application ClassLoader）尝试加载。只有当三者都无法加载时，才会由用户自定义的类加载器尝试加载
1. 双亲委派好处:1. 安全: 防止恶意代码去篡改核心库；2. 类的一致性: 保证层次结构, 相同的类只加载一次
1.1 什么情况下要打破双亲委派: 热更新
tomcat 要打破的原因是
Tomcat打破双亲委派模式是因为在Web应用中，每个Web应用都是一个独立的Java应用，拥有自己的类加载器，且需要加载各自的类和依赖库。
tomcat 的父类加载器是StandardClassLoader 会导致类冲突、破坏应用的隔离
</code></pre>
<h3 id="oom-怎么排查"><a href="#oom-怎么排查" class="headerlink" title="oom 怎么排查"></a>oom 怎么排查</h3><pre><code class="hljs">1. 使用jmap 去对内存进行dump
2. 启动的时候增加gc 日志查看
    2.1 如果是full GC 很频繁, 说明老年代空间不足, 或者是老年代内存被填满了
    2.2 如果是full GC 很长, 说明GC 无法及时的释放内存
    2.3 查看每次GC 后堆内的使用情况, 判断是否有内存持续增长无法回收, 
3. 查看dump 下来的内存文件
    3.1 通过 MAT 查看 大对象、对象的引用链路、
4. 如果是堆内存不足
    4.1 尝试增加堆内存
    4.2 针对频繁的 full gc, 或者是yong gc 对内存占用分析, 调整比例
    4.3 对频繁创建和销毁的对象可以通过 polling, 减少不必要的重复创建
    4.2 更换GC 算法
</code></pre>
<h3 id="堆外内存排查"><a href="#堆外内存排查" class="headerlink" title="堆外内存排查"></a>堆外内存排查</h3><pre><code class="hljs">1. 判断是否限制堆外内存的大小: MaxDirectMemorySize限制堆外的大小
2. NMT(native memory Tracking)
    -XX:NativeMemoryTracking=detail
    jcmd &lt;pid&gt; VM.native_memory summary 查看当前JVM 内存的占用情况
    查看各个内存区域的占用情况:
        java heap: 堆上的
        class: 和类加载相关的, 包括metaspace
        Thread: 线程相关的
        GC: 垃圾回收器占用的内存
        Direct: 直接内存的占用
        Native Memory: 通过JNI 或其他本机分配的内存
3. pmap 查看虚拟内存和本机内存的分配
4. netty 的话 有Dio.netty.leakDetection.level 检测, 是否发生泄漏
</code></pre>
<h3 id="CPU-负载过高"><a href="#CPU-负载过高" class="headerlink" title="CPU 负载过高"></a>CPU 负载过高</h3><pre><code class="hljs">1. 查看是否有死循环
2. GC 频繁
3. IO 操作过多(入频繁的磁盘IO)
4. 上下文切换过多, 请求量大
工具使用:
1. top + jstack 查看 什么线程在处理
2. jstat 查看GC 行为. 释放有频繁的full GC 
3. perf 生成采样文件
    perf record -F 99 -a -g -- sleep 60
    FlameGraph 工具生成svg 火焰图
</code></pre>
<h3 id="yong-GC-频率高"><a href="#yong-GC-频率高" class="headerlink" title="yong GC 频率高"></a>yong GC 频率高</h3><pre><code class="hljs">原因: 程序在 eden 区的对象分配和晋升速率过高, 导致频繁的进行GC
1. 打开GC 日志
2. 调整堆内存大小
    初始堆大小:Xms 最大堆大小: Xmx, 策略上尽量设置一样大.  避免堆内存动态扩展带来的开销
    调大新生代的比例: -XX:NewRatio
3. 排查代码是否会产生大量临时对象, 这些临时对象是否可以复用
4. 调整晋升到老年代的阈值
    -XX:MaxTenuringThreshold
5. 使用zgc
</code></pre>
<h3 id="yong-GC-耗时长"><a href="#yong-GC-耗时长" class="headerlink" title="yong GC 耗时长"></a>yong GC 耗时长</h3><pre><code class="hljs">原因: 新生代GC 的时候发生了较大的停顿, 可能导致性能下降
    1. 打开GC日志
    2. 调整新生代的比例: 比例越大, 单次GC 扫描的时间也就是越长, 比例越小, 可能会导致频繁GC
    3. 调整晋升的阈值: 过大的阈值可能导致新生代空间不足, 增加GC的停顿时间
    4. 对象是否可以polling 处理
</code></pre>
<h3 id="full-GC-频率高"><a href="#full-GC-频率高" class="headerlink" title="full GC 频率高"></a>full GC 频率高</h3><pre><code class="hljs">原因: 老年代空间不足, 导致频繁的full GC
    1. 打开GC日志, 查看GC 频率和停顿时间
    2. 可能原因: 
        2.1 老年代空间不足, 新生代晋升到老年代后占用了过多的老年代
        2.2 metaspace 空间不足, 类加载过多, 导致metaspace 被用完了
    3. MAT 查看内存占用情况
    4. 增大堆内存
</code></pre>
<h3 id="java-内存区域有哪些"><a href="#java-内存区域有哪些" class="headerlink" title="java 内存区域有哪些"></a>java 内存区域有哪些</h3><pre><code class="hljs">程序计数器
    线程私有的, 当前线程正在执行的行号指示器
虚拟机栈
    线程私有的, 随着线程的创建而创建, 每个方法的调用都将对应的操作进行入栈和出栈
本地方法栈
    线程私有的, 执行native 方法用到的
堆
    线程共享的 
metaspace 方法区    存放类的加载信息, 运行时常量池, 类加载器、静态变量等
    线程共享的
创建线程很多导致异常的
    1. 虚拟机栈    抛出OOM 异常, unable to create new native thread
    2. 堆上的      OOM, java heap space
</code></pre>
<h3 id="yong-区比"><a href="#yong-区比" class="headerlink" title="yong 区比"></a>yong 区比</h3><pre><code class="hljs">新生代 Eden + S0 +  S1
  对应的比列是多少 8:1:1
老年代
G1 默认是5%
</code></pre>
<h3 id="如何判断死亡对象-GC-Roots-有哪些，空间分配担保是什么。"><a href="#如何判断死亡对象-GC-Roots-有哪些，空间分配担保是什么。" class="headerlink" title="如何判断死亡对象, GC Roots 有哪些，空间分配担保是什么。"></a>如何判断死亡对象, GC Roots 有哪些，空间分配担保是什么。</h3><pre><code class="hljs">虚拟机栈中引用对象
本地方法栈中引用对象
方法区中静态属性引用的对象
方法区中常量引用的对象
所有被同步持有的锁
空间分配担保: Minor GC 之前, 老年代本身还有空间容纳新生代所有剩余对象
</code></pre>
<h3 id="为什么要用分代收集"><a href="#为什么要用分代收集" class="headerlink" title="为什么要用分代收集"></a>为什么要用分代收集</h3><pre><code class="hljs">1. 大多数对象的存活时间比较短, 少数对象存活时间比较长, 可以减少GC 扫描的范围, 提升GC 的效率
2. 不同年代的GC 算法采取不一样的, 年轻代 标记复制算法, 老年代, 标记清除 或者是标记整理
</code></pre>
<h3 id="如果GC的时候内存不够分配怎么办"><a href="#如果GC的时候内存不够分配怎么办" class="headerlink" title="如果GC的时候内存不够分配怎么办"></a>如果GC的时候内存不够分配怎么办</h3><pre><code class="hljs">1. 如果年轻代和老年代都无法找到足够的空间, JVM 会触发一次full GC, 在full GC的过程中, JVM 会清理整个堆
2. 如果在full GC 后仍然无法满足内存分配的请求, JVM 会抛出OOM 的异常, 表示堆内存已经耗尽, 无法分配新的对象
-xms 设置初始堆的大小,
-xmx 设置最大堆的大小
-xx:newRation 设置年轻代和老年代的比例
</code></pre>
<h3 id="GC-算法"><a href="#GC-算法" class="headerlink" title="GC 算法"></a>GC 算法</h3><pre><code class="hljs">1. 标记清除 													老年代
  1.1 从根对象出发, 遍历所有的可达对象
  1.2 对可达对象进行标记
  1.3 未被标记的对象属于不可达对象, 等待清除的对象
  1.4 对不可达对象进行清除
优点: 实现简单, 不需要移动对象
缺点: 容易造成内存的碎片, 处理达对象困难
    解决方式: 增加压缩, 称之为标记整理算法
2. 标记复制													新生代										
    将内存分为两部分, 每次使用其中的一部分, 当内存使用完后, 将存活的对象复制到另外一部分去
    1. 将内存区域划分为From 区 和 To 区
        1.1 From 区: 当前正在使用的区域, 存放正在使用的存活对象
        1.2 To 区: 空闲的列表, 用于存放GC 存活时的对象
    2. 从GCRoots 对象出发, 遍历所有的可达对象
        2.1 标记From 区的存活对象, 确定在To 区的位置
    3. 将From 区的对象复制到To 区, 在复制期间, 对象的地址会重新发生变化
    4. 更新对象地址的引用
    5. 清空From 区, 将From 区和To 区进行互换角色
优点: 所有对象都整齐的放到新的区域上去, 不会产生内存碎片
      新生代中对象生存时期比较短, 复制对象比较少, 效率高
缺点: 对象内存浪费, 需要使用两个大小相同的内存区域, 实际每次只使用一半
      每次收集的时候需要从一边复制到另外一边去, 会产生一定的开销
3. 标记整理算法 											老年代
    标记过程和标记清除一样, 只是在回收对象的时候, 将对象移动到一侧, 然后直接去清理 
</code></pre>
<h3 id="CMS-收集器"><a href="#CMS-收集器" class="headerlink" title="CMS 收集器"></a>CMS 收集器</h3><pre><code class="hljs">1. 初始标记
    从 GCRoots 出发的直接可达性对象, 需要进行 STW, 
2. 并发标记
    在初始标记的基础上, 标记处内存中所有的可达性对象, 此时没有进行STW, 用户线程和GC 线程同时在运行.
3. 重新标记	
    需要进行STW, 对并发标记遗漏的对象进行修正, 在并发标记起期间产生的不可达对象需要在下一次GC 周期才能被回收
4. 并发清除
    清除所有未被标记的对象, 进行对象回收, GC 线程和 用户线程同时在运行
缺点: 
    1. 碎片化验证, 清除过程中不对内存进行压缩整理, 导致内存碎片话严重
    1.1 影响: 碎片化严重, 可能会导致老年代无法分配达对象, 触发full GC
    2. 浮动垃圾: 在并发标记期间产生的垃圾, 无法在当前GC周期被清除, 只能等到下一次GC
    2.1 影响: GC 效果不如预期, 需要预留更多的内存空间
    3. 某些情况下会退化成单线程回收
    3.1 如果堆内存不足以支撑程序的内存分配, 进而出发一次Full GC
    3.2 年轻代向老年代晋升, 如果老年代没有足够的空间去容纳这些对象的时候, 也会导致CMS 失败, 从而退化成单线程的Serial Old 收集器
    3.3 空间碎片化, 由于 CMS 回收产生的碎片化, 导致大对象无法找到连续的内存进行分配, 最终触发full GC
</code></pre>
<h3 id="G1收集器"><a href="#G1收集器" class="headerlink" title="G1收集器"></a>G1收集器</h3><pre><code class="hljs">    其中-XX:G1NewSizePercent  新生代比列默认时5%
    使用标记-整理算法
1. 标记阶段
    1. 初始标记
    从GC Roots 出发, 标记直接可达的对象, 需要进行STW
    2. 并发标记
        从GCRoots 出发, 找出存活对象, 应用线程和GC线程是可以同时活动的, 
    3. 再标记
        标记在并发标记时转移的对象
2. 清理阶段
        清点出有存活的对象和没有存活的对象
3. 复制阶段
    重新分配对象内存和复制成员变量, 转移的时候需要进行STW, 复制的耗时和存活对象的数量以及对象的复杂程度成正比
   
**初始标记**
    标记从GC Roots 出发的可达对象 需要进行STW
- **并发标记**
    标记整个堆中的存活对象, 不会进行STW
- **最终标记**
    完成并发标记, 并且处理在并发标记期间导致应用对象的变化, 需要进行STW
- **筛选回收**
    确定进行回收, 并根据收集的数据区域进行回收
- **拷贝回收**
    将存活的对象从回收区拷贝到新的区块, 方便进行回收
    特点:
        region 管理, 每个区域可能是Eden 区, 也可能是Survivor区, 也可能是old区
        并发标记和整理, 支持并发标记, 降低了STW 
        可预测的停顿时间
        优先回收: 维护一个优先队列, 根据各个区域回收的价值(回收成本和收益) 决定哪些要优先回收
    G1 怎么解决浮动垃圾:
        将对分割成多个region, 更加灵活的去管理和回收内存, 降低浮动垃圾的影响
        垃圾回收的时候, 可以进行并发标记和整理, 最大限度的降低程序的停顿
</code></pre>
<h3 id="ZGC"><a href="#ZGC" class="headerlink" title="ZGC"></a>ZGC</h3><pre><code class="hljs">通过染色指针和读屏障技术解决了对象转移的问题, 从而降低了耗时
    染色指针: 指针中存放了对象的一些信息, 例如对象是否被标记, 是否移动了, 相当于用空间换时间
</code></pre>
<h3 id="什么时候触发yong-GC"><a href="#什么时候触发yong-GC" class="headerlink" title="什么时候触发yong GC"></a>什么时候触发yong GC</h3><pre><code class="hljs">1. 新对象申请内存的时候, eden区发现内存不足, 则触发yong gc, 如果yong gc 后还是不足, 则直接进入老年代分配, 老年代分配也不足, 触发full gc
</code></pre>
<h1 id="spring"><a href="#spring" class="headerlink" title="spring"></a>spring</h1><h2 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h2><pre><code class="hljs">本质上是一个继承了annotation 的特殊接口
</code></pre>
<h2 id="IOC-和-AOP"><a href="#IOC-和-AOP" class="headerlink" title="IOC 和 AOP"></a>IOC 和 AOP</h2><pre><code class="hljs">1. IOC:
  核心是将对象的创建和依赖关系的管理交给 Spring 容器来处理, 开发者无需手动去创建或者管理对象, spring 的IOC 通过DI (依赖注入) 来实现
  	DI: Spring 容器会自动将对象的依赖注入给他们, 依赖注入可以通过 构造起注入, setter 方法注入, 或者字段注入
2. AOP:
    面向切面编程, 在允许不修改业务逻辑情况下, 通过定义好的切面, 将一些通用的功能模块化并动态的应用到业务逻辑中
    AOP 概念:
        Aspect: 代表了通用逻辑的模块化单位
        Join point: 指程序执行的过程中, 某个可插入切面的执行点, 通常是方法或者是对象的创建
        Advice: 通知
            Before: 在目标方法执行之前
            After: 在目标方法执行之后
            Around: 包裹目标方法执行
            AfterReturning: 目标方法成功执行后执行
            AfterThrowing: 目标方法异常执行后执行
    IOC 指的是控制反转, 将对象的创建和管理委托给spring容器, 而不是直接有应用程序代码直接控制
    AOP 指的是允许不修改代码的情况下, 方便的添加或者修改横切关注点
    AOP 一般通过动态代理来进行实现
        jdk 自身的动态代理: 基于java 的反射来进行实现的
        cglib 
</code></pre>
<h2 id="springBoot-的自动装配"><a href="#springBoot-的自动装配" class="headerlink" title="springBoot 的自动装配"></a>springBoot 的自动装配</h2><pre><code class="hljs">1. 通过注解或者是一些简单的配置就能在spring boot 的帮助下实现某块功能, 
2. @EnableAutoConfiguration: 启用springBoot的自动配置机制, 通过AutoConfigurationImportSelector 来实现的
     @Configuration
     @ComponentScan
</code></pre>
<h2 id="spring-注解的依赖"><a href="#spring-注解的依赖" class="headerlink" title="spring 注解的依赖"></a>spring 注解的依赖</h2><pre><code class="hljs">需要实现的bean 接口如下: BeanPostProcessor, ApplicationContextAware, BeanClassLoaderAware
    BeanPostProcessor 允许实例化之后以及bean 初始化方法之前调用
    ApplicationContextAware  在初始化的时候获取到Spring 上下文的引用, 从而可以访问容器中其他的bean或者执行的相关操作,
    BeanClassLoaderAware 提供classLoader的访问能力, 使得bean 可以动态加载资源

    BeanClassLoaderAware -&gt; ApplicationContextAware -&gt; PropertyPlaceholderConfigurer -&gt; BeanPostProcessor
</code></pre>
<h2 id="bean-生命周期"><a href="#bean-生命周期" class="headerlink" title="bean 生命周期"></a>bean 生命周期</h2><pre><code class="hljs">实例化: 根据@Configuration 或者是扫描到的@Component 等注解识别需要实例化的bean, 通过反射去调用无参构造函数去进行实例化
依赖注入: 将属性设置到实例化对象中
Aware 接口处理: 如果实现了beanNameAware 则调用setName 传递bean 名称, 实现BeanFactoryAware 则调用setBeanFactory, 实现ApplicationContextAware 则调用setApplicationContext 传递ApplicationContext
BeanPostProcessor 中的 postProcessBeforeInitialization
初始化: @PostConstruct 会调用初始化后的一些行为,  如果接口实现了 InitializingBean 的 afterPropertiesSet, 则会调用afterPropertiesSet
BeanPostProcessor 中的 postProcessAfterInitialization
准备就绪, 可以准备使用
bean 的销毁
</code></pre>
<h2 id="spring-如何解决循环以来的问题"><a href="#spring-如何解决循环以来的问题" class="headerlink" title="spring 如何解决循环以来的问题"></a>spring 如何解决循环以来的问题</h2><pre><code class="hljs">1. 通过三级缓存来处理
    1.1 一级缓存: 存储已经完全出时候的单例bean
    1.2 二级缓存: 用于存储正在创建的bean 的早期引用, 防止重复创建bean
    1.3 三级缓存: 用于存储尚未完全创建的bean 的工厂对象, 通过这个工厂对象可以获取bean 的早期引用
    具体创建过程
        创建bean a: spring 创建 bean a, 先把他放到三级缓存中, 表示a 处理创建过程中, 但是还没有完全初始化
        创建bean b: 创建a的时候发现依赖于b, 创建 bean b, 并放到三级缓存中
        创建bean b 的时候发现依赖于a, 于是检查缓存中是否有a, 发现a 还没有完全初始化, 但是存在a 的早期引用, 将早期引用放到b 中, 继续创建b
        bean b 创建完成, 将b 从三级缓存放到一级缓存, 表示完全初始化, 回到bean a, 完成a 的初始化, 放到一级缓存
2. @lazy
    表示bean 只需要在使用的时候才进行创建
</code></pre>
<h2 id="spring-事物什么时候会失效"><a href="#spring-事物什么时候会失效" class="headerlink" title="spring 事物什么时候会失效"></a>spring 事物什么时候会失效</h2><pre><code class="hljs">1. 确保所有使用@Transaction 的是 public 方法, 改成public
2. 一个类中的方法调用另外一个方法时会失效, 因为AOP 是通过代理类来的, 放到另外一个类中
3. 没有通过代理类出来的, 手动创建一个对象的, 而不是通过spring 的bean调用的
    // 错误的调用方式，事务不会生效
    MyService service = new MyService();
    service.method();
</code></pre>
<h2 id="spring-事物的传播机制"><a href="#spring-事物的传播机制" class="headerlink" title="spring 事物的传播机制"></a>spring 事物的传播机制</h2><pre><code class="hljs">1. REQUIRED(默认的)
    当前存在一个事物, 则加入该事物, 当前没有事物, 则创建一个新的事物, 如果一个方法回滚, 则整个事物会滚
2. SUPPORTS
    如果当前有事物, 则以事物的方式进行加入, 如果当前没有事物, 则以非事物的方式继续运行
3. REQUIRES_NEW 表示新开一个事物, 将当前事物进行挂起
4. NOT_SUPPORTED: 以非事物的方式运行, 将当前事物挂起

REQUIRED（默认）：加入当前事务，如果没有则创建一个新的事务。
REQUIRES_NEW：总是创建一个新的事务，暂停当前的事务。
NESTED：创建一个嵌套事务，在当前事务的上下文中运行，但具有独立的提交点。
SUPPORTS：支持当前事务，如果没有则不使用事务。
NOT_SUPPORTED：不使用事务，挂起当前事务。
NEVER：不允许当前存在事务，如果有事务则抛出异常。
MANDATORY：必须在已有事务中运行，如果没有事务则抛出异常
</code></pre>
<h2 id="FactoryBean-和-BeanFactory-区别"><a href="#FactoryBean-和-BeanFactory-区别" class="headerlink" title="FactoryBean 和 BeanFactory 区别"></a>FactoryBean 和 BeanFactory 区别</h2><pre><code class="hljs">1. BeanFactory
    定义: 是Spring 容器最基础的接口， 负责创建、管理、获取 spring 的beans， 他是IOC 容器的核心接口, 提供getBean 来获取容器中的bean
2. factoryBean
    定义: 是一个接口, 允许用户自定义创建复杂的bean, 本质上是一个用于生产bean 的工厂类， FactoryBean 自身也是一个spring 容器管理的bean 
    工作原理:
        当Spring 容器加载FactoryBean 时, 他会调用getObject 方法返回真正的bean, 而不是FactoryBean 本身, 
        如果要获得FactoryBean 则可以在getBean 的时候加上&amp; 符号
        MyFactoryBean factoryBean = (MyFactoryBean) factory.getBean(&quot;&amp;myFactoryBean&quot;);
</code></pre>
<table>
<thead>
<tr>
<th><strong>特性</strong></th>
<th><strong>BeanFactory</strong></th>
<th><strong>FactoryBean</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>作用</strong></td>
<td>Spring IoC 容器的核心接口，用于管理和获取 beans</td>
<td>用于自定义复杂对象的创建逻辑</td>
</tr>
<tr>
<td><strong>职责</strong></td>
<td>提供依赖注入、bean 生命周期管理等核心功能</td>
<td>定制复杂 bean 的创建，返回自定义对象</td>
</tr>
<tr>
<td><strong>常见实现</strong></td>
<td>ApplicationContext、XmlBeanFactory（已过时）</td>
<td>需要用户实现 FactoryBean 接口</td>
</tr>
<tr>
<td><strong>获取 bean</strong></td>
<td>直接通过 getBean() 获取 Spring 管理的 bean</td>
<td>调用 getObject() 方法来返回具体的 bean</td>
</tr>
<tr>
<td><strong>获取本身</strong></td>
<td>无法获取自身，getBean() 返回的是 bean</td>
<td>可通过 &amp; 前缀获取 FactoryBean 本身</td>
</tr>
<tr>
<td><strong>使用场景</strong></td>
<td>Spring 容器的核心，适用于所有 bean 管理</td>
<td>适用于需要复杂创建逻辑的 bean，例如代理对象、连接池</td>
</tr>
</tbody></table>
<h2 id="事物是否回滚"><a href="#事物是否回滚" class="headerlink" title="事物是否回滚"></a>事物是否回滚</h2><pre><code class="hljs">1. 默认遇到RuntimeException 或者是Error 的时候进行回滚
</code></pre>
<h2 id="springBoot-提供出来的扩展点有哪些"><a href="#springBoot-提供出来的扩展点有哪些" class="headerlink" title="springBoot 提供出来的扩展点有哪些"></a>springBoot 提供出来的扩展点有哪些</h2><pre><code class="hljs">1. ApplicationContextInitializer
    可以在spring 应用程序上下文刷新之前进行配置, 可以获取到Environment的信息
2. 从spring 容器中获取到bean 对象
    2.1 FactoryBean: beanFactory 是bean 工厂, factoryBean 是一种bean 的类型, 当容器注入的class 类型是FactoryBean 类型的时候, 最终生成bean 是通过FactoryBean 的getObject 获取到的
3. 实现自定义的HandlerInterceptor 拦截器
4. ApplicationContextAware 获取bean 对象
5. ApplicationListener 监听事件的
6. BeanPostProcessor bean 初始化前后做一些事情

    
</code></pre>
<h2 id="Autowired和-Resource"><a href="#Autowired和-Resource" class="headerlink" title="@Autowired和@Resource"></a>@Autowired和@Resource</h2><pre><code class="hljs">相同点: 
    都可以作为属性注入修饰, 在接口只有单一实现类的时候, 两个注解的修饰情况相同
不同点: 
    1. @Resource 是jdk 原生的, @Autowired 是spring 引入的注解
    2. @Autowired 默认按照byType 自动配置,(优先根据接口类型去匹配并注入bean)
         @Resource 是byName 进行配置的 (优先根据bean 的名字去进行匹配, 例如类名)
        当一个接口有多个类的时候, @Autowired 和 @Resource 都是需要通过名称才可以正确匹配到对应的name, @Autowired 可以通过@Qualified 来进行显示制定, @Resource 可以通过name 进行显示制定
    3. @Autowired 支持在构造函数、方法、字段、和参数上进行使用, @Resource 主要用于字段和方法上的注入, 不支持在构造函数或者是参数上进行使用
</code></pre>
<h1 id="注册中心"><a href="#注册中心" class="headerlink" title="注册中心"></a>注册中心</h1><h2 id="ZK"><a href="#ZK" class="headerlink" title="ZK"></a>ZK</h2><h3 id="zk-投票过程"><a href="#zk-投票过程" class="headerlink" title="zk 投票过程"></a>zk 投票过程</h3><pre><code class="hljs">投票采用paxos 算法实现
1. epoch 候选者的zxId(事物日志的id) 越大说明数据越新, 
2. zxId 相同比较epoch, epoch 相同比较服务器id
3. 服务器选票过半的成为leader

1. 节点分类
leader: 主节点，负责处理写请求，并将事务日志同步到从节点
flower: 从节点，接收 Leader 的同步数据，并参与读请求。
observer: 观察者节点，不参与选举和投票，但接收 Leader 的同步数据。
2. 选举算法
    Fast Leader Election 参考的点: zxid, myId, 当前数据的完整度和 机器的优先级
</code></pre>
<h3 id="zk-选举过程"><a href="#zk-选举过程" class="headerlink" title="zk 选举过程"></a>zk 选举过程</h3><pre><code class="hljs">重新选举的算法:
zk 集群进入不可用的时候, 会重新发起选举, 选举过程如下:
1. 每个节点重新发起投票, 投票的信息包含有ZXID, 服务器的id, zxid 代表该节点处理最新事物的id, id 越大代表处理的数据越新, 
    1.1 节点优先选择最新的zxID 做为leader,
    1.2 leader 相同的情况下选择 更大的服务器id
2. 每个节点收到其他节点的投票后, 将其与当前的投票进行比较, 如果接受到的投票比自己当前的投票更好, 具体比较过程参照zxId和 服务器id, 则更新自己的投票并重新广播
3. 每个节点投票获得超过半数后, 则该节点成为新的leader, 其他节点通过他进行同步数据
4. 新的leader 确定后, 进行数据同步
</code></pre>
<h3 id="zk-脑裂"><a href="#zk-脑裂" class="headerlink" title="zk 脑裂"></a>zk 脑裂</h3><pre><code class="hljs">如何解决ZK 脑裂问题
    1. 确保奇数个节点
    2. 网络分区的监控和恢复
    3. 启用Observer 节点
    4. 事物的日志和快照定期备份
    5. Quorums: 当集群中存活节点少于法定人数的时候, 集群不可用
    6. 冗余通信
</code></pre>
<h3 id="zk-写数据的过程"><a href="#zk-写数据的过程" class="headerlink" title="zk 写数据的过程"></a>zk 写数据的过程</h3><pre><code class="hljs">1. 客户端发起写的操作, 这个操作只能到leader 节点上去
2. leader 收到写请求后, 会生成一个zxId, 通知zxId 是递增的
3. leader 会将zxId 封装成一个propersal 进行广播, 基于zab 协议,确保所有flower 接收到
4. flower 接受propersal 并进行ACK 响应
5. leader 接受ACK, 过半就可以持久化写入
6. leader 进行commit, 并通知所有的flower
7. flower 收到leader 的commit 后并对自己进行刷新
8. leader 确认写完成后并通知客户端
通过写请求只能leader 处理、zxId 是递增的、zab 协议来实现一致性
P 的话通过法定人数, 过半节点
</code></pre>
<h3 id="zk-如何保证数据一致性"><a href="#zk-如何保证数据一致性" class="headerlink" title="zk 如何保证数据一致性"></a>zk 如何保证数据一致性</h3><pre><code class="hljs">zk 写数据的时候通过zab 协议来保证的
</code></pre>
<h3 id="zk-机器数量为啥是奇数"><a href="#zk-机器数量为啥是奇数" class="headerlink" title="zk 机器数量为啥是奇数"></a>zk 机器数量为啥是奇数</h3><pre><code class="hljs">因为奇数台机器和偶数台机器的容忍度是一样的. 为了防止增加不必要的机器. 因此最好是奇数台
</code></pre>
<h3 id="zab-协议"><a href="#zab-协议" class="headerlink" title="zab 协议"></a>zab 协议</h3><pre><code class="hljs">全局顺序一致性、原子广播(事物要么在集群的所有副本上提交成功, 要么在所有副本上提交失败)、崩溃恢复(当主节点出现宕机事件, 可以快速选举出新的主节点, 并从奔溃点恢复数据)
消息广播阶段:
    leader 负责接收客户端的请求, 并将请求做为 Proposal 向所有的 flower 进行广播
        1. leader 发送 proposal , leader 收到请求后, 会生成一个 proposal 并将其广播给所有的 flower 
        2. flower 收到 leader 发过来的 proposal 后, 先写入本地事物, 写入成功后向 leader 发送 ack 确认
        3. leader 收到大多数flower 的ack 后, 向所有的 flower 发送 commit 消息
        4. flower 收到 commit 消息后, flower 提交该事物并对外提供读物服务
    保证事物提交顺序的一致性		
奔溃恢复阶段:
    当leader 发生奔溃的时候, 重新选举
        1. 根据数据的日志、myId 选出一个新的leader. 当新的leader 被选举出来以后, 其他flower 通过新leader 来同步数据
</code></pre>
<h2 id="Eureka"><a href="#Eureka" class="headerlink" title="Eureka"></a>Eureka</h2><h3 id="eureka-数据同步过程"><a href="#eureka-数据同步过程" class="headerlink" title="eureka 数据同步过程"></a>eureka 数据同步过程</h3><pre><code class="hljs">1. 多节点部署与复制
eureka 集群中的各个节点会相互的同步注册信息和服务信息
2. 服务注册和同步的流程
1. 服务注册过程: 微服务向eureka 节点发送注册请求
2. 增量同步
    1. 服务注册的时候, 当一个服务实例向其中一个eureka 节点进行注册, 对应的eureka 节点会将该实例信息同步给其他的eureka 节点
    2. 服务续约. 服务节点定时给eureka 进行心跳请求续约, 每次续约都会触发增量同步
    3. 服务下线. 
    4. 服务状态变更
    2.1 实现方式:
        通过增量队列来实现的, 当有节点注册、续约、下线、状态变化的时候, 会放到增量队列中,eureka 会定时从增量队列中获取数据, 将需要同步的数据发送给其他节点, 其中防止很长时间都没有被同步, 增量队列中需要携带上时间戳, 可以用来进行触发全量同步
    自我保护机制, 设置成一个阈值可以判断时因为节点异常了,
    具体case
        服务实例向节点 A 注册，A 将该变更添加到自己的增量队列中。
        节点 A 定期检查增量队列，发现有新注册的服务实例。
        节点 A 通过增量同步的 API /eureka/v2/apps/delta，将该变更同步给节点 B。
        节点 B 接收到增量信息后，更新其本地的注册表，保持与节点 A 的数据一致性。
3. 全量同步
    3.1 节点重启: 当有一个节点重启了
    3.2 增量同步失败: 由于增量同步出现异常, 节点之间注册信息不一致, 触发全量同步. 增量同步失败的原因可能因为网络故障、超时、抖动等
    3.3 数据检测不一致: 节点会去定时检测其他节点信息和注册表中的数据是否一致, 发现有不一致的, 并且增量失败
    3.4 全量同步过程:
        3.4.1 节点向其他节点发送全量同步请求
        3.4.2 接受其他节点的全量注册信息, 
        3.4.3 将全量节点更新到本地
        3.4.4 恢复正常
4. 新的节点起来以后怎么做的数据同步
    全量同步
5. 如何通知给服务的消费方
    5.1 客户端通过定时拉的方式获取,初次时进行全量拉取, 后面是进行增量拉取
    5.2 拉增量失败后, 会触发拉取全量的
    5.3 当服务器进入到自我保护机制时, 拉取到的数据可能是旧的
</code></pre>
<h3 id="如何解决eureka-问题-当客户端很多的时候怎么处理-hash-环-虚拟节点"><a href="#如何解决eureka-问题-当客户端很多的时候怎么处理-hash-环-虚拟节点" class="headerlink" title="如何解决eureka 问题: 当客户端很多的时候怎么处理, hash 环 + 虚拟节点"></a>如何解决eureka 问题: 当客户端很多的时候怎么处理, hash 环 + 虚拟节点</h3><pre><code class="hljs">如何做到注册方的上下线, 秒级别推送:
  基于WS 或者是长轮训
      WS:
          1. 服务消费方在初始化过程中，会先经Session域名查询Session的IP地址列表并缓存到本地，然后再从列表中选择一台Session服务器与之建立 WebSocket长连接，并发送服务订阅请求。
          2. Session在收到服务订阅请求后，先会将服务订阅信息和 WebSocket 连接的映射关系存储到本地。后续当Session收到Data推送的服务变更消息时，它会先从上述映射关系中查询该服务对应的变更订阅方（即对应的WebSocket 连接列表），然后将消息通过这些连接推送出去。
          3. 在收到服务变更消息后，服务消费方会根据消息的内容更新本地缓存中的服务地址列表
  上下线的时候, data 节点通知所有的session 节点
</code></pre>
<h2 id="Consul"><a href="#Consul" class="headerlink" title="Consul"></a>Consul</h2><pre><code class="hljs">1. 通过WAN Gossip 协议 解决多数据中心的问题
WAN Gossip 协议: 通过随机选择节点进行数据交换, 但是传播速度比较慢, 节点可能会有重复的数据通信,
</code></pre>
<h2 id="注册中心发布怎么解决"><a href="#注册中心发布怎么解决" class="headerlink" title="注册中心发布怎么解决"></a>注册中心发布怎么解决</h2><pre><code class="hljs">一是关闭/启动应用程序前，先拉出服务实例，程序启动成功后，再拉入服务实例；二是客户端负载均衡自动拉出访问异常服务实例。
</code></pre>
<h1 id="netty"><a href="#netty" class="headerlink" title="netty"></a>netty</h1><h2 id="Netty-的一次网络请求过程是什么"><a href="#Netty-的一次网络请求过程是什么" class="headerlink" title="Netty 的一次网络请求过程是什么"></a>Netty 的一次网络请求过程是什么</h2><pre><code class="hljs">服务端
    初始化阶段
        创建EventLoopGroup, bossGroup 和 workerGroup, bossGroup 负责接受请求, workerGroup 负责处理 BossGroup 分配过来的IO 操作
        配置 serverBootstrap : 使用 ServerBootstrap 来配置 Netty 服务, 包括 channel 的类型, 指定 EventLoopGroup, 配置 channelPipeline , 以及设置服务器的监听端口
    绑定端口
        serverBootStrap.bind() 方法绑定服务器的监听端口, 会启动一个异步操作过程, bossGroup 中的线程会监听这个连接请求
        bind() 返回一个future, 可以通过sync()  或者是addListener 来等待响应
    接受客户端请求
        bossGroup 中的线程会去监听端口的连接请求, 当有新的请求进来的时候, Netty会为这个连接创建一个channel, 并将其分配给worker 的EventLoop上,
        注册channel: 新的channel 会被注册在worker Group 中的eventLoop 上, 接下来和这个连接的相关读写操作都是在这个EventLoop 上
    处理客户端请求
        每个channel 关联的channelpipeline, 包含了一系列的handler
        当客户数据到达的时候, 数据会通过channelPipeline 中的inbounder 来进行处理, 负责数据的读取, 解码，业务逻辑处理等
    响应客户端
        当业务逻辑处理完后, 通过会通过ChannelHandlerContext.writeAndFlush() 将数据响应回给客户端
        数据会通过channelpipeline 中的outbounder，然后通过底层的socket 发送给客户端
    关闭连接
        客户端关闭连接, 或者是服务端主动关闭连接的时候, Netty 会处发ChannelInbounderHandler 的channelInactive 或者是channelUnregistered, 可以进行资源清理
        在关闭服务器的时候, 需要调用bossGroup 和worker Group 的shutdownGracefully 进行线程资源的释放
客户端
    初始化:
        EventLoopGroup 的创建, 用于管理和服务之间网络链接和IO 操作, Bootstrap 配置客户端的各种参数, 包括线程模型, NioSocketChannel, 远端服务器的地址, 以及客户端的handler
    建立链接
        连接服务器: 通过Bootstrap.connect() 方法启动连接过程, 链接成功后会将channel 注册到event loop 上
        等待建立连接完成:  connect() 返回一个ChannelFuture, 可以通过sync() 或者是addListener 进行完成
    发送请求
        构造数据进行请求, 连接成功后, 通过channel 向服务器发送数据, 通常是将请求封装成 ByteBuf 
        对数据进行writeAndFlush 写数据, 数据会通过ChannelPipeline 的outbounder 进行处理, 通过底层的socket 发送到服务器
    接收响应
        pipeline 处理, 当服务器响应数据到的时候, 数据会到channelHander 的inbounder,
        处理响应数据: 业务逻辑进行处理, 处理完后返回给应用层
    关闭连接
        主动关闭连接: channel.close 关闭连接, 释放资源
        监听关闭操作: close 返回的future 进行监听, 进行监听关闭是否成功。
    资源清理
        group.shutDownGracefully() 进行清理
</code></pre>
<h2 id="Channel-的作用"><a href="#Channel-的作用" class="headerlink" title="Channel 的作用"></a>Channel 的作用</h2><pre><code class="hljs">负责网络IO操作相关的
    1.1 管理IO 操作
        对数据读取、发送、和连接的管理
    1.2 处理事件
        从网络传输到channelPipeline, 将channelPipeline 处理后的数据返回到网络中去
    1.3 支持异步IO
        即将数据异步写入到网络中,不会阻塞当前线程
</code></pre>
<h2 id="EventLoop-作用"><a href="#EventLoop-作用" class="headerlink" title="EventLoop 作用"></a>EventLoop 作用</h2><pre><code class="hljs">1.每一个EventLoop 维护着一个 Selector 和 线程
2.处理IO 事件和任务
    监视和处理IO事件, 基于Java NIO 的selector 事件
3. 任务的调度
    还可以管理定时任务和普通任务, 可以提交任务到eventLoop上, 按照顺序和指定周期执行
4. 线程管理
    一个eventLoop通常和一个线程绑定, 每个eventLoop 可以维护多个channel, 但一个channel 始终绑定在一个eventLoop 上, 确保了同一个channel 上的事件处理是线程安全的
5. 事件的派发与处理
    负责从IO操作中获取事件, 将这些事件派发到对应的ChannelHandler中, 每个channel 代表一个连接或者IO操作, 在其pipeline中的一系列处理
</code></pre>
<h3 id="EventLoop-执行的流程"><a href="#EventLoop-执行的流程" class="headerlink" title="EventLoop 执行的流程"></a>EventLoop 执行的流程</h3><pre><code class="hljs">1. eventLoop 的线程模型
    由eventLoopGroup 管理,  他是一个单线程的执行器, 专门处理IO任务, 
    每个channel 都绑定了一个固定的eventLoop, 从创建到关闭期间一直由该eventLoop 负责处理
    EventLoopGroup 有多个eventLoop 实例构成, 但是一个eventLoop 始终对应一个线程, 线程是复用的
2. selector 机制
    eventLoop 的核心任务是事件循环, 通过不断的轮训selector, 检查是否有IO 事件, 如果有事件发生, 则eventLoop 会将事件分发给channel 对应的pipeline 进行处理
3. 任务队列
    可以用于任务的提交与处理
4. channelPipeline 和 channelHandler 处理
    当eventLoop 轮训到IO事件的时候, 通过 channelPipeline 来传递这些事件, 其中channelPipeline 是一组 channelHandler 组成
5. 任务调度机制
    eventLoop 可以处理定时调度任务, 类似于schedule 的任务
    任务在eventLoop 中的任务队列中管理, eventLoop 定期检查是否有任务
6. eventLoop 的执行流程
    1. 选择IO事件: 通过 Selecor.slect() 阻塞,  等待IO事件, 如果有事件触发, 进行下一步
    2. 处理IO 事件: 将事件触发分发到对应的 channelPipeline , 交给注册的 channelHandler 来处理
    3. 执行任务队列中的任务: 处理完IO 事件后, 从任务队列中获取任务并执行, 
    4. 继续轮训IO: 完成任务后继续进入selecot.select()轮训, 等待事件
</code></pre>
<h3 id="Selecor-机制"><a href="#Selecor-机制" class="headerlink" title="Selecor 机制"></a>Selecor 机制</h3><pre><code class="hljs">Selecor: 可以用来检测 channel 是否准备好进行 IO 操作的对象, 通过 Selecor , 一个线程可以管理多个 Channel 
Channel: 代表一个 IO 连接
SelectionKey: 记录 Channel 在  Selector 上的注册状态, 包含事件类型
事件类型: 
    OP_ACCEPT: 接受连接就绪
    OP_CONNECT: 连接完成
    OP_READ: 读操作完成
    OP_WRITE: 写操作就绪
工作机制:
    注册 Channel , 将channel 注册到 Selector 上, 告诉我们关联的事件类型,  每个注册的 channel 会关联一个 channelKey, 标识该channel 的状态
    选择IO事件: 在调用Selector.select() 的时候, 同步等待 Selector 准备好的Channel， 进行响应的 IO  操作, 
    处理就绪的Channel:  当Selecotor 检测到某个 Channel 有事件准备好的时候, 返回关联的 selectionKey, 通过selectionKey 进行对应的IO 操作
    清理处理过的事件
优缺点:
    优点: 一个线程可以管理多个Channel, 减少线程的上下文切换
                Selector 可以避免 BIO , 提供性能
                支持大规模并发连接
    缺点:
        空轮训问题
netty 利用Selector 机制来监听网络IO 事件, eventLoop 负责调用 Selector.select() 方法获取注册的 Channel, 根据事件触发 netty 的channelHandler 来进行处理, eventLoopGroup 会处理大量的并发连接, 每个eventLoop 在一个线程中运行, 不同的channel 分配到不同的EventLoop 上
netty 怎么解决空轮训问题
    1. 监测selector 是否进入空轮训, 默认是512, 如果发现 selector 轮训多次没有返回任何事件, 任务可能出现空轮训, 销毁并创建新的Selector, 避免空轮训CPU 过高
    2. 通过设置合理的超时时间
</code></pre>
<h2 id="EventLoopGroup-作用"><a href="#EventLoopGroup-作用" class="headerlink" title="EventLoopGroup 作用"></a>EventLoopGroup 作用</h2><pre><code class="hljs">用于管理所有的EventLoop, 一个 EventLoopGroup 用于管理多个线程来并发去处理执行IO 事件
</code></pre>
<p>Channel 是网络通信的管道, 负责实际数据的读写, EventLoop 是负载驱动Channel 的 执行, 通过循环监听IO 事件来处理这些事件, EventLoopGroup 是多个EventLoop 的管理着, 负责分配和管理多个EventLoop, 并支持多并发处理多个Channel</p>
<h2 id="常见参数"><a href="#常见参数" class="headerlink" title="常见参数"></a>常见参数</h2><pre><code class="hljs">.option(ChannelOption.SO_REUSEADDR, Boolean.TRUE)
           - **用途**: 允许重用本地地址和端口。
           - **适用场景**: 服务器端 `ServerSocketChannel`。
           - **解释**: 
             - `SO_REUSEADDR` 允许多个 `Socket` 绑定到同一个地址和端口。通常用于服务器重启时避免“地址已占用”的错误。
             - `SO_REUSEPORT`（在一些平台支持）允许多个进程绑定到同一个端口，帮助实现负载均衡。
           - **默认值**: `false`。
.option(ChannelOption.ALLOCATOR, ByteBufManager.byteBufAllocator)
       - **用途**: 设置 ByteBuf 的分配器（`ByteBufAllocator`）。
       - **适用场景**: 服务器端和客户端。
       - **解释**: 
         - Netty 提供了 `PooledByteBufAllocator` 和 `UnpooledByteBufAllocator` 两种分配器。`PooledByteBufAllocator` 使用内存池，适合高性能场景；`UnpooledByteBufAllocator` 则每次分配新的缓冲区，适合短连接或对内存要求不高的场景。
       - **默认值**: `PooledByteBufAllocator`。
.childOption(ChannelOption.SO_KEEPALIVE, Boolean.TRUE)
       - **用途**: 启用 TCP 保活机制。
       - **适用场景**: 适用于客户端和服务器端的 `SocketChannel`。
       - **解释**: 
         - 如果启用 `SO_KEEPALIVE`，TCP 会定期发送保活包，检查连接是否还保持有效。适用于长连接的应用程序，确保连接在无数据传输时不会无故断开。
       - **默认值**: `false`（禁用保活）。
.childOption(ChannelOption.TCP_NODELAY, Boolean.TRUE)
       - **用途**: 启用或禁用 Nagle 算法。
       - **适用场景**: 用于客户端和服务器端的 `SocketChannel`。
       - **解释**: 
         - Nagle 算法通过合并小的数据包来减少网络拥塞。如果应用程序需要低延迟通信（如实时应用），可以将 `TCP_NODELAY` 设置为 `true`，禁用 Nagle 算法，使得数据尽快发送。
       - **默认值**: `false`（启用 Nagle 算法）。
.childOption(ChannelOption.ALLOCATOR, ByteBufManager.byteBufAllocator)
       - **用途**: 设置 ByteBuf 的分配器（`ByteBufAllocator`）。
       - **适用场景**: 服务器端和客户端。
       - **解释**: 
         - Netty 提供了 `PooledByteBufAllocator` 和 `UnpooledByteBufAllocator` 两种分配器。`PooledByteBufAllocator` 使用内存池，适合高性能场景；`UnpooledByteBufAllocator` 则每次分配新的缓冲区，适合短连接或对内存要求不高的场景。
       - **默认值**: `PooledByteBufAllocator`。
</code></pre>
<h2 id="如何实现零拷贝"><a href="#如何实现零拷贝" class="headerlink" title="如何实现零拷贝"></a>如何实现零拷贝</h2><h3 id="什么是零拷贝"><a href="#什么是零拷贝" class="headerlink" title="什么是零拷贝"></a>什么是零拷贝</h3><pre><code class="hljs">零拷贝指的是全程不需要CPU 进行参与, 所有数据都是通过DMA来进行传输的
    传统的:
        4次上下文切换, 4 次 拷贝
            用户态发起读文件, 一次是写文件. 每次读写都是用户态切换到内核态, 内核完成后, 再从内核台切换为用户态
            2 次 CPU 拷贝, 2 次 DMA 拷贝
            第一次拷贝: 把磁盘中的数据拷贝到操作系统的内核缓冲区中, 通过DMA来操作
            第二次拷贝: 把内核缓冲区的数据拷贝到用户缓冲区中, 此时用户可以使用这部分数据, 通过CPU 拷贝来完成
            第三次拷贝: 把刚刚拷贝过来的数据, 再拷贝到内核缓冲区, 通过CPU 拷贝来操作
            第四次拷贝: 把内核缓冲区数据 拷贝到网卡的缓冲区中, 通过DMA 来操作的
    mmap
        4 次上下文切换, 2次拷贝
        应用进程调用 mmap 的时候, DMA 会把磁盘中的数据拷贝到内核缓冲区中, 此时应用进程和操作系统进程共享这个缓冲区
        应用进程调用write 的时候, 操作系统直接将内核缓冲区中的数据拷贝到socket 缓冲区中。
        最后可以通过DMA 将内核缓冲区数据拷贝到网卡缓冲区中
        4 次上下文切换, 3 次拷贝
    sendFile
        sendFile 可以直接代替read 和 write, 减少1次系统调用, 2次上下文切换
        全程只需要2次上下文切换, 2次SG-DMA数据copy
</code></pre>
<h3 id="netty-如何实现零拷贝"><a href="#netty-如何实现零拷贝" class="headerlink" title="netty 如何实现零拷贝"></a>netty 如何实现零拷贝</h3><pre><code class="hljs">1. Fileregion 的sendFile
    sendFile 在内核中支持完成数据直接从硬盘中传输到网卡中, 不需要将数据拷贝到用户空间态。避免了数据的来回拷贝
2. ByteBuf 的直接内存 DirectBuf
     DirectBuf 是分配在堆外的, 数据可以直接在内核态和直接内存进行传输， 避免了堆上的拷贝, 堆外的DirectByteBuf 通过JNI访问, 数据不需要先拷贝到JVM 的堆内存上, 直接操作操作系统, 在进行IO的时候, 可以减少一次内存拷贝
3. composite Buffer
    通过CompositeByteBuf, 可以将多个不同的ByteBuf 组合成一个逻辑上的ByteBuf, 而不会进行数据拷贝, 每个子的ByteBuf 保持独立的内存空间。 
4. Sokcet 缓冲
    在网络IO的时候, 避免将数据直接从操作系统的socket 缓冲区拷贝到用户空间, 而是直接引用缓冲区数据操作
5. mmap 内存映射
    通过mmap 将文件映射到内存, 从而避免文件读写下的多次数据拷贝
</code></pre>
<h2 id="为什么需要将网络容器从tomcat-换成Netty"><a href="#为什么需要将网络容器从tomcat-换成Netty" class="headerlink" title="为什么需要将网络容器从tomcat 换成Netty"></a>为什么需要将网络容器从tomcat 换成Netty</h2><pre><code class="hljs">1. 从业务角度去看: 请求流量高的时候, 2C 和 2B 的流量有影响
2. 解决方案上怎么去排查
vmstat 1
/proc/stat 
top 等可以判断进程啥下文切换
可以检测上下文切换是否很高,
1. 实现机制上:
     serverlet 通过 startAsync 本质上依赖线程池去进行处理, netty天生为异步非阻塞的, 使用事件驱动的方式, 每个EventLoop 可以处理多个IO操作事件,可以极大的降低了线程数和线程切换的开销
2. 线程模型:
    serverlet 3.0异步依赖容器的线程管理, 在并发增加的情况下可能会导致线程的耗尽; netty 中使用少量的worker 线程来处理事件, 减少了上下文的切换, 避免了传统线程池模型的问题.
3. IO 模型
    serverlet 3.0 虽然支持异步处理, 但是底层依赖于阻塞IO模型; netty 使用java NIO 的非阻塞式, 从底层上确保了高并发表现的性能
4. 并发高的情况下 tomcat 由于采用的是BIO 加上异步线程的方式去处理的, 会有大量的线程产生, CPU 内存 文件描述符都会发生资源竞争，netty 是通过NIO 方式去做的，使用少量的worker 线程就可以去处理
</code></pre>
<h2 id="tomcat-通过startAsync-来实现线程的切换"><a href="#tomcat-通过startAsync-来实现线程的切换" class="headerlink" title="tomcat 通过startAsync 来实现线程的切换"></a>tomcat 通过startAsync 来实现线程的切换</h2><pre><code class="hljs">1. 通过startAsync 开启异步, 并生成一个 AsyncContext 的对象
2. 调用后, tomcat 会释放当前的线程资源, 将请求挂起, 此时客户端的连接仍然保持打开, 但是占用tomcat 的资源
3. 等待后台任务完成或者超时后, 会通过线程池去进行处理
</code></pre>
<h3 id="tomcat-通过startAsync-和-netty-的区别"><a href="#tomcat-通过startAsync-和-netty-的区别" class="headerlink" title="tomcat 通过startAsync 和 netty 的区别"></a>tomcat 通过startAsync 和 netty 的区别</h3><pre><code class="hljs">从架构和模型上
    1. tomcat 是基于 servlet 规范来做的, 虽然是基于NIO去做了, 但是依赖于传统的阻塞IO 
    2. netty 支持异步非阻塞的处理请求
从线程管理上
    1. 使用固定的线程池来处理, startAsync 通过启动新的线程来处理异步任务, 但是还是依赖于 servlet 容器管理的线程
    2. netty 通过使用 eventLoop 和 workGroup 的worker 线程进行管理, 可以处理大量的并发连接.
异步处理方式上
    1. tomcat 通过startAsync 时需要手动去管理异步的上下文, 适用于 servlet API 约定的方式
    2. netty 是基于异步非阻塞的, 所有的 IO 都是异步的, 用户可以通过使用回掉或者是future 机制处理结果
</code></pre>
<h3 id="serverlet-和-reactor-对比有什么缺点"><a href="#serverlet-和-reactor-对比有什么缺点" class="headerlink" title="serverlet 和 reactor 对比有什么缺点"></a>serverlet 和 reactor 对比有什么缺点</h3><pre><code class="hljs">1. servlet 是阻塞式IO, 线程管理和有限的扩展,在高并发下会导致大量的线程上下文切换, 增加了CPU 的开销
2. reactor 使用少量的线程就可以处理大量的请求, 因为显著的减少了线程的上下文切换
其中线程的上下文指的是线程在运行中所需要维护的各种信息
    1. CPU 寄存器的信息
    2. 栈信息: 保存局部变量表、方法调用链和返回地址等信息
    3. 线程局部存储
    4. 线程优先级
    5. 程序计数器等信息
</code></pre>
<h3 id="为什么netty-用少量的worker-线程就可以做到同样tomcat-的事情"><a href="#为什么netty-用少量的worker-线程就可以做到同样tomcat-的事情" class="headerlink" title="为什么netty 用少量的worker 线程就可以做到同样tomcat 的事情"></a>为什么netty 用少量的worker 线程就可以做到同样tomcat 的事情</h3><pre><code class="hljs">1. 事件驱动的设计
    因为netty 是基于reactor 的事件驱动模型,worker 不处理整个请求的生命周期, 只响应或底层发出的网络事件, 使得只有事件触发的时候才去执行任务, 而不是阻塞等待
2. 非阻塞 I/O
    netty 使用的NIO 为非阻塞IO, selector 机制: 通过NIO的selector的机制, netty 可以让worker 线程管理多个channel, 当selector监听到某个channel 有IO 事件的时候, 该线程才会去处理这个channel, 在没有事件时, 线程会去监听而不被阻塞
3. 任务划分与分离
    bossGroup 和 workerGroup 的职责分离, bossGroup 专门处理连接的建立和关闭, 而worker Group 专注于处理已建立的连接的读写操作. 从而避免了线程资源的抢占
4. 避免线程上下文的切换. 
    IO 的多路复用技术, 可以让一个线程监听多个channel 上的事件, 当channel 准备好读写的时候, 线程可以立即处理, 从而显著减少了线程数量
</code></pre>
<h2 id="为什么要用netty"><a href="#为什么要用netty" class="headerlink" title="为什么要用netty"></a>为什么要用netty</h2><pre><code class="hljs">事件驱动模型:
    基于reactor模式去做的, 通过EventLoop来管理IO 操作事件, 并将这些事件派发给相关的channelHandler, 实现高效的网络通信, 可以处理大量的并发连接
    核心组建:
        eventLoop:
                1.每一个EventLoop 维护着一个 Selector 和 线程
                2.处理IO 事件和任务
                    监视和处理IO事件, 基于Java NIO 的selector 事件
                3. 任务的调度
                    还可以管理定时任务和普通任务, 可以提交任务到eventLoop上, 按照顺序和指定周期执行
                4. 线程管理
                    一个eventLoop通常和一个线程绑定, 每个eventLoop 可以维护多个channel, 但一个channel 始终绑定在一个eventLoop 上, 确保了同一个channel 上的事件处理是线程安全的
                5. 事件的派发与处理
                    负责从IO操作中获取事件, 将这些事件派发到对应的ChannelHandler中, 每个channel 代表一个连接或者IO操作, 在其pipeline中的一系列处理
        channel:
            负责网络IO操作相关的
            1.1 管理IO 操作
                对数据读取、发送、和连接的管理
            1.2 处理事件
                从网络传输到channelPipeline, 将channelPipeline 处理后的数据返回到网络中去
            1.3 支持异步IO
                即将数据异步写入到网络中,不会阻塞当前线程
        channelPipeline: 
            是一个处理链, 每个IO 事件都会按照顺序通过channelPipeline, 将多个channelHandler连接起来, 形成一条链, 每个channelHandler只负责处理特定的事件
        channelHandler: 
            用于处理特定类型事件的处理器, 不同的channelHandler 实现不同的功能, 有的可以用来编解码, 有的可以用来处理连接事件
        Selector: 
            用于监听多个Channel 上的IO 事件, 当selector 发现某个Channel 上有事件发生的时候, 会通过EvenetLoop 来进行处理
    工作流程:
        boosGroup 和 workerGroup
            bossGroup 负责监听客户端的连接请求事件, 将接收请求并将连接交给workerGroup进行处理
            workerGroup负责处理具体的IO 操作
        事件的监听与触发
            当有IO发生的时候, EventLoop 会从selector 中获取到该事件, 并将其传递给绑定的channel
            事件会按照事件类型依次在channelPipeline 上流过, 通过channelHandler 来具体处理
        channelHandler 处理事件
            入站事件有inbounder 处理, 出站事件由outbounder 处理
            每个channelHandler 可以对事件进行处理, 处理完成后让下一个处理器进行处理
    线程模型
        EventLoop 绑定一个线程, 因此EventLoop管理的channel 也是在同一个线程上去运行的, 确保每个channel 上的事件处理是安全的, 从而减少了上下文切换的开销		
支持零拷贝
    零拷贝指的是全程不需要CPU 进行参与, 所有数据都是通过DMA来进行传输的
    全程只需要2次上下文切换, 2次DMA数据copy
ByteBuf 好处:
    1. 容量可以动态的调整
    2. 支持零拷贝, 减少数据在不同内存区域之间的复制, 
    3. polling 机制 从而进行重复利用
</code></pre>
<h1 id="场景题"><a href="#场景题" class="headerlink" title="场景题"></a>场景题</h1><h2 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h2><pre><code class="hljs">高并发场景下, 怎么保证最可能的一致性
    缓存扰动: 刚更新的缓存没有被读取到, 再次被更新的情况下
    Cache-Aside
        读请求中: 首先请求缓存, 如果命中缓存, 则直接返回缓存中的数据, 如果没有命中缓存, 则将查询出来的数据更新到缓存中, 然后返回查询出来的结果数据
        写请求: 先更新数据库, 再删除缓存
            为什么是删除缓存, 而不是更新
                直接删除的时候性能高: 缓存中的数据可能是由多个条件下聚合出来的,
                更加安全: 可能将旧的值放入到缓存中, 两个线程同时去更新数据的情况下
            先更新数据库, 在删除缓存防止 缓存中的数据是老的

            删除缓存, 更新缓存, 更新数据库
    先更新数据库	 -&gt; 删除缓存
            优点: 删除缓存是因为性能更高, 写请求中更新可能导致数据的不一致性
            缺点: 在读写下面也会有并发问题 T1 去读取数据, T2 去更新数据, T1 中更新晚于T2的缓存删除更新
    删除缓存 -&gt; 更新数据库
            读写并发的时候可能导致缓存脏数据, 可以通过延迟双删
                1. 或者是在写请求的情况下加锁, 保证更新数据库和删除缓存串行处理
            缓存删除失败的情况下 需要引入MQ 或者是 监听数据库消费来解决
            优点
            缺点
    Write-Through
    更新数据库 -&gt; 更新缓存
        通过分布式锁 来解决更新数据库和更新缓存的一致性, 或者是将请求放到MQ中去处理
            优点
            缺点
    Write-Through
        或者是后续批量去进行写, 针对写特别多的情况下去做
    更新缓存 -&gt; 更新数据库
            优点
            缺点
        加上补偿机制
        分布式锁
    读多写少的情况下:
        Cache-Aside 结合数据库日志做补偿
    写多读少的情况下, 并且对于一致性要求比较高的情况下
        Write-Through结合分布式锁:	
            写后去更新缓存
        极端情况下:Write-Behind
</code></pre>
<!-- 
## 为什么需要将网络容器从tomcat 换成Netty
    1. 实现机制上:
         serverlet 通过 startAsync 本质上依赖线程池去进行处理, netty天生为异步非阻塞的, 使用事件驱动的方式, 每个EventLoop 可以处理多个IO操作事件,可以极大的降低了线程数和线程切换的开销
    2. 线程模型:
        serverlet 3.0异步依赖容器的线程管理, 在并发增加的情况下可能会导致线程的耗尽; netty 中使用少量的worker 线程来处理事件, 减少了上下文的切换, 避免了传统线程池模型的问题.
    3. IO 模型
        serverlet 3.0 虽然支持异步处理, 但是底层依赖于阻塞IO模型; netty 使用java NIO 的非阻塞式, 从底层上确保了高并发表现的性能
    4. 并发高的情况下 tomcat 由于采用的是BIO 加上异步线程的方式去处理的, 会有大量的线程产生, CPU 内存 文件描述符都会发生资源竞争，netty 是通过NIO 方式去做的，使用少量的worker 线程就可以去处理
 -->
<h1 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h1><h2 id="MESI-协议"><a href="#MESI-协议" class="headerlink" title="MESI 协议:"></a>MESI 协议:</h2><pre><code class="hljs">    多核处理器的缓存一致性协议, 用来保证多个处理器之间数据一致性
</code></pre>
<h2 id="paxos-算法-zab-协议"><a href="#paxos-算法-zab-协议" class="headerlink" title="paxos 算法,zab 协议"></a>paxos 算法,zab 协议</h2><pre><code class="hljs">    zab 协议: 
        重新选举的算法:
            zk 集群进入不可用的时候, 会重新发起选举, 选举过程如下:
            1. 每个节点重新发起投票, 投票的信息包含有ZXID, 服务器的id, zxid 代表该节点处理最新事物的id, id 越大代表处理的数据越新, 
                1.1 节点优先选择最新的zxID 做为leader,
                1.2 leader 相同的情况下选择 更大的服务器id
            2. 每个节点收到其他节点的投票后, 将其与当前的投票进行比较, 如果接受到的投票比自己当前的投票更好, 具体比较过程参照zxId和 服务器id, 则更新自己的投票并重新广播
            3. 每个节点投票获得超过半数后, 则该节点成为新的leader, 其他节点通过他进行同步数据
            4. 新的leader 确定后, 进行数据同步
</code></pre>
<h2 id="zk-和其他注册中心对比-Eureka"><a href="#zk-和其他注册中心对比-Eureka" class="headerlink" title="zk 和其他注册中心对比 Eureka"></a>zk 和其他注册中心对比 Eureka</h2><pre><code class="hljs">  ZK CP Eureka 是AP 
</code></pre>
<h3 id="防止ZK-脑裂"><a href="#防止ZK-脑裂" class="headerlink" title="防止ZK 脑裂"></a>防止ZK 脑裂</h3><pre><code class="hljs">  如何解决ZK 脑裂问题
  1. 确保奇数个节点
  2. 网络分区的监控和恢复
  4. 启用Observer 节点
  5. 事物的日志和快照定期备份
  6. Quorums: 当集群中存活节点少于法定人数的时候, 集群不可用
  7. 冗余通信
</code></pre>
<h2 id="系统变得很慢怎么处理"><a href="#系统变得很慢怎么处理" class="headerlink" title="系统变得很慢怎么处理"></a>系统变得很慢怎么处理</h2><pre><code class="hljs">    1. 确认问题,  通过系统监控、日志确认系统的实际情况和性能
    2. 定位问题:  通过监控、
    3. 分析问题:
        1. CPU: top 查看CPU 负载 以及load 的情况, 查看占用CPU 资源高的原因
        2. 磁盘IO: iostat 查看磁盘的情况
        3. 网络情况: 查看网络是否正常
        4. 数据库
        5. 内存占用情况(机器的以及堆上的, jmap)
        6. 线程是否有死锁, jstack
        7. 查看外部请求是否有block, 是否有强依赖的情况
    4. 解决问题
    5. 验证是否解决了
应用服务器监控内容
    1. 资源监控
    2. 日志监控
    3. 健康监控
    4. 实时监控
</code></pre>
<h2 id="LB-算法"><a href="#LB-算法" class="headerlink" title="LB 算法"></a>LB 算法</h2><pre><code class="hljs">1. 随机
2. 加权随机
3. 轮训
4. 最少连接
5. 最短响应
6. P2C
    1. 当有请求到的时候, 从所有可用节点中随机选择两台
    2. 比较当前两个节点当前负载
    3. 将请求转发给负载比较轻的节点
</code></pre>
<h2 id="zk-watch-机制"><a href="#zk-watch-机制" class="headerlink" title="zk watch 机制"></a>zk watch 机制</h2><pre><code class="hljs">ZooKeeper（ZK）中的 watch 机制 是一种轻量级的事件通知机制，允许客户端注册对某些节点状态变化的监听。当被监控的节点发生变化时，ZooKeeper 会通知相应的客户端。这种机制可以有效帮助客户端实时感知分布式系统中数据的变化，是 Zookeeper 作为分布式协调服务的重要特性。
</code></pre>
<h2 id="服务治理是什么"><a href="#服务治理是什么" class="headerlink" title="服务治理是什么"></a>服务治理是什么</h2><pre><code class="hljs">业务在刚开始的时候往往都是单体应用, 随着用户量和访问量的增加, 架构上会从单体应用转换成分布式应用, 把单体应用中的每个模块按照特定的方法去进行拆分, 服务和服务之间通过HTTP 或者是 RPC 方式调用, 服务注册与发现、负载均衡、熔断限流、服务路由、监控、自动扩展与降级、服务的配置
</code></pre>
<h2 id="分布式调用-如果对于下游不是强依赖的-下游服务挂掉-或者下游服务吞吐量不高怎么做"><a href="#分布式调用-如果对于下游不是强依赖的-下游服务挂掉-或者下游服务吞吐量不高怎么做" class="headerlink" title="分布式调用. 如果对于下游不是强依赖的, 下游服务挂掉, 或者下游服务吞吐量不高怎么做"></a>分布式调用. 如果对于下游不是强依赖的, 下游服务挂掉, 或者下游服务吞吐量不高怎么做</h2><pre><code class="hljs">1. 设置适当的超时时间
2. 熔断
3. 重试
如果下游服务挂了, 如何做到最小资源浪费, 流量半开的机制是什么
</code></pre>
<h2 id="限流算法"><a href="#限流算法" class="headerlink" title="限流算法"></a>限流算法</h2><pre><code class="hljs">1. 计数器
实现方式: 在一个固定的时间内, 维护一个计数器, 记录当前请求的次数, 超过预定的值, 就进行限流
优点: 简单
缺点: 窗口边界有突发流量
假设1min内服务器的负载能力为100，因此一个周期的访问量限制在100，然而在第一个周期的最后5秒和下一个周期的开始5秒时间段内，分别涌入100的访问量，虽然没有超过每个周期的限制量，但是整体上10秒内已达到200的访问量，已远远超过服务器的负载能力，由此可见，计数器算法方式限流对于周期比较长的限流，存在很大的弊端
2. 滑动窗口
实现方式: 将固定的窗口分割成细小的窗口, 通过不断的滑动来统计某段时间内的流量请求情况,
优点: 减少临届问题, 限流更加平滑
缺点: 实现复杂度高, 内存占用高
3. 漏桶
实现方式: 将请求流量看成是水流, 漏桶以固定的速率漏水, 如果漏桶满了, 超出的流量则被丢弃或者是排队处理
优点: 可以平滑处理突发流量, 严格限制流量速度
缺点: 容易导致短时间内的高峰流量被拒绝
4. 令牌痛
实现方式: 按照固定速率生成令牌, 每次请求需要拿一个令牌才可以被处理, 如果桶内没有令牌, 则进行拒绝
优点: 相对灵活, 允许在时间范围内处理突发流量, 同时平滑处理长时间的流量
缺点: 实现复杂
</code></pre>
<h2 id="如何避免深度分页"><a href="#如何避免深度分页" class="headerlink" title="如何避免深度分页"></a>如何避免深度分页</h2><pre><code class="hljs">1. 确保排序的列上使用索引
2. 基于游标的分页, where 条件中增加过滤
3. 使用redis 等缓存机制
</code></pre>
<h2 id="限流和熔断的区别"><a href="#限流和熔断的区别" class="headerlink" title="限流和熔断的区别"></a>限流和熔断的区别</h2><pre><code class="hljs">1. 熔断指的当服务端调用出现大量异常时,  组织进一步请求, 避免服务的异常
    工作方式: 当请求成功数低于一定程度的时候, 熔断器 会进入打开状态, 或者是半打开状态, 只允许少量请求进行通过, 请求成功恢复正常
    场景: 下游服务不稳定或者宕机情况下, 防止请求过多对系统进一步压力. 快速失败 
2. 限流指的是控制单位时间内请求的速率, 避免过高的请求
    工作方式: 设置阈值限制每个用户或者是整个系统的请求数量
    场景: 控制用户访问速率, 保护API 接口不会被滥调, 避免过载
</code></pre>
<h2 id="单元化理解"><a href="#单元化理解" class="headerlink" title="单元化理解"></a>单元化理解</h2><p>单元化定义: 一个能完成所有业务操作的自包含集合, 包含了这个业务所需要的所有服务和数据, 每一个单元部署了系统所需要的所有应用, 数据则是按照某种数据维度划分后的一部分<br>核心在于水平模式, 每个机房都有完成全站所有业务的能力<br>数据分区:</p>
<h1 id="面试"><a href="#面试" class="headerlink" title="面试"></a>面试</h1><h2 id="SHEIN"><a href="#SHEIN" class="headerlink" title="SHEIN"></a>SHEIN</h2><pre><code class="hljs">Netty
事件驱动模型:
    基于reactor模式去做的, 通过EventLoop来管理IO 操作事件, 并将这些事件派发给相关的channelHandler, 实现高效的网络通信, 可以处理大量的并发连接
    核心组建:
        eventLoop:
                1.每一个EventLoop 维护着一个 Selector 和 线程
                2.处理 IO 事件和任务
                    监视和处理IO事件, 基于Java NIO 的selector 事件
                3. 任务的调度
                    还可以管理定时任务和普通任务, 可以提交任务到eventLoop上, 按照顺序和指定周期执行
                4. 线程管理
                    一个eventLoop通常和一个线程绑定, 每个eventLoop 可以维护多个channel, 但一个channel 始终绑定在一个eventLoop 上, 确保了同一个channel 上的事件处理是线程安全的
                5. 事件的派发与处理
                    负责从IO操作中获取事件, 将这些事件派发到对应的ChannelHandler中, 每个channel 代表一个连接或者IO操作, 在其pipeline中的一系列处理
        channel:
            负责网络IO操作相关的
            1.1 管理IO 操作
                对数据读取、发送、和连接的管理
            1.2 处理事件
                从网络传输到channelPipeline, 将channelPipeline 处理后的数据返回到网络中去
            1.3 支持异步IO
                即将数据异步写入到网络中,不会阻塞当前线程
        channelPipeline: 是一个处理链, 每个IO 事件都会按照顺序通过channelPipeline, 将多个channelHandler连接起来, 形成一条链, 每个channelHandler只负责处理特定的事件
        channelHandler: 用于处理特定类型事件的处理器, 不同的channelHandler 实现不同的功能, 有的可以用来编解码, 有的可以用来处理连接事件
        Selector: 用于监听多个Channel 上的IO 事件, 当selector 发现某个Channel 上有事件发生的时候, 会通过EvenetLoop 来进行处理
    工作流程:
        boosGroup 和 workerGroup
            bossGroup 负责监听客户端的连接请求事件, 将接收请求并将连接交给workerGroup进行处理
            workerGroup负责处理具体的IO 操作
        事件的监听与触发
            当有IO发生的时候, EventLoop 会从selector 中获取到该事件, 并将其传递给绑定的channel
            事件会按照事件类型依次在channelPipeline 上流过, 通过channelHandler 来具体处理
        channelHandler 处理事件
            入站事件有inbounder 处理, 出站事件由outbounder 处理
            每个channelHandler 可以对事件进行处理, 处理完成后让下一个处理器进行处理
    线程模型
        EventLoop 绑定一个线程, 因此EventLoop管理的 channel 也是在同一个线程上去运行的, 确保每个channel 上的事件处理是安全的, 从而减少了上下文切换的开销		
异步非阻塞体现:
    1. 基于java NIO 的非阻塞IO
        基于NIO 中的selector 和 channel 来实现非阻塞的IO, 意味着每个IO 操作都是非阻塞的
    2. selector 机制
        使用selector 来监听channel 上的IO 事件
    3. 异步操作的提交与处理
        通过future 机制, IO 操作实现异步化
    4. 异步事件的派发
        eventLoop 监听到selector 上的IO 事件后, 异步派发给worker 去进行处理
异步非阻塞和线程安全
    线程安全通过单线程的eventLoop 去处理channel, 避免了多线程下的并发访问, 实现了一个channel 的线程安全
支持零拷贝
    零拷贝指的是全程不需要CPU 进行参与, 所有数据都是通过DMA来进行传输的
    全程只需要2次上下文切换, 2次DMA数据copy
ByteBuf 好处:
    1. 容量可以动态的调整
    2. 支持零拷贝, 减少数据在不同内存区域之间的复制, 
    3. polling 机制 从而进行重复利用
epool pool selector 的区别
    epool原理 采用事件驱动的方式, 
    原理是通过内核维护的事件通知机制，将已注册的文件描述符放入红黑树中管理，并在文件描述符上发生事件时将其加入就绪队列（双向链表），应用程序通过 epoll_wait() 高效地等待并处理这些就绪事件
    poll：需要定时扫描文件描述符, 
    每次调用时传入所有待监控的文件描述符，内核通过线性扫描检查文件描述符状态，返回已准备好进行 I/O 操作的文件描述符，性能随监控的文件描述符数量增加而线性下降
动态代理
    1. 进行接口定义, 创建一个自定义接口
    2. 实现InvocationHandler接口, 类中的invoke 方法参数中有proxy 代理类, method 方法, args 对应的相关参数
        proxy :动态生成的代理类
        method : 与代理类对象调用的方法相对应
        args : 当前 method 方法的参数

    3. 创建代理类
        通过java.lang.reflect.Proxy 类生成一个代理对象	
            Proxy.newProxyInstance(classLoader, interface, invocationHandler)
                loader :类加载器，用于加载代理对象。
                interfaces : 被代理类实现的一些接口；
                h : 实现了 InvocationHandler 接口的对象；
    4. 调用代理方法
        通过newProxyInstance 创建出来的代理类, 去调用方法的时候, 实际上会去调用InvocationHandler 接口类中的invoke 方法, 因此可以再invoke 方法中自定义处理逻辑
字节码增强:
    cglib 通过生成目标类的子类的方法来创建代理对象
            定义一个类；
            自定义 MethodInterceptor 并重写 intercept 方法，intercept 用于拦截增强被代理类的方法，和 JDK 动态代理中的 invoke 方法类似；
            通过 Enhancer 类的 create()创建代理类；
        cglib 不可以代理声明为final 类型的类和方法
    asm 是可以直接修改字节码的
其中spring 默认是使用clglib

高并发
    GC 
异步
    future
promise
Spring 的常见问题
    
HTTP
TCP
    三次握手 四次挥手 各个阶段, 以及每个阶段的问题
动态代理
    jdk cglib asm
ByteBuf
Spring 的IOC 和 AOP
    IOC 指的是控制反转, 将对象的创建和管理委托给spring容器, 而不是直接有应用程序代码直接控制
    AOP 指的是允许不修改代码的情况下, 方便的添加或者修改横切关注点
        AOP 一般通过动态代理来进行实现
            jdk 自身的动态代理: 基于java 的反射来进行实现的
            cglib 
反射
    获取class 对象的方式:
        1. Class alunbarClass = TargetObject.class;
        2. Class alunbarClass1 = Class.forName(&quot;cn.javaguide.TargetObject&quot;);
        3. TargetObject o = new TargetObject();
                Class alunbarClass2 = o.getClass();
        4. ClassLoader.getSystemClassLoader().loadClass(&quot;cn.javaguide.TargetObject&quot;);
    反射的操作
        创建一个我们要使用反射操作的类 TargetObject
        使用反射操作这个类的方法以及参数
            获取方法:	Method[] methods = targetClass.getDeclaredMethods();
            获取方法并调用: Method publicMethod = targetClass.getDeclaredMethod(&quot;publicMethod&quot;,String.class);
            publicMethod.invoke(targetObject, &quot;JavaGuide&quot;);
            获取指定参数:Field field = targetClass.getDeclaredField(&quot;value&quot;);
            对指定参数进行修改
                field.setAccessible(true);
                field.set(targetObject, &quot;JavaGuide&quot;);
问题:
    1. 
    2. 堆外内存的排障
    3. gdb --batch --pid 36563 --ex &#39;call malloc_trim() 进行内存释放
    2. 并发压不上去怎么处理
    3. dubbo
    4. grpc
    5. kafka
    6. redis
    7. HTTP 1.1 2.0 等
    8. jdk 各个版本的差异 为了解决什么问题
    9. spring spring boot 
    各个协议的问题, 并在下一个协议上怎么去解决的
</code></pre>
<h2 id="极兔速递"><a href="#极兔速递" class="headerlink" title="极兔速递"></a>极兔速递</h2><pre><code class="hljs">1. 网关为什么要用netty
2. 线程数怎么去定的 为什么大多数是CPU 核数+1
    2. 每个请求耗时比较高
    3. 
4. pipeline handler 是做什么用的
5. 后端机器上下线
    下游应用存在非RPC 或者是非
6. 鉴权怎么做的?
7. 限流怎么做的
    7.1 为什么要自己去进行限流
8. 为什么使用4C 8G 升级到4C 16G
9. 全链路灰度怎么做的
    全链路定义:
    请求头的识别
        9.1 header、body、param、cookie、流量比例
10. 网关自身怎么灰度
11. 针对异步的请求怎么去做灰度
12. 配置中心怎么去做灰度的, 数据库等的话 需要影子库
13. 自动生成API 文档怎么说的 -&gt; 自动性怎么体现
14. serverless 架构思想怎么体现的
15. 流量怎么监控, 监控的告警阈值怎么配置??????????  告警 限流 等治理?????
16. Agent
17. 个人评估觉得厉害的:
    17.1 
    17.2 
    17.3 MQ 延迟队列、灰度功能

18. spring boot 的扩展点有哪些
19. 什么是动态代理
20. 如果自己去实现动态代理怎么去做
21. MQ 的消息扭转, 生产者 消费者怎么消费
22. 长轮训 怎么理解???
    为什么要用长轮训去做
23. 时间轮 怎么做的
24. 语言表达不清楚
</code></pre>
<h2 id="霸王茶姬"><a href="#霸王茶姬" class="headerlink" title="霸王茶姬"></a>霸王茶姬</h2><pre><code class="hljs">1. 请求的URL 配置
2. 全链路灰度怎么做的
3. 自研网关和spring cloud 或者zuul 
4. 限流的模式是什么
    4.1 和sentional 
5. zk 脑裂问题
6. netty 中的 channel 作用是什么
7. netty 中的 eventLoop 作用
8. 线程数中各个参数的关系是什么
9. mysql 的隔离级别
10. 幻读怎么解决的
11. 缓存和数据库的一致性问题
12. redis 缓存穿透和 击穿
13. synchronized
14. hashMap 中的扩容因子选取
    14.1 为什么是0.75
</code></pre>
<h2 id="神舟"><a href="#神舟" class="headerlink" title="神舟"></a>神舟</h2><pre><code class="hljs">1. 集群化分
2. 和spring Cloud 怎么去对比
3. 后端 IP信息怎么动态感知
4. 日志是怎么记录的
6. spring 注解 和 配置中心加载读取的顺序
</code></pre>
<h2 id="华泰准备"><a href="#华泰准备" class="headerlink" title="华泰准备"></a>华泰准备</h2><pre><code class="hljs">1. 存储数据量很大 变化很大怎么处理
        几百万条数据怎么处理
        1.1 引入metaserver？？？？ 客户端主动向metaserver 去拉去数据, 注册中心只需要维护provider 的ip:port 信息
        负载均衡算法
        协议:
            http2.0 Triple grpc http3.0
        一些常用的配置????
        一些常见的用户问题, 做了哪些功能？？？
    2. 服务端不健康的时候, 怎么主动从注册中心上将自己给剔除掉
    网关在协议转换上会不会常见很多个对象出来
1. dubbo 
    失败重试的策略
        1.1 快速失败策略: 请求失败, 直接把异常跑出去
        1.2 失败安全策略: 
        1.3 失败自动恢复策略: 后台记录失败请求, 通过定时任务对失败请求进行充实
        1.4 并行调用多个服务: 把消息广播给服务提供者集群, 只需要一个返回成功即可
        1.5 广播调用策略: 逐个调用服务提供者的集群, 只要集群中任何一个节点返回异常, 表示本次请求失败
    核心组建:
        服务的提供方
        服务的消费者
        注册中心
    请求的过程
        服务注册:
            服务的提供方在启动的时候将请求接口、方法、版本协议等信息注册到注册中心上
            服务的消费者从注册中心订阅所依赖服务的信息, 注册中心会返回服务提供者地址的列表
        服务发现
            服务发现的过程, 服务的消费者会从注册中心拉取到服务提供者的列表并保存到本地缓存中, 当有新的服务的提供方或者老的服务提供方需要下线的时候, 注册中心会通知消费者, 消费者动态更新服务的提供者列表
        服务准备调用
            proxy 生成: 服务的消费者使用动态代理机制, 生成服务接口的代理对象, 当消费者调用接口方法时, 实际上是调用这个接口对象的方法
            Cluster &amp; LoadBalance
        网络通信准备
            编码和序列化: 代理对象将方法调用, 参数信息封装成一个RPC请求, 通过编解码器对请求进行序列化和反序列化
            Netty 通道管理: 使用Netty 作为底层通信框架, 消费者和提供方之间的通信依赖Netty 去进行传输数据
        发送请求
            consumer: 消费者通过Netty 客户端将序列化后的RPC 请求发送到指定的服务提供方
            provider: 提供方的Netty server 会去接收请求, 并将其传递给指定的服务处理线程池去进行处理
        请求处理
            服务的提供方接收到请求并对接收到的数据进行反序列化, 恢复出原始请求对象
            调用服务: 服务的提供方根据请求对象的服务名、方法名、通过反射的方式执行实际的业务逻辑
            返回结果: 提供方将执行结果返回给响应对象, 并序列化后, 返回给发送方
        接收响应
            consumer: 消费者的Netty 客户端接收到响应后, 并将其反序列化成对象
            结果处理: 将拿到的结果反序列化成对象返回给上层调用者
        服务调用完成
            上层的程序获得结果, 整个RPC 请求结束

2. grpc 和 dubbo 的对比
    grpc 直接基于http2.0 的, 默认使用 protobuf 来进行序列化和反序列化

    dubbo 可以使用 Hessian、Kryo、Java 序列化 等
http 1.1 2.0 quic 协议对比
HTTP 1.X 存在的问题  
    单向请求: 只能单向请求, 不可以服务端主动给客户端发送响应
    协议开销大: header里携带的内容过大，且不能压缩，增加了传输的成本。
    队头阻塞: 下个请求必须要等待前面请求返回后, 才可以发出。导致带宽无法被利用
HTTP2.0 怎么针对上述问题解决的
    多路复用:  通过使用二进制帧来对数据进行传输, 不再是Http 1.x 的纯文本协议, 所有的请求都被分割成了更小的数据帧, 这些帧可以在网络中按照任意顺序发送, 接收方再根据帧的标识符进行重组, 提高了带宽的利用率
    消除对头阻塞: 通过多路复用来允许多个请求和响应再同一个TCP 连接上进行传输, 从而消除了对头阻塞问题
    减少了延迟: 多路复用可以使得数据流并行传输, 每个数据流有唯一的标示, 并且可以是无序的, 降低了延迟
    减少连接开销: 可以共用链接
HTTP2.0的问题
    TCP 层面的队头堵塞问题: 
        TCP的顺序性:  发送方的某个数据包在传输过程中丢失了, 接收段需要等待重传的丢失包才可以处理后续的数据包, 导致了TCP 的队头堵塞
        TCP 传输时某个数据流的数据包丢失了, 会导致后续的数据流堵塞, 因为TCP 需要等待丢失的数据包和重传
    对比Http1.x 的话: 使得TCP的队头堵塞影响整个链接上的请求和响应, HTTP1.x 的话只影响对应链接的请求和响应
可以通过QUIC 和 http3.0 去进行解决
    基于UDP 去实现的
    QUIC 实现了TCP + HTTPS + HTTP/2的功能，目的是保证可靠性的同时降低网络延迟
    安全性: 
        1. 对于首次建立链接的: 需要交换密钥 消耗一次RTT, 再发送业务数据
        2. 对于非首次的, 通过diff-Hellman 来进行密钥交换, 
    链接的唯一性基于64位的connection id
    如何解决队头堵塞问题:
        1. 基于UDP
        2. 数据包级别的确认, 如何确定数据包是否一致 : 通过Stream ID 来标识当前数据流属于哪个资源请求, 同时增加stream offset 确认在数据流中的位置, 两个确定数据包重传

    7. 总结
    Protobuf：适合需要高效、跨语言通信和数据存储的场景，特别是在需要数据结构化的分布式系统和微服务架构中非常有用。
    Kryo：专注于Java生态系统，提供高效的二进制序列化，适用于高性能计算和需要优化网络传输的应用。
    FastJson：适合Web开发，特别是需要与前端进行数据交换的场景，尽管在性能上不如二进制序列化框架，但其易用性和广泛的语言支持使其非常流行。
    Hessian2：用于分布式系统中的跨语言通信，适合需要轻量级二进制传输协议的场景，但在Java内部应用中，Kryo可能会有更好的性能表现。    
4. HTTPS 的过程
    1. 客户端发起请求
    2. 服务器收到请求后, 向客户端发送数字证书(SSL/TLS 证书), 证书包含服务器的公钥和CA 签名的信息
    3. 客户端验证证书
    3.1 客户端检验证书、查看证书的有效期、证书链接、证书的域名是否和服务器匹配       防止中间人攻击
    3.2 如果证书不可信, 客户端会警告用户并提示
    4. 客户端使用生成会话密钥, 信息通过公钥进行加密, 服务器使用私钥进行解密。        确保只有对应私钥的才可以进行揭秘
    5. 客户端和服务端双方拥有会话密钥后, 通过会话密钥进行对数据传输
    6. 数据传输
    7. 
4. zk 和其他注册中心对比 Eureka
    ZK CP Eureka 是AP 
    防止ZK 脑裂
            如何解决ZK 脑裂问题
            1. 确保奇数个节点
            2. 网络分区的监控和恢复
            4. 启用Observer 节点
            5. 事物的日志和快照定期备份
            6. Quorums: 当集群中存活节点少于法定人数的时候, 集群不可用
            7. 冗余通信
5. SPI 
    SPI 的具体原理是这样的：我们将接口的实现类放在配置文件中，我们在程序运行过程中读取配置文件，通过反射加载实现类。这样，我们可以在运行的时候，动态替换接口的实现类
        META-INF/dubbo
6. HTTP RPC 区别
    1. 服务发现上的区别
        HTTP 通过DNS 解析获取背后的地址
        RPC 通过注册中心
    2. 底层连接
        HTTP keep-alive 
        RPC polling 机制
    3. 传输内容
        HTTP 传输内容多 冗余
        RPC 定制化程度高
7. 动态代理
        jdk 动态代理通过Proxy 类生成一个代理对象, 这个代理对象实现了目标类的接口, 并将方法调用委托给InvocationHandler 来进行处理
        1. 接口定义
            1.1 创建一个自定义的接口
        2. 实现InvocationHandler 接口
            2.1 这个类的invoke 方法 会处理所有代理类上的方法调用
                    proxy :动态生成的代理类
                    method : 与代理类对象调用的方法相对应
                    args : 当前 method 方法的参数
        3. 创建代理类
            MyInterface target = new MyInterfaceImpl();

            // 创建InvocationHandler
            MyInvocationHandler handler = new MyInvocationHandler(target);
                	loader :类加载器，用于加载代理对象。
                    interfaces : 被代理类实现的一些接口；
                    h : 实现了 InvocationHandler 接口的对象；
            // 创建代理实例
            MyInterface proxyInstance = (MyInterface) Proxy.newProxyInstance(
                target.getClass().getClassLoader(),
                target.getClass().getInterfaces(),
                handler
            );
        4. 调用代理类的方法
8. 线程数的配置方式
    计算密集型
        一般设置为接近于或等于CPU核心数。
            计算密集型任务主要依赖于CPU执行计算。过多的线程会导致线程上下文切换增加，反而可能降低性能。因此，线程数与核心数保持一致或略多于核心数即可充分利用CPU。
    IO 密集型
        通常是CPU核心数的多倍。
            IO密集型任务通常会有大量时间在等待IO操作完成，如网络或磁盘操作。在等待期间，CPU会空闲，因此可以通过增加线程数来提高并发量，减少CPU空闲时间。
9. jdk 新版本特性
        jdk11. 
            可以开始使用zgc, 
            移除的模块：Java EE 和 CORBA 模块 包的变化
        jdk21: 
            虚拟线程
            线程是映射到操作系统的本地线程去做的, 虚拟线程直接由jvm 去进行管理, 避免了上下文开销的切换
</code></pre>
<h2 id="茄子科技"><a href="#茄子科技" class="headerlink" title="茄子科技"></a>茄子科技</h2><pre><code class="hljs">1. rocketMQ 
    生产消息的过程:
    1. producer 发送消息之前, 先向NameServer 获取消息Topic 的路由信息
    2. NameServer 返回 该 topic 的 路由表和 broker 列表
    3. producer 根据代码指定的queue 选择策略, 从queue 列表中选择一个queue 进行存储
        轮训
        最小投递延迟
    4. producer 向选出queue 所在的broker 发出rpc 请求, 将消息发送到选择出来的queue
    消费者消费消息:
        广播消费: 所有的consumer 实例 都会接受同一个Topic 的全量消息
        集群消费: 每条消息只会发送给其中一个consumer
        consumer 向Nameserver 获取Broker 的地址,
        consumer 链接到Broker 上, 并订阅指定的topic
        broker 根据ConsumerQueue 文件找到消息的偏移量和大小
        broker 根据commitLog 文件读取消息数据
        Broker 将消息数据返回给consumer
    rebalance:
    rocketMQ 怎么保证那么快的
        使用了顺序存储, page cache、异步刷磁盘、 mmap 零拷贝技术
        不是直接写入到磁盘的, 是写入到page cache 中, 随后以异步的方式pdflush 到磁盘上去
        读操作的话也是走page cache 
    如何保证不被重复消费
    kafka 吞吐量高的原因:
        1. 顺序读写磁盘
        2. 零拷贝linux 使用sendFile, 减少一次数据拷贝
        3. 通常消费者批量从Broker 拉取数据
    kafka 和 rocketmq 分别使用场景
        1. kafka: 适用于高吞吐量、大规模数据处理的场景, 日志收集, 流式处理
        2. rocketMQ 适用于消息的顺序性, 一致性有较高要求的应用, 对业务需要精确的控制消息

    如何保证消息可靠性
        可达性保证: 
            生产者: 
                提供了sync 发送消息方式, 等待Broker 返回,
                    支持同步, 线程池回调 
                发送消息的时候失败或者是超时了, 则重新发送
                    默认3次的重试次数
                broker 提供了多master, 当某台broker 宕机了, 保证消息可以投递到另外一台上去
                    利用多主的方式进行重试
            broker 处理
                提供同步的刷盘策略
                当主的broker 磁盘损坏的时候, 可以给broker 指定slave, 同时设置slave 为同步刷盘策略, 设置master 为SYNC_MASTER, 保证消息同时落到master 和 slave
            consumer 消费端
                consmuer 默认提供 at least one 策略: consumer pull 消息到本地后, 消费完成才响应ack
                提供重新消费的能力, 防止消费的时候异常
    如何解决消息堆积的问题
        耗时高原因: 	CPU  内部计算, 外部IO: 读写数据库, 访问redis, 下游RPC 调用
        消息堆积带来影响: 
            存储压力上涨, 延迟增加, 一致处理积压的消息
        怎么解决消息堆积
            1. 梳理消费耗时: 是否计算逻辑过于复杂, 是否存在死循环, 是否可以做异步处理, 
            2. 增加 消费端 的并发度, 增加单个节点消费者的消费线程, 增加消费节点
                消费节点 = 流量峰值 / 单个节点消息吞吐量
redis
    支持的数据结构:
        String、Hash、List、Set、ZSet
    可以持久化保存在磁盘中
    redis 单线程
        接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端 整个过程是单线程的
        单线程为什么那么快:
            1. 大部分操作都是在内存当中操作的, 采用了高效的数据结构,  
            2. I/O 多路复用去处理大量客户端的Socket 请求, 
            使用单线程的原因:
                CPU 不是Redis 性能的瓶颈, 更多的是在内存上和网络I/O的限制, 同时单线程可维护性高, 多线程的话增加系统复杂度, 存在线程切换等问题
        6.0 后用多线程去做
            为什么要在6.0 后用多线程去做: 提升网络I/O, 命令的执行仍然是单线程的
    Redis 如何实现数据不丢失
        1. 读写操作在内存中, 同时有做持久化
        2. 持久化日志: 
            AOF 日志、每一个写的命令, 将对应的命令写入到该文件中
                先执行命令操作, 再记录到AOF 文件日志中
                写回的策略
                always			EverySyc 				No
                同步写回			每秒回写					由操作系统控制
                可靠性高,			性能适中, 				性能好
                但是开销大		宕机丢失一秒数据			宕机丢失的数据多
                
            RDB 日志: 将某一时刻的内存数据, 以二进制的方式写入磁盘
                生成rdb 文件: save(会阻塞主线程) 和 bgsave(后台线程操作)
                使用bgsave 的时候可以继续处理命令
            混合持久化方式
    Redis 如何实现集群的高可用
        1. 主从复制
            主从复制采用读写分离的方式, 写数据的时候写到主节点, 主节点收到写的命令后会更新给从节点,  客户端无须等到从节点都更新完再拿到响应的结果
        2. 哨兵模式
            可以对主从进行监控, 同时进行主从切换
        3. 切片集群
            数据量很大的时候, 可以用redis cluster
        redis cluster 或者主从的时候出现脑裂怎么办
            当主节点发现从节点下线, 或者通信的数量少于阈值时, 那么禁止主节点进行写数据, 直接把错误返回给客户端
            min-slave-to-write x 主节点至少要和 x 个节点进行连接, 如果小于这个数量, 主节点会禁止写数据
            min-slave-to-lag x   主从复制的延迟同步不可以超过 x 秒,  如果超过的话, 会禁止 主节点写数据
            上述的配置可以防止主节点故障的时候进行写数据, 只有新的主库才可以写数据
                        哨兵模式和主从模式
        哨兵负责三个事情: 
            监控: 
                主观下线
                    发送Ping 命令给主节点, 如果主节点在一定时间内没有相应的话, 会被标记为SDOWN, 主观下线,
                客观下线
                    多个哨兵节点通信认为某个节点不可用, 则认为改节点为客观下线, ODOWN
            哨兵节点的选主:
                在主节点被标记为ODOWN 后, 哨兵节点会通过RAFT进行一次投票选举, 确定哪个哨兵节点作为领导者, 负责执行故障转移, 每个哨兵节点可以发起投票,并且每个哨兵节点只能投票给一个哨兵节点
                获得多数票的哨兵节点被选为领导者, 负责后续的主从切换
            选择主节点
                哨兵的leader 从可用的从节点中选主一个新的主节点, 主节点标准:
                    1. 从节点的优先级高的更可能被选中
                    2. 复制偏移量, (代表和主节点是否更接近的,) 更有可能选中
                    3. 链接状态好的
                哨兵的leader 会向其他哨兵节点通知选主的主节点
            主从切换
                选中的从节点会倍提升为主节点, 新的主节点会停止从旧的主节点同步数据, 并且开始接受写入操作
                重新配置集群,  其他从节点开始从新的主节点上去同步数据, 包含和旧的主节点连接的断开. 从新的主节点获取数据
                通知客户端, 客户端根据配置更新配置
            恢复正常运行
    删除策略
        1. 主库通过lazy 的方式进行删除
        2. 主库会发送一个del 事件给从库, 从库收到后对数据进行删除
    内存满了后怎么处理
        1. 进行淘汰
    Redis 缓存设计
        如何避免缓存失效
            1. 不给热点key 设置过期时间
            2. 将缓存失效的事件随机打散, 防止集体失效
        如何避免缓存击穿
            1. 热点key 要过期的时候, 通知后台线程进行更新
        如何避免缓存穿透 数据不存在数据库中, 要不存在redis 中
            1. 对恶意请求进行限制拦截
            2. 设置默认值
            3. 通过布隆过滤器 去设置值是否存在, 不是直接通过数据库进行查询
    更新缓存策略
        1. cache aside: 
            针对读多写少的场景: 先更新数据库, 再去删除缓存
        写多读少的场景
            Write Through 策略
            数据更新的时候, 如果数据库中有数据, 则先更新缓存中的数据,通过缓存组建同步更新到数据库中, 缓存组建告知应用程序更新完成
            如果没有数据的话 则直接进行更新即可
        Write back
            更新数据库的时候, 只更新缓存, 将缓存数据设置为脏数据, 然后立马返回, 数据库的更新 再通过批量更新
    大key 的影响
        1. 客户端阻塞超时
        2. 引发网络阻塞
        3. 内存分布不均匀
        4. 阻塞工作线程
    如果找到大key
        1. redis-cli --bigkeys
        2. scan 找大key

mmap
    mmap 是一种将文件或其他对象映射到进程的虚拟内存空间的机制。通过 mmap，进程可以直接访问文件内容，就像访问内存中的数据一样，而不需要调用传统的 read 或 write 系统调用
零拷贝
    零拷贝是一种优化技术，旨在减少数据在用户态和内核态之间的拷贝次数，从而提高 I/O 性能。传统的文件 I/O 操作需要多次数据拷贝，例如从磁盘到内核缓冲区、从内核缓冲区到用户态缓冲区等。而零拷贝技术通过直接在内核空间中处理数据，避免了这些不必要的拷贝操作
为什么要分代
    1. 大多数对象的存活时间比较短, 少数对象存活时间比较长, 可以减少GC 扫描的范围, 提升GC 的效率
    2. 不同年代的GC 算法采取不一样的, 年轻代 标记复制算法, 老年代, 标记清除 或者是标记整理
问题:
    1. 网关内外网流量怎么区分
    1. 内部服务治理有哪些
        1.1 负载均衡
        1.2 服务路由
        1.3 服务降级
        1.4 服务限流
        1.5 服务监控
    2. 限流机制
        1. 如何进行自我保护
    3. 网关下游处理时长抖动怎么保证网关的可用性
    4. 一次RPC 调用的过程
    请求的过程
        服务注册:
            服务的提供方在启动的时候将请求接口、方法、版本协议等信息注册到注册中心上
            服务的消费者从注册中心订阅所依赖服务的信息, 注册中心会返回服务提供者地址的列表
        服务发现
            服务发现的过程, 服务的消费者会从注册中心拉取到服务提供者的列表并保存到本地缓存中, 当有新的服务的提供方或者老的服务提供方需要下线的时候, 注册中心会通知消费者, 消费者动态更新服务的提供者列表
        服务准备调用
            proxy 生成: 服务的消费者使用动态代理机制, 生成服务接口的代理对象, 当消费者调用接口方法时, 实际上是调用这个接口对象的方法
            Cluster &amp; LoadBalance
        网络通信准备
            编码和序列化: 代理对象将方法调用, 参数信息封装成一个RPC请求, 通过编解码器对请求进行序列化和反序列化
            Netty 通道管理: 使用 Netty 作为底层通信框架, 消费者和提供方之间的通信依赖 Netty 去进行传输数据
        发送请求
            consumer: 消费者通过Netty 客户端将序列化后的RPC 请求发送到指定的服务提供方
            provider: 提供方的Netty server 会去接收请求, 并将其传递给指定的服务处理线程池去进行处理
        请求处理
            服务的提供方接收到请求并对接收到的数据进行反序列化, 恢复出原始请求对象
            调用服务: 服务的提供方根据请求对象的服务名、方法名、通过反射的方式执行实际的业务逻辑
            返回结果: 提供方将执行结果返回给响应对象, 并序列化后, 返回给发送方
        接收响应
            consumer: 消费者的Netty 客户端接收到响应后, 并将其反序列化成对象
            结果处理: 将拿到的结果反序列化成对象返回给上层调用者
        服务调用完成
            上层的程序获得结果, 整个RPC 请求结束

    5. Netty 的一次网络请求过程是什么
        客户端
            初始化:
                EventLoopGroup 的创建, 用于管理和服务之间网络链接和IO 操作, Bootstrap 配置客户端的各种参数, 包括线程模型, NioSocketChannel, 远端服务器的地址, 以及客户端的handler
            建立链接
                连接服务器: 通过Bootstrap.connect() 方法启动连接过程, 链接成功后会将channel 注册到event loop 上
                等待建立连接完成:  connect() 返回一个ChannelFuture, 可以通过sync() 或者是addListener 进行完成
            发送请求
                构造数据进行请求, 连接成功后, 通过channel 向服务器发送数据, 通常是将请求封装成ByteBuf 
                对数据进行writeAndFlush 写数据, 数据会通过ChannelPipeline 的outbounder 进行处理, 通过底层的socket 发送到服务器
            接收响应
                pipeline 处理, 当服务器响应数据到的时候, 数据会到channelHander 的inbounder,
                处理响应数据: 业务逻辑进行处理, 处理完后返回给应用层
            关闭连接
                主动关闭连接: channel.close 关闭连接, 释放资源
                监听关闭操作: close 返回的future 进行监听, 进行监听关闭是否成功。
            资源清理
                group.shutDownGracefully() 进行清理
        服务端
            初始化阶段
                创建EventLoopGroup, bossGroup 和 workerGroup, bossGroup 负责接受请求, workerGroup 负责处理BossGroup 分配过来的IO 操作
                配置serverBootstrap: 使用ServerBootstrap 来配置Netty 服务, 包括channel 的类型, 指定EventLoopGroup, 配置channelPipeline, 以及设置服务器的监听端口
            绑定端口
                serverBootStrap.bind() 方法绑定服务器的监听端口, 会启动一个异步操作过程, bossGroup 中的线程会监听这个连接请求
                bind() 返回一个future, 可以通过sync()  或者是addListener 来等待响应
            接受客户端请求
                bossGroup 中的线程会去监听端口的连接请求, 当有新的请求进来的时候, Netty会为这个连接创建一个channel, 并将其分配给worker 的EventLoop上,
                注册channel: 新的channel 会被注册在worker Group 中的eventLoop 上, 接下来和这个连接的相关读写操作都是在这个EventLoop 上
            处理客户端请求
                每个channel 关联的channelpipeline, 包含了一系列的handler
                当客户数据到达的时候, 数据会通过channelPipeline 中的inbounder 来进行处理, 负责数据的读取, 解码，业务逻辑处理等
            响应客户端
                当业务逻辑处理完后, 通过会通过ChannelHandlerContext.writeAndFlush() 将数据响应回给客户端
                数据会通过channelpipeline 中的outbounder，然后通过底层的socket 发送给客户端
            关闭连接
                客户端关闭连接, 或者是服务端主动关闭连接的时候, Netty 会处发ChannelInbounderHandler 的channelInactive 或者是channelUnregistered, 可以进行资源清理
                在关闭服务器的时候, 需要调用bossGroup 和worker Group 的shutdownGracefully 进行线程资源的释放
    6. TCP 流式处理怎么对流量进行拆分
    7. Redis 的高可用怎么保证的, 
        哨兵模式和主从模式
        哨兵负责三个事情: 
            监控: 
                主观下线
                    发送Ping 命令给主节点, 如果主节点在一定时间内没有相应的话, 会被标记为SDOWN, 主观下线,
                客观下线
                    多个哨兵节点通信认为某个节点不可用, 则认为改节点为客观下线, ODOWN
            哨兵节点的选主:
                在主节点被标记为ODOWN 后, 哨兵节点会通过RAFT进行一次投票选举, 确定哪个哨兵节点作为领导者, 负责执行故障转移, 每个哨兵节点可以发起投票,并且每个哨兵节点只能投票给一个哨兵节点
                获得多数票的哨兵节点被选为领导者, 负责后续的主从切换
            选择主节点
                哨兵的leader 从可用的从节点中选主一个新的主节点, 主节点标准:
                    1. 从节点的优先级高的更可能被选中
                    2. 复制偏移量, (代表和主节点是否更接近的,) 更有可能选中
                    3. 链接状态好的
                哨兵的leader 会向其他哨兵节点通知选主的主节点
            主从切换
                选中的从节点会倍提升为主节点, 新的主节点会停止从旧的主节点同步数据, 并且开始接受写入操作
                重新配置集群,  其他从节点开始从新的主节点上去同步数据, 包含和旧的主节点连接的断开. 从新的主节点获取数据
                通知客户端, 客户端根据配置更新配置
            恢复正常运行
    8. 问题:
        底层技术不是太差? 广度上不够, 需要对各个原理有了解
</code></pre>
<!-- ### 注册中心
#### eureka
##### eureka 如果实现数据同步
    1. 多节点部署与复制
        eureka 集群中的各个节点会相互的同步注册信息和服务信息
    2. 服务注册和同步的流程
        1. 服务注册过程: 微服务向eureka 节点发送注册请求
        2. 增量同步
            1. 服务注册的时候, 当一个服务实例向其中一个eureka 节点进行注册, 对应的eureka 节点会将该实例信息同步给其他的eureka 节点
            2. 服务续约. 服务节点定时给eureka 进行心跳请求续约, 每次续约都会触发增量同步
            3. 服务下线. 
            4. 服务状态变更
            2.1 实现方式:
                通过增量队列来实现的, 当有节点注册、续约、下线、状态变化的时候, 会放到增量队列中,eureka 会定时从增量队列中获取数据, 将需要同步的数据发送给其他节点, 其中防止很长时间都没有被同步, 增量队列中需要携带上时间戳, 可以用来进行触发全量同步
            自我保护机制, 设置成一个阈值可以判断时因为节点异常了,
            具体case
                服务实例向节点 A 注册，A 将该变更添加到自己的增量队列中。
                节点 A 定期检查增量队列，发现有新注册的服务实例。
                节点 A 通过增量同步的 API /eureka/v2/apps/delta，将该变更同步给节点 B。
                节点 B 接收到增量信息后，更新其本地的注册表，保持与节点 A 的数据一致性。
        3. 全量同步
            3.1 节点重启: 当有一个节点重启了
            3.2 增量同步失败: 由于增量同步出现异常, 节点之间注册信息不一致, 触发全量同步. 增量同步失败的原因可能因为网络故障、超时、抖动等
            3.3 数据检测不一致: 节点会去定时检测其他节点信息和注册表中的数据是否一致, 发现有不一致的, 并且增量失败
            3.4 全量同步过程:
                3.4.1 节点向其他节点发送全量同步请求
                3.4.2 接受其他节点的全量注册信息, 
                3.4.3 将全量节点更新到本地
                3.4.4 恢复正常
        4. 新的节点起来以后怎么做的数据同步
            全量同步
        5. 如何通知给服务的消费方
            5.1 客户端通过定时拉的方式获取,初次时进行全量拉取, 后面是进行增量拉取
            5.2 拉增量失败后, 会触发拉取全量的
            5.3 当服务器进入到自我保护机制时, 拉取到的数据可能是旧的
##### 如何解决eureka	问题: 当客户端很多的时候怎么处理, hash 环 + 虚拟节点
            如何做到注册方的上下线, 秒级别推送:
                基于WS 或者是长轮训
                    WS:
                        1. 服务消费方在初始化过程中，会先经Session域名查询Session的IP地址列表并缓存到本地，然后再从列表中选择一台Session服务器与之建立 WebSocket长连接，并发送服务订阅请求。
                        2. Session在收到服务订阅请求后，先会将服务订阅信息和 WebSocket 连接的映射关系存储到本地。后续当Session收到Data推送的服务变更消息时，它会先从上述映射关系中查询该服务对应的变更订阅方（即对应的WebSocket 连接列表），然后将消息通过这些连接推送出去。
                        3. 在收到服务变更消息后，服务消费方会根据消息的内容更新本地缓存中的服务地址列表
                上下线的时候, data 节点通知所有的session 节点
#### zk
##### zk 选举
    1. 节点分类
        leader: 主节点，负责处理写请求，并将事务日志同步到从节点
        flower: 从节点，接收 Leader 的同步数据，并参与读请求。
        observer: 观察者节点，不参与选举和投票，但接收 Leader 的同步数据。
    2. 选举算法
        Fast Leader Election 参考的点: zxid, myId, 当前数据的完整度和 机器的优先级
##### zk 写数据的过程
    1. 客户端发起写的操作, 这个操作只能到leader 节点上去
    2. leader 收到写请求后, 会生成一个zxId, 通知zxId 是递增的
    3. leader 会将zxId 封装成一个propersal 进行广播, 基于zab 协议,确保所有flower 接收到
    4. flower 接受propersal 并进行ACK 响应
    5. leader 接受ACK, 过半就可以持久化写入
    6. leader 进行commit, 并通知所有的flower
    7. flower 收到leader 的commit 后并对自己进行刷新
    8. leader 确认写完成后并通知客户端
    通过写请求只能leader 处理、zxId 是递增的、zab 协议来实现一致性
    P 的话通过法定人数, 过半节点
##### 如何解决脑裂问题
    1. 确保奇数个节点
    2. 网络分区的监控和恢复
    4. 启用Observer 节点
    5. 事物的日志和快照定期备份
    6. Quorums: 当集群中存活节点少于法定人数的时候, 集群不可用
    7. 冗余通信 -->
<!-- ### Consul
    1. 通过WAN Gossip 协议 解决多数据中心的问题
    WAN Gossip 协议: 通过随机选择节点进行数据交换, 但是传播速度比较慢, 节点可能会有重复的数据通信,
### 注册中心发布怎么解决
    一是关闭/启动应用程序前，先拉出服务实例，程序启动成功后，再拉入服务实例；二是客户端负载均衡自动拉出访问异常服务实例。
 -->

<h2 id="美团"><a href="#美团" class="headerlink" title="美团"></a>美团</h2><pre><code class="hljs">1. mysql
    char 和 varchar的区别
        char: 固定长度的字符类型, 定义时需要指定字符长度, 不够的时候会在末尾补足空格, 适合存储固定长度的
        varchar:  可变长度的字符串类型, 存储时需要指定最大长度,存储的时候根据实际长度占用存储空间
    in 和 exist 的区别
        in 表示左边表达式是否存在于右边, 返回true or false
        exist 可以返回一行数据
        性能上的差异:
            exists 的性能要比in 好, 尤其是在表比较大的情况下, 因为exist 找到一条后就立刻返回停止查询, in 需要遍历整个子查询
        使用场景:
            查询子集合较小并且变动属于低频的, in 更加直观,  当子查询涉及到外部查询的每一行判断的时候,  并且子查询效率较高, exist 更为合适
        null 值的处理:
            in 可以正确处理子查询中包含null 的情况, 而exist 不受子查询结果中null  值的影响
    执行一条sql 请求的过程
        1. 客户端发送请求
            客户端通过网络连接向数据库发送一条sql 语句, 
        2. 连接管理
            连接处理: 数据库服务器收到客户端的请求后, 检查是否有可用的连接池, 如果有的话 则用现有的处理连接, 没有的话创建一个新的连接
            权限验证: 服务器会去验证客户端的身份, 检查客户端是否有执行这条sql 命令的权限, 如果校验失败, 则返回错误
        3. SQL 解析
            词法分析
            语法分析
            语义检查
        4. 查询优化
            生成查询计划: 数据库会根据语法树生成多个可能的查询计划, 查询计划是SQL 执行的方案, 描述了如何访问和处理
            选择最优计划: 数据库会根据执行的代价选择一个最优的方案, 代价评估包含有IO成本, CPU 资源消耗 内存使用等
        5. 查询计划
            执行计划: 根据选定的查询计划, 逐步执行sql 语句
            中间结果处理: 执行过程中, 可能会有一些中间结果, 中间结果会在最终结果生成前被处理
        6. 返回结果
            结果集生成: 将最终的结果集返回给客户端, 可能是查询的结果, 可能是更新的影响数等等
            资源释放: 清理执行过程中使用的临时资源, 并对资源进行释放
        7. 事物处理
            如果SQL 是在事物中执行的, 数据库还需要执行事物的提交或回滚
        8. 日志记录
    存储引擎为什么默认选择innodb
        1. 支持事物
        2. innodb 是聚集索引, MyISAM 是非聚集索引
        3. 锁力度: innodb 最小是行锁，myIsam 是表锁
    索引
        适合当主键的字段
            1. 唯一性, 且不为空
            2. 递增的
                原因: 
                    1. 避免页分裂
                        1.1 尽可能的顺序写, 无需在中间插入数据
                        1.2 避免页分裂: 如果是随机的话, 新数据可能要在中间插入, 导致数据库对现有数据进行分割
                     	1.3 插入效率高
                    2. 缓存命中率比较高
                        2.1 减少缓存压力, 新的数据可以顺序写入和读取, 减少缓存中不断去进行对老数据替换
                        2.2 数据和索引的缓存优化: 如果主键是递增的, 最新的数据往往是在相邻页上, 这些页面可能已经被加载到了缓存中, 从而提高缓存命中率
                    3. 索引维护简单
                        3.1 顺序更新, 减少维护索引结构的复杂性
                        3.2 避免索引碎片: 随机主键会导致叶子结点不断被打乱, 产生大量的碎片, 需要频繁的进行索引重组. 顺序可以保证索引结构的稳定性增长
                    4. 空间利用率高
                        4.1 有助于更好的利用磁盘空间
                        4.2 减少数据碎片

            3. 不建议用业务字段, 无法预测未来是否重复
            4. 大多数情况下用唯一自增id

        聚集索引 和 非聚集索引区别:
            1. 数据存储上
                聚集索引和数据是存放在一起的, 聚集索引的叶子结点就是实际的数据行, 非聚集索引的叶子结点不包含完整的数据行, 而是包含指向完整数据行的指针或者是主键值, 数据行本身存储在聚集索引中
            2. 索引和数据关系上
                直接通过聚集索引可以找到数据行, 不需要额外的步骤去进行查找, 非聚集索引查找数据的时候, 现在非聚集索引中找到对应的主键值, 再通过主键值回溯到聚集索引上去找对应的数据行
            3. 唯一性上
                聚集索引是基于主键构建的, 每个表只能有一个主键, 一个表可以有多个非聚集索引
            4. 效率
                对于范围查询和排序查询, 聚集索引的查询效率更高, 因为避免了额外的寻址查询
                非聚集索引在使用覆盖索引进行查询的时候效率更高, 无需进行回表操作
            5. 使用场景
                聚集索引适合频繁的范围查询, 顺序插入, 大量返回完整行数据的
                非聚集索引适合更加频繁的多列查询, 覆盖索引查询
        B+ 树的叶子结点是双向链表
        联合索引的条件
            将区分度大的字段放在前面
        需要回表的：
            如果要查询的数据不再二级索引中, 就会先检查二级索引,  找到对应的叶子结点, 获取到主键的值, 再去主键索引查找
        覆盖索引
            一个索引列包含了查询的所有列, 不需要回表就可以完成查询
        查询的时候会尽量用联合索引
        索引的缺点
            1. 占用物理空间
            2. 创建和维护需要耗时, 随着数据量的变大而变大
            3. 降低表增删改的效率, 每次增删改, 需要动态更新索引
        需要用索引:
            1. 字段有唯一性限制
            2， 经常用于where 条件的
            3. 经常用于group by 或者是order by 的
        不适合的
            1. where group by order by 中用不到的字段
            2. 大量重复的字读
            3. 数据表很少的情况下
            4. 经常更新的字段
        防止索引失效
            1. like %xx 的 或者是like %xx% 的
            2. 索引列进行计算的
            3. 遵循最左匹配原则
            4. where 条件中 or 前后不是索引列的
            5. 联合索引遇到范围查询后, 范围查询后面就会停止精确匹配
        mysql 如何解决并发问题的
            1. 锁机制, 行级锁、表锁、页锁等
            2. 事物隔离级别
            3. MVCC
        隔离级别如何实现
            读已提交: 事物中只能读取到其他已提交的数据
                通过在语句语句执行之前生成一个read view, 因此可以保证每次读取的时候可以读取到其他事物提交后的数据
            可重复读 是通过在启动事物时生成一个read view, 整个事物期间都在用这个read view, 因此没办法防止幻读, 因为整个事物期间基于的视图时一样的

        MVCC: 多版本并发控制协议
            通过维护数据的多个版本, 允许事物在不加锁的条件下并发的读取数据,  从而提高系统的并发性和数据的一致性
            innodb 在每行的数据库上额外记录两个隐藏字段:
                创建版本号: 标识插入或者更新这行数据事物的id
                删除版本号: 标识删除这行数据事物的id，实际指向undo log的指针, 用于回滚或者读取旧版本
            工作过程:	
                1. 插入操作:
                    插入新行的时候, innodb会为这行记录事物ID 并创建版本号, 删除版本号为空
                2. 更新操作
                    更新数据的时候, 会在当前数据上创建新的版本, 更新创建版本号, 同时保留旧的版本号用于并发事物读取
                3. 删除操作
                    删除数据的时候, 不会立马去进行物理删除, 而是将删除记录在undo log 中, 同时给该行数据的删除版本号写入当前事物id
                4. 读取操作
                    根据当前的事物隔离级别, 会通过事物的id 和 版本号来判定是否可以看到特定的数据版本
            read view:
                是MVCC 中的一个概念, 表明特定时间点当前事物可以看到哪些数据
                一致性试图: 当事物开始读取数据的时候,  该视图定义了可以看到的数据版本, 
                事物的范围: 当前系统中未提交的最早事物的id, 当前系统中最新的事物id, 当前还未提交的事物id
            优点: 
                高并发: 读操作不需要加锁, 避免了读写之间的冲突, 提升系统的能力
                数据一致性: 保证数据的一致性的同时, 提供了更高的查询能力
                避免思索: 读操作不需要加锁, 减少了死锁的发生
            缺点:
                额外的存储空间: 由于需要维护多个版本的数据, MVCC 会占用额外的存储空间
                版本链的管理: 随着数据的更新, 版本链可能变长
                复杂的实现
        mysql 中的锁:
            全局锁
                flush tables with read lock: 会将整个库设置为只读状态
            表锁

            行锁
                例如在select for update 的时候 或者update 的时候会用到拍他锁
                innodb 支持行锁
                记录锁
                    S锁: 共享锁
                        允许多个事物读取同一条数据,但是禁止对改数据进行修改
                        当一个事物持有S锁, 其他事物也可以获取S锁, 但是其他事物允许获得X锁, 不可以对数据进行修改
                        适用于select 查询的场景
                    X锁: 排他锁
                        确保同一个事物对数据的独占, 既可以读取数据, 也可以修改数据, 拍他锁禁止其他事物同时修改数据
                        当一个事物持有X锁的时候, 其他事物不允许获取X锁, 也不可以获取X锁, 只有持有X锁的事物才可以对数据进行读取和更改, 保证事物的独占
                        适用于更新的场景
                gap 锁
                    防止幻读
                    BEGIN;
                    SELECT * FROM orders WHERE order_date &gt;= &#39;2023-01-01&#39; AND order_date &lt; &#39;2023-02-01&#39; FOR UPDATE;
                    -- 对指定日期范围内的间隙加锁，防止其他事务插入新的订单记录
                    COMMIT;
                next-key-lock

        一条update 是不是原子性的 
            是的, 通过undolog 来实现的
        大事物带来的问题
            1. 一个事物特别多的sql, 锁定的数据会特别多, 
            2. 回滚的时候会占用大量的空间
            3. 执行时间长 会导致主从延迟
        日志的分类:
            redo log: 实现了事物的持久性, 用于掉电等故障
            undo log: 实现了事物的原子性, 用于事物的回滚和MVCC
            bin log: server 生成的日志, 用于数据备份和主从复制
            relay log
        binlog: 记录了数据库表结构变更, 表数据修改的日志
            格式有STATEMENT(每一条修改数据的SQL 都会记录到日志中) 、row(记录每条数据的最终数据)、 MIXED
            主要用于主从复制的一致性, 可以精准的重新主库中所有数据的变更
        undoLog: 用于撤销回退的日志, 保证了ACID中的原子性
            在事物没有提交之前, 会将之前的日志记录到undoLog 中, 可以用来回滚
            1. 没有事物引用、事物已经提交、数据库中没有长时间运行的事物的情况下可以删除
        redoLog: 保证数据的持久化
            1. redoLog 中记录事物完成后的数据, 记录的是更新后的值
            2. 可以确保在崩溃后, 通过redolog 可以将数据恢复到一致性状态
            3. 性能优化, redolog 允许mysql数据页的修改 可以异步的刷新到磁盘中去, 不必每次去写, 提高写性能
        能不能只有binlog 没有redoLog
            不能, binlog 是server 层的日志, 没办法记录哪些脏页还没有刷盘, redoLog 是引擎层的日志, 可以记录哪些数据没有刷盘, 崩溃恢复的时候可以通过它来进行恢复数据
        binlog redolog  undolog 关系
            binlog 是逻辑层面sql 的修改, 主要用于主从复制和数据恢复
            redolog 是物理层面数据页更改, 保证事物的持久性和恢复
            undolog 是数据的旧版本, 用于事物回滚和MVCC
        WAL 技术: write ahead of log 先写日志, 再在合适的时间点将数据刷新到磁盘上去
        事物提交的过程起的作用:
            undolog 记录旧版本数据, redolog 记录新数据, 事物提交时, redo log会先标记事物为prepare状态, 再写入binlog, 最后将事物标记为commit 再进行提交
        恢复的时候:
            redolog 来完成所有已提交事物的操作, 使用undolog 来进行事物的回滚, binlog 用于主从复制或者是后续重演事物
        binlog 的两阶段提交
            目的: 
                保持binlog 和 redo log 的一致性: 确保数据库崩溃后, 保证事物提交的原子性和一致性
                防止数据丢失: 如果事物已经提交到了redo log，但是没有写入到binlog 中, 在系统奔溃后恢复, 由于binlog 没有该事物的记录, 从而影响主从复制
                防止数据不一致: 如果事物已经写入到binlog 但是没有写入到redolog， 奔溃后恢复的时候会导致binlog 中有记录, 但是实际数据库没有应用, 导致数据不一致
            过程
                1. prepare 阶段
                    事物执行, innondb 会将事物的更改记录写入到redo log 中, 并将这些日志标记为 prepare 状态, 这意味着这些事物已经在操作了, 但是还未提交, 数据的修改刷新了内存中, 但是还没有刷新到磁盘
                2. commit 阶段
                    写入binlog， 在事物提交之前, 将事物的更改写入到binlog 中, 此时binlog 记录的是最终持久化的数据, 此时redolog 中数据还是处于prepare 状态
                    提交事物, 将redolog 中的事物标记为commit 状态, 一旦事物标记为commit, 数据页的修改会被刷新到磁盘上
            关键:
                顺序性和原子性:
                    先记录redolog 的prepare 状态, 再写入binlog, 最后提交redo log， 防止奔溃恢复时出现数据的不一致
                奔溃恢复
                    如果在写入binlog 后, 但是在提交redolog 之前的 发生了奔溃, mysql 在恢复时根据redolog 的prepare状态 和binlog 的记录继续完成提交, 确保事物的一致性
            update 的具体过程
                服务端处理的过程, 假设校验这些都过了
                1. 调用执行引擎查找对应的记录, 如果数据本来就是在buffer pool 中, 则直接返回, 没有的话从磁盘中读取到buffer pool。再返回
                2. 执行器查看更新后的数据是否和前面的是一样的，一样的话不做任何处理, 不一样的话，将更新前后的值传递给innodb 进行处理
                3. 开启事物, 先将记录记录到undo log 中, 将更新的旧数据记录到undo log中
                4. innodb 开始更新记录, 先更新内存, 同时标记为脏页, 将记录写入redolog 中, 为了减少磁盘的IO, 由后台线程将脏页数据写入到磁盘中
                5. 更新完成后, 记录该语句对应的binlog, 此时binlog 会保存到binlog cache 中, 在事物提交的时候统一将所有binlog刷新的磁盘上
                6. 事物提交
                    prepare 阶段 redolog 设置事物状态为prepare, 将redolog 刷盘
                    commit 阶段 binlog刷盘, 将redolog设置为commit
        主从复制
            主从复制: 
                1. 写入binlog
                2. 同步binlog
                3. 回放binlog
            主库在收到客户端的提交事物请求后, 先将数据写入到binlog 中,更新存储引擎中的数据, 再返回给客户端
            从库会起一个专门的IO 线程, 连接主库的log dump 线程, 接收主库的binlog日志, 再将binlog 信息relay log 到从库的中继日志
            从库创建一个专门回放binlog的线程, 去读relay log 中日志, 回放binlog 更新存储引擎中数据
            保证写数据的时候只写主库, 读的时候从从库读取
        主从延迟怎么处理
            强制从主库上读取
        分库分表
            分库: 将数据按照一定的规则划分到多个库中, 每个库只负责部分数据的存储, 为了解决单台mysql 扛不住的问题
            分表: 将数据分摊到不同的表上, 为了解决单个表太大的问题
            垂直分库: 按照业务功能
            水平分库: 同一个表按照一定的规则拆分
        MHA 如何实现主从切换
            MHA manager 会对主库的状态进行检测, 发送探测请求,ping 命令, 同时监控mysql 的错误日志和系统日志, 用来捕捉异常信息, 根据设定的阈值来判别主库是否发生了异常,
            重新选主的策略
                1. 复制延迟小, 选择延迟最小的从库, 减少数据不一致的风险
                2. 数据一致性 优先选择最具完整事物日志的从库
                3. 可用性: 当前运行良好的从库
            提升主库
                停止新主库的slave 进程, 使得不再继续同步, 重新命名realy log, 确保从库变为主库
                修改每个从库的change master to 命令, 让他指向到新的主库
                启动从库的slave 进程, 开始从新的主库上同步数据
            MHA 自身的高可用
                1. 部署多个MHA 实例, 确保一个MHA 实例出了问题, 另一个可以继续工作
                2. MHA 通过VIP 的方式去处理, 对于客户端来说无需感知
                3. 心跳机制和自动切换: 定时心跳检测主的MHA Manager 的状态. 
                4. 防止 MHA 节点脑裂: 使用仲裁机制, 类似于ZK, 优先级和选举机制,
        write-set
            每次提交的时候, 相当于对事物的写操作生成了一个集合
        WriteSet
            WriteSet 是一个集合, 包含了某个事物修改的所有操作的元数据,  可以用来冲突检测(将提交事物的writeset 和 其他节点中未提交的进行比较, 检测是否有冲突), 全局一致性

        MGR
            使用Paxos 一致性协议, 支持多主的模式, 集群内所有结点通过一致性写作, 决定事物的提交顺序, 检测到节点故障的时候, 自动从剩余的节点中选举出新的主节点(如果是单主的情况下)
            如何解决数据的冲突
                1. 基于组内通信的全局事物一致性
                    基于paxos 实现事物的全局一致性, 一个节点发起事物投票后, 事物会被广播到组内, 确保所有结点对该事物达成一致
                2. 冲突与检测处理
                    基于writeSet 的冲突检测机制: 每个事物提交的时候, MGR 会生成一个write-set, 记录了该事物中所有的修改, 相当于对该事物的写操作生成了一个集合
                    冲突检测: 当一个节点尝试提交事物的时候, 会将该事物的write-set 与组内其他节点已提交但未应用的事物write-set 进行比较, 判断是否有冲突发生
                3. 检测到冲突
                    丢弃冲突的事物: 根据事物的先后顺序, 来决定保留哪个事物, 通常是保留先提交的事物
                4. 冲突处理后的应用
                    处理完冲突后, MGR会将所有成功提交的事物 应用到每个节点上去. 确保所有结点数据的一致性
                5. 用户对冲突自行处理
                    1. 默认将数据写到某个节点上去, 按照节点的轮训, 避免冲突
    DTS:
        1. 怎么保证网络可用
        2. 高效同步???
        3. HA
        1. 语法转换和解析
        2. 迁移过程的一个高可用
            2.1 日志读取高可用
            2.2 日志回放高可用
            2.3 数据拉取的时候怎么控制速率和大小
        3. 源数据所在集群发生了变化怎么处理
        4. 全量迁移的时候需要同时进行增量
        5. 顺序ABA 问题


        零拷贝 
            1. 零拷贝指的是在IO时减少或者消除数据内存拷贝的次数以及CPU的参与, 使得数据在IO的时候可以更加高效
            主要实现手段:
            1. sendfile() 系统调用: 是linux 提供的一种系统调用, 可以直接将数据从文件描述符传输到网络套接字上, 不需要将数据复制到用户空间, 内核直接通过mmap 和 DMA 进行数据传输
            2. mmap 系统调用: 可以将文件映射到进程的地址空间, 这样进程可以直接在自己的地址空间访问文件内容, 不需要显示的读写
            3. DMA 技术, 通过DMA 允许设备直接访问内存, 无需经过CPU, 通过DMA,
            优点:
                1. 减少CPU的开销, 避免了不必要的内存拷贝
                2. 提高数据传输效率. 减少了数据的传输效率
                3. 减少上下文的切换. 减少用户态和内核态的上下文切换
        page cache
            是磁盘上的数据缓存到内存中的操作, 加速读写
            读操作:
                如果读取的时候数据已经在page cache 中, 则说明命中了直接返回, 避免了磁盘的IO
                如果读取的时候数据没有在page cache 中, 则从磁盘中获取并缓存到page cache中
            写操作
                预先将数据写入到page cache 中, 操作系统会在后台将page cache 数据写入到磁盘上去
            优点:
                提高读取速度: 加速磁盘的读取, 降低磁盘IO
                减少写入次数: 集中写的机制
                提高内存利用率: 操作系统会动态调整大小
            缺点:
                内存占用
                写入延迟

        netty 高低水位怎么控制发送速率, netty 怎么进行流量限流
            通过检测给外部发送的缓冲区数据是否超过了高低水位, 从而控制TCP的发送速率
            config.setWriteBufferHighWaterMark(64 * 1024); // 64KB 高水位线
            config.setWriteBufferLowWaterMark(32 * 1024);  // 32KB 低水位线
        java agent 机制

        ringBuffer
            是一种固定的环形缓冲区, 
            优点: 
                固定长度
                循环利用
                低延迟
                由于是固定内存的 因此减少GC压力


        id 生成器, 雪花算法,twitter 那个
            雪花算法的64位组成如下
            符号(1)_时间戳(41)_数据中心(5)_机器id(5)_序列号(12)

        磁盘 堆外读取

        mysql 中 Event 怎么理解????

        heartbeat_event 怎么理解???

        通过WRITE_BUFFER_WATER_MARK 控制发送速率


        数据一致性保证
        1. 时序保证: replicator 消费时顺序发送给applier
        2. At Least Once
            2.1 一边重启怎么处理
                replicator 重启的话 通过读取本地的gtid set
                applicator 重启的话 通过目标数据库当前执行过的gtid set 进行对比
            2.2 解决循环复制的问题
                set gtid_next 将该事物的gtid 设置为同步过来的gtid_event 中的GTID
                set gtid_next=GTID
        3. DDL 	

        netty
        java agent proxy-client


        ringbuffer

        DDL 怎么处理
        回环怎么处理
        大数据怎么处理??
        分布式id 生成器 算法
</code></pre>
<h3 id="一面问题"><a href="#一面问题" class="headerlink" title="一面问题"></a>一面问题</h3><pre><code class="hljs">1. qconfig 服务端 CAP 怎么选择, 为什么这样去选
2. qconfig 元数据是否放在ZK 中
3. 单元化的理解
3.1 单元化如何实现的, 就是从整个公司的角度, 以及从配置中心角度=====
3.2 单元化的时候数据怎么落到正确的存储上去
    3.2.1 单元化的目的:
4. 数据批量变换和数据预热怎么处理, 为什么要这样去做
5. 批量变更在什么情况下有问题
    5.1 批量变更不是delay 去做, 是从请求方开始就聚集去做处理
6. jmap 查看堆上的内存, 查看内存占用的过程是什么样的
7. pmap 查看堆外内存的场景,为什么会怀疑和malloc 分配内存有关联
    7.1. ptmalloc 申请内存 和 jemlloc 为什么 ptmalloc
    7.2 	ptmalloc 中用户释放掉的内存, 为了下次快速使用, 会存到自己的空闲列表中, 因此导致了很多的64M 内存占用的问题
8. 线程资源占用 应该调整哪个参数 或者jvm 应该怎么调整					=======
    1. 需要调整线程栈的大小 和 堆上的大小
9. 稳定性有什么总结性的
    9.1 幂等服务
    =======
    事物管理
    限流熔断
    重试机制
10. 网关 为什么要从tomcat 换成netty
11. 为什么netty 可以用更少的线程来做同样的事情
12. netty 怎么去管理堆外内存
    12.1 mmap + bytebuf
    12.1 每个bytebuf 有个引用计数器, 当bytebuf 被使用的时候, 计数器+1, 不再需要使用的时候, 计数器-1, 当byteBuf关联的计数器降为0的时候。
    通过PooledByteBufAllocator 和 ByteBuf 来实现的, 在需要使用堆外内存的时候, 分配一个新chunk 或者直接向操作系统申请一个, 然后通过ByteBuf 的API 对堆外内存去进行读写. 内存释放的时候通过引用计数机制的减少
ResourceLeakDetector 可以用来检测
-XX:MaxDirectMemorySize=1G 限制堆外内存的使用
13. 网关上降本增效 怎么去做这个事情
14. 读已提交 和 可重复读 怎么保证的
15. mvcc 是利用什么机制实现的
16. undo log 在什么时候会去删除掉
17. undo log 在多版本比较的时候会在什么时候可以删除 ===============
    17.1 当所有以来undo log 的事物都不再使用的时候就可以删除了
18. 内存写了, 磁盘还没有落的时候, crash 了.  怎么去保证
19. synchronized 的锁升级的过程
20. cas 会有什么问题
</code></pre>
<h3 id="二面"><a href="#二面" class="headerlink" title="二面"></a>二面</h3><pre><code class="hljs">1. 项目哪个印象更深刻一点
2. 详细介绍一下配置中心做了哪些事情
3. 配置读取的单元化
    3.1 配置读取的就近读、就近写的单元化, 配置中心底层的数据读取怎么做到单元化
    3.2 配置中心数据放在MGR数据库上, MGR集群
4. 网关tomcat 换成netty 为什么要去做这个事情
5. 对重要应用的隔离是怎么去做的
    5.1 重要应用的定义怎么定义
    5.1 重要性怎么收集
6. 网关集群流量配置的灰度, 配置的灰度怎么去做的
7. 网关流量权重怎么设计的
8. 网关灰度的机器和普通机器怎么做, 其他人是怎么做的 业界方案怎么做的
9. 单台机器QPS 从多少提升到10000
    9.1 原来值是多少 2000
    9.2 做了哪些改造有那么高提升
10. 网关服务的容灾 和 高可用
11. 网关的水平扩、缩容怎么做的
12. 基于k8s 的自动扩缩容, 提供给业务同学用, 和网关之间的关联性
    12.1 进行扩缩绒的标准是什么
    12.2 自动扩缩容的机制是怎么实现的
    12.3 采集流量的QPS 信息
    12.4 如何确定好下游的节点是够的???
    12.5 弹性伸缩为什么要放在网关侧去做
13. 网关项目的参与人
    13.1 为啥人那么少
14. 项目的迭代周期是什么
    14.1 网关项目的重点是什么
15. 网关转发的同样的请求, 转发到不同的应用、集群、机器上去
16. 项目有什么做的不好的???
17. 项目中长期的规划, 有哪些可以做的
18. 对标其他公司的差距有哪些?
    18.1. 稳定性、容灾性、性能上的差距, 支持的能力上差距
19. 性能优化的思路、流程
    19.1 以耗时高的为例子
    19.2 CPU比较高的话 排查工具
20. 如何快速定位full GC
21. java 服务 的full GC 多久是属于正常的
22. java 服务日常关注哪些指标
23. mysql 的高可用架构
24. 主从架构下, mysql update 的数据流程
25. 有了解过消息中间件么?? 使用的场景有么?
26. 多线程并发工具, 如何控制多线程同步, 控制线程的调度顺序
27. 网关部分线程池在什么情况下会用到
28. 算法题: 接雨水
29. 为什么离职
30. 是否有其他offer
31. 容灾、可用性、稳定性
32. 个人关注的技术方向有哪些、以及了解渠道
33. 日常自己总结, 提升效率的有什么方法
</code></pre>
<h4 id="MNS"><a href="#MNS" class="headerlink" title="MNS"></a>MNS</h4><h5 id="MNS-准备"><a href="#MNS-准备" class="headerlink" title="MNS 准备"></a>MNS 准备</h5><pre><code class="hljs">1. MNS 工作流程
2. OCTO 工作流程
3. 路由策略
4. 限流方法有哪些, 分别有什么问题
5. 如何解决分片的reblance


普通哈希 和 一致性哈希
</code></pre>
<p>限流算法:<br>    1. 计数器<br>        实现方式: 在一个固定的时间内, 维护一个计数器, 记录当前请求的次数, 超过预定的值, 就进行限流<br>        优点: 简单<br>        缺点: 窗口边界有突发流量<br>                假设1min内服务器的负载能力为100，因此一个周期的访问量限制在100，然而在第一个周期的最后5秒和下一个周期的开始5秒时间段内，分别涌入100的访问量，虽然没有超过每个周期的限制量，但是整体上10秒内已达到200的访问量，已远远超过服务器的负载能力，由此可见，计数器算法方式限流对于周期比较长的限流，存在很大的弊端<br>    2. 滑动窗口<br>        实现方式: 将固定的窗口分割成细小的窗口, 通过不断的滑动来统计某段时间内的流量请求情况,<br>        优点: 减少临届问题, 限流更加平滑<br>        缺点: 实现复杂度高, 内存占用高<br>    3. 漏桶<br>        实现方式: 将请求流量看成是水流, 漏桶以固定的速率漏水, 如果漏桶满了, 超出的流量则被丢弃或者是排队处理<br>        优点: 可以平滑处理突发流量, 严格限制流量速度<br>        缺点: 容易导致短时间内的高峰流量被拒绝<br>    4. 令牌痛<br>        实现方式: 按照固定速率生成令牌, 每次请求需要拿一个令牌才可以被处理, 如果桶内没有令牌, 则进行拒绝<br>        优点: 相对灵活, 允许在时间范围内处理突发流量, 同时平滑处理长时间的流量<br>        缺点: 实现复杂</p>
<h3 id="单元化理解-1"><a href="#单元化理解-1" class="headerlink" title="单元化理解:"></a>单元化理解:</h3><pre><code class="hljs">单元化定义: 一个能完成所有业务操作的自包含集合, 包含了这个业务所需要的所有服务和数据, 每一个单元部署了系统所需要的所有应用, 数据则是按照某种数据维度划分后的一部分
核心在于水平模式, 每个机房都有完成全站所有业务的能力
数据分区: 
</code></pre>
<h4 id="netty-组建介绍"><a href="#netty-组建介绍" class="headerlink" title="netty 组建介绍"></a>netty 组建介绍</h4><h5 id="Channel-的作用-1"><a href="#Channel-的作用-1" class="headerlink" title="Channel 的作用"></a>Channel 的作用</h5><pre><code class="hljs">负责网络IO操作相关的
    1.1 管理IO 操作
        对数据读取、发送、和连接的管理
    1.2 处理事件
        从网络传输到channelPipeline, 将channelPipeline 处理后的数据返回到网络中去
    1.3 支持异步IO
        即将数据异步写入到网络中,不会阻塞当前线程
</code></pre>
<h5 id="EventLoop-作用-1"><a href="#EventLoop-作用-1" class="headerlink" title="EventLoop 作用"></a>EventLoop 作用</h5><pre><code class="hljs">1.每一个EventLoop 维护着一个 Selector 和 线程
2.处理IO 事件和任务
    监视和处理IO事件, 基于Java NIO 的selector 事件
3. 任务的调度
    还可以管理定时任务和普通任务, 可以提交任务到eventLoop上, 按照顺序和指定周期执行
4. 线程管理
    一个eventLoop通常和一个线程绑定, 每个eventLoop 可以维护多个channel, 但一个channel 始终绑定在一个eventLoop 上, 确保了同一个channel 上的事件处理是线程安全的
5. 事件的派发与处理
    负责从IO操作中获取事件, 将这些事件派发到对应的ChannelHandler中, 每个channel 代表一个连接或者IO操作, 在其pipeline中的一系列处理
</code></pre>
<h5 id="EventLoopGroup-作用-1"><a href="#EventLoopGroup-作用-1" class="headerlink" title="EventLoopGroup 作用"></a>EventLoopGroup 作用</h5><pre><code class="hljs">用于管理所有的EventLoop, 一个 EventLoopGroup 用于管理多个线程来并发去处理执行IO 事件
</code></pre>
<p>Channel 是网络通信的管道, 负责实际数据的读写, EventLoop 是负载驱动Channel 的 执行, 通过循环监听IO 事件来处理这些事件, EventLoopGroup 是多个EventLoop 的管理着, 负责分配和管理多个EventLoop, 并支持多并发处理多个Channel</p>
<h5 id="为什么需要将网络容器从tomcat-换成Netty-1"><a href="#为什么需要将网络容器从tomcat-换成Netty-1" class="headerlink" title="为什么需要将网络容器从tomcat 换成Netty"></a>为什么需要将网络容器从tomcat 换成Netty</h5><pre><code class="hljs">vmstat 1
/proc/stat 
top 等可以判断进程啥下文切换
可以检测上下文切换是否很高,
1. 实现机制上:
     serverlet 通过 startAsync 本质上依赖线程池去进行处理, netty天生为异步非阻塞的, 使用事件驱动的方式, 每个EventLoop 可以处理多个IO操作事件,可以极大的降低了线程数和线程切换的开销
2. 线程模型:
    serverlet 3.0异步依赖容器的线程管理, 在并发增加的情况下可能会导致线程的耗尽; netty 中使用少量的worker 线程来处理事件, 减少了上下文的切换, 避免了传统线程池模型的问题.
3. IO 模型
    serverlet 3.0 虽然支持异步处理, 但是底层依赖于阻塞IO模型; netty 使用java NIO 的非阻塞式, 从底层上确保了高并发表现的性能
4. 并发高的情况下 tomcat 由于采用的是BIO 加上异步线程的方式去处理的, 会有大量的线程产生, CPU 内存 文件描述符都会发生资源竞争，netty 是通过NIO 方式去做的，使用少量的 worker 线程就可以去处理
</code></pre>
<h2 id="为什么要用netty-1"><a href="#为什么要用netty-1" class="headerlink" title="为什么要用netty"></a>为什么要用netty</h2><pre><code class="hljs">事件驱动模型:
    基于reactor模式去做的, 通过EventLoop来管理IO 操作事件, 并将这些事件派发给相关的channelHandler, 实现高效的网络通信, 可以处理大量的并发连接
    核心组建:
        eventLoop
            1.每一个EventLoop 维护着一个 Selector 和 线程
            2.处理IO 事件和任务
                监视和处理IO事件, 基于Java NIO 的selector 事件
            3. 任务的调度
                还可以管理定时任务和普通任务, 可以提交任务到eventLoop上, 按照顺序和指定周期执行
            4. 线程管理
                一个eventLoop通常和一个线程绑定, 每个 eventLoop 可以维护多个channel, 但一个channel 始终绑定在一个eventLoop 上, 确保了同一个channel 上的事件处理是线程安全的
            5. 事件的派发与处理
                负责从IO操作中获取事件, 将这些事件派发到对应的ChannelHandler中, 每个channel 代表一个连接或者IO操作, 在其pipeline中的一系列处理
        channel
            负责网络IO操作相关的
            1.1 管理IO 操作
                对数据读取、发送、和连接的管理
            1.2 处理事件
                从网络传输到channelPipeline, 将channelPipeline 处理后的数据返回到网络中去
            1.3 支持异步IO
                即将数据异步写入到网络中,不会阻塞当前线程
        channelPipeline: 是一个处理链, 每个IO 事件都会按照顺序通过channelPipeline, 将多个channelHandler连接起来, 形成一条链, 每个channelHandler只负责处理特定的事件
        channelHandler: 用于处理特定类型事件的处理器, 不同的channelHandler 实现不同的功能, 有的可以用来编解码, 有的可以用来处理连接事件
        Selector: 用于监听多个 Channel 上的IO 事件, 当selector 发现某个Channel 上有事件发生的时候, 会通过EvenetLoop 来进行处理
    工作流程:
        boosGroup 和 workerGroup
            bossGroup 负责监听客户端的连接请求事件, 将接收请求并将连接交给workerGroup进行处理
            workerGroup负责处理具体的IO 操作
        事件的监听与触发
            当有IO发生的时候, EventLoop 会从selector 中获取到该事件, 并将其传递给绑定的channel
            事件会按照事件类型依次在channelPipeline 上流过, 通过channelHandler 来具体处理
        channelHandler 处理事件
            入站事件有inbounder 处理, 出站事件由outbounder 处理
            每个channelHandler 可以对事件进行处理, 处理完成后让下一个处理器进行处理
    线程模型
        EventLoop 绑定一个线程, 因此EventLoop管理的channel 也是在同一个线程上去运行的, 确保每个channel 上的事件处理是安全的, 从而减少了上下文切换的开销	
零拷贝 
    1. 零拷贝指的是在IO时减少或者消除数据内存拷贝的次数以及CPU的参与, 使得数据在IO的时候可以更加高效
    主要实现手段:
    1. sendfile() 系统调用: 是linux 提供的一种系统调用, 可以直接将数据从文件描述符传输到网络套接字上, 不需要将数据复制到用户空间, 内核直接通过mmap 和 DMA 进行数据传输
    2. mmap 系统调用: 可以将文件映射到进程的地址空间, 这样进程可以直接在自己的地址空间访问文件内容, 不需要显示的读写
    3. DMA 技术, 通过DMA 允许设备直接访问内存, 无需经过CPU, 通过DMA,
    优点:
        1. 减少CPU的开销, 避免了不必要的内存拷贝
        2. 提高数据传输效率. 减少了数据的传输效率
        3. 减少上下文的切换. 减少用户态和内核态的上下文切换
page cache
    是磁盘上的数据缓存到内存中的操作, 加速读写
    读操作:
        如果读取的时候数据已经在page cache 中, 则说明命中了直接返回, 避免了磁盘的IO
        如果读取的时候数据没有在page cache 中, 则从磁盘中获取并缓存到page cache中
    写操作
        预先将数据写入到page cache 中, 操作系统会在后台将page cache 数据写入到磁盘上去
    优点:
        提高读取速度: 加速磁盘的读取, 降低磁盘IO
        减少写入次数: 集中写的机制
        提高内存利用率: 操作系统会动态调整大小
    缺点:
        内存占用
        写入延迟	
支持零拷贝
    零拷贝指的是全程不需要 CPU 进行参与, 所有数据都是通过DMA来进行传输的
    全程只需要2次上下文切换, 2次DMA数据copy
ByteBuf 好处:
    1. 容量可以动态的调整
    2. 支持零拷贝, 减少数据在不同内存区域之间的复制, 
    3. polling 机制 从而进行重复利用
</code></pre>
<h5 id="Netty-的一次网络请求过程是什么-1"><a href="#Netty-的一次网络请求过程是什么-1" class="headerlink" title="Netty 的一次网络请求过程是什么"></a>Netty 的一次网络请求过程是什么</h5><pre><code class="hljs">客户端
    初始化:
        EventLoopGroup 的创建, 用于管理和服务之间网络链接和IO 操作, Bootstrap 配置客户端的各种参数, 包括线程模型, NioSocketChannel, 远端服务器的地址, 以及客户端的handler
    建立链接
        连接服务器: 通过Bootstrap.connect() 方法启动连接过程, 链接成功后会将channel 注册到event loop 上
        等待建立连接完成:  connect() 返回一个ChannelFuture, 可以通过sync() 或者是addListener 进行完成
    发送请求
        构造数据进行请求, 连接成功后, 通过channel 向服务器发送数据, 通常是将请求封装成 ByteBuf 
        对数据进行writeAndFlush 写数据, 数据会通过ChannelPipeline 的outbounder 进行处理, 通过底层的socket 发送到服务器
    接收响应
        pipeline 处理, 当服务器响应数据到的时候, 数据会到channelHander 的inbounder,
        处理响应数据: 业务逻辑进行处理, 处理完后返回给应用层
    关闭连接
        主动关闭连接: channel.close 关闭连接, 释放资源
        监听关闭操作: close 返回的future 进行监听, 进行监听关闭是否成功。
    资源清理
        group.shutDownGracefully() 进行清理
服务端
    初始化阶段
        创建EventLoopGroup, bossGroup 和 workerGroup, bossGroup 负责接受请求, workerGroup 负责处理; BossGroup 分配过来的IO 操作
        配置 serverBootstrap : 使用 ServerBootstrap 来配置 Netty 服务, 包括 channel 的类型, 指定 EventLoopGroup, 配置 channelPipeline , 以及设置服务器的监听端口
    绑定端口
        serverBootStrap.bind() 方法绑定服务器的监听端口, 会启动一个异步操作过程, bossGroup 中的线程会监听这个连接请求
        bind() 返回一个future, 可以通过sync()  或者是addListener 来等待响应
    接受客户端请求
        bossGroup 中的线程会去监听端口的连接请求, 当有新的请求进来的时候,bossGroup 中的某个eventLoop 会调用 NIO 的 selector 来监听OP_ACCEPT 事件, 一旦有新的连接时间发生, Boss Group 会接受这个连接并为这个连接创建一个channel, 并将连接对应的 channel 分配给worker 的EventLoop上,
        注册channel: 新的channel 会被注册在worker Group 中的eventLoop 上, 接下来和这个连接的相关读写操作都是在这个EventLoop 上
    处理客户端请求
        每个channel 关联的channelpipeline, 包含了一系列的handler
        当客户数据到达的时候, 数据会通过channelPipeline 中的inbounder 来进行处理, 负责数据的读取, 解码，业务逻辑处理等
    响应客户端
        当业务逻辑处理完后, 通过会通过ChannelHandlerContext.writeAndFlush() 将数据响应回给客户端
        数据会通过channelpipeline 中的outbounder，然后通过底层的socket 发送给客户端
    关闭连接
        客户端关闭连接, 或者是服务端主动关闭连接的时候, Netty 会处发ChannelInbounderHandler 的channelInactive 或者是channelUnregistered, 可以进行资源清理
        在关闭服务器的时候, 需要调用bossGroup 和worker Group 的shutdownGracefully 进行线程资源的释放
</code></pre>
<h3 id="项目准备"><a href="#项目准备" class="headerlink" title="项目准备"></a>项目准备</h3><pre><code class="hljs">1. yong gc 和full GC 如何优化的
    1.1 full gc 找到大的文件
    1.2 yong gc 在配置的快速变更期间, 导致客户端全都重新建立长轮训请求, 导致服务端的压力比较大, 服务端为了保证配置检测到配置文件的快速变更下发, 需要解析所有的配置文件版本号,以及和本地对比, 这部分数据都是瞬时压力比较大的, 因为客户端的数量比较多, 每次变更都是需要重新连上来, 因此一开始怀疑是不是Yong 区太小了, 导致yong 区GC 比较频繁, 因此将yong 区的大小调大 G1NewSizePercent, 观察效果. 同时由于我们采用的是G1 的算法, 他在yong gc 的时候会有STW, 导致处理耗时变长, 并且此时由于yong 区的对象比较多, 因此我们决定将G1 换成zgc, 第一步就是需要jdk 从1.8 升级到jdk11
    升级jdk 的时候有一些依赖 包的调整,  因为jdk11 引入了一些模块化, 一些类都废弃掉了. 升级完后再去将gc 方式换成zgc,
</code></pre>
<h1 id="项目总结"><a href="#项目总结" class="headerlink" title="项目总结"></a>项目总结</h1><h2 id="API-网关"><a href="#API-网关" class="headerlink" title="API 网关"></a>API 网关</h2><h4 id="对比其他网关区别"><a href="#对比其他网关区别" class="headerlink" title="对比其他网关区别"></a>对比其他网关区别</h4><pre><code class="hljs">1. 服务端支持集群模式的, 根据不同的集群功能, 拉取不同的配置
2. 数据集群有区分, 不同的数据类型拉取方式不一样
3. 限流功能自己实现
4. 有一些缓存的配置没有实现. 业务属性太强, 容易出问题
</code></pre>
<h2 id="配置中心"><a href="#配置中心" class="headerlink" title="配置中心"></a>配置中心</h2><h3 id="对比apollo-实现差别"><a href="#对比apollo-实现差别" class="headerlink" title="对比apollo 实现差别"></a>对比apollo 实现差别</h3><pre><code class="hljs">1. apollo config server 会定时轮训数据库去进行感知变化, 简单, 但是会带来延迟性高和资源的浪费
2. qconfig 通过两者结合
3. 对于配置的一些集群限流, 配置中心的服务端没有分集群, 但是控台对外restAPI  会根据不同的应用属性, 进行限制
</code></pre>
<!-- 
1. 网关如何提高性能
    4C 8G
    请求方式就是一个healthCheck 响应ok 这种的
    1.1 一开始压测
        如何解决压不上去的问题

    1.2 发现CPU 一下子就上去了
    1.3 更换网络框架
    1.4 更换IO 模型
2. 配置中心如何提升性能
3. 用户体验上的???
4. 单元测试上的

     -->
                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%80%BB%E7%BB%93/" class="category-chain-item">总结</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>技术总结</div>
      <div>http://localhost:4000/2024/08/17/interview/技术总结/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>pc-xie</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年8月17日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/09/06/interview/%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D/" title="项目介绍">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">项目介绍</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/08/11/jvm/jvm%20%E6%95%B4%E7%90%86/" title="jvm 整理">
                        <span class="hidden-mobile">jvm 整理</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
